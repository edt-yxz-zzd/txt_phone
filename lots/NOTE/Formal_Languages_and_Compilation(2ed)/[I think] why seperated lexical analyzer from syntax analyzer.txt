
1) syntax analyzer use CFG, but lexical analyzer may not use CFG
    e.g. Python, we must enclose indented body by <begin>...<end> before parsing

2) even when we can use CFG to descript lexical analyzer,
    2-1) lexeme/token are usually descripted by REG which may be ambiguous
        unambiguous r.e. may be too long
    2-2) how to classify characters??
        2-2-1) enumerate all characters of a class
            to boring
        2-2-2) use predefined classes and regex operator
            e.g. ".", "\w", "[:alpha:]", "rex_difference" "rex_intersection"
            complicate the grammar syntax
    2-3) time-space consume
        NOTE: Nc << Nt where Nc == num_chars, Nt = num_tokens
        time-complexity : O(Nc^3) vs O(Nt^3)
        space-complexity ??

        