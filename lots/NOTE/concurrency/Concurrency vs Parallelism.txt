
-- asynchronously
-- Interruptability
concurrency
    = parallelism
        -- Independentability
        -- some calculations happen simultaneously
        -- require: multiple cores or distribute system

    | interleaved processing
        -- a.k.a. coroutines


















The difference between “concurrent” and “parallel” execution?
http://softwareengineering.stackexchange.com/questions/190719/the-difference-between-concurrent-and-parallel-execution
Concurrent processing describes two tasks occurring asynchronously, meaning the order in which the tasks are executed is not predetermined. Two threads can run concurrently on the same processor core by interleaving executable instructions. For example, thread 1 runs for 10ms, thread 2 runs for 10ms etc.

Parallel processing is a type of concurrent processing where more than one set of instructions is executing simultaneously. This could be multiple systems working on a common problem as in distributed computing, or multiple cores on the same system.

















Concurrency Vs Parallelism
https://www.researchgate.net/post/Concurrency_Vs_Parallelism
Concurrency, means that you have concurrent accesses to one or more shared resources in a system (operating system, database system, etc...). Concretely, two or more threads (or processes) make accesses to a given resources or set of resources. You can perfectly gave concurrency without parallelism. If two or more threads that are running on a single-core CPU, or on the same core in a multi-cores CPU, they can concurrently access to the same resources even if their execution is in pseudo-parallelism. This usually means that you have to deal with mutual exclusion if you want to avoid data incoherency problems, in the case of write (modification) accesses.

Parallelism means that two or more processes (or threads) are running in parallel (I mean here not in pseudo-parallelism like in single-core processors, but in real parallelism like in multi--cores). Parallelism may involve concurrency of the threads or processes sharing one or more resources and making write operations (modifications) on these resources. Concurrency for read operations exists but is not a major concern as it does not generate coherency problems. Now, we can perfectly have parallelism without concurrency, if no resource is shared.

In operating systems, we can also say that several processes or threads running on the same core are making a concurrent use of the processor (core). They are all in competition to obtain the processor.

There is effectively no difference between pseudo-parallelism and real parallelism from the possible concurrent accesses point of view. The only difference is that things will go faster with real parallelism.

Anyway, in some rare cases with pseudo parallelism, we can have potential concurrent accesses (write accesses for example) to a given resource from several threads, but this will luckily work! This is because in pseudo-parallelism (on a single CPU), even if we have concurrent accesses, they are sequential. The problem is when a task or thread commutation occurs when a thread did not achieve to terminate its write access before its execution quantum ends. So if you are lucky, a parallel program could work without generating coherency problems. But this is pure luck!

When things really work in parallel (real parallelism on multiple CPUs or on a multi-core CPU), you have to be very very lucky for your program to work correctly without any synchronization techniques. This is because without synchronization, there is not any kind of sequential execution among threads. To be honest, in every case, you need to use synchronization techniques like mutual exclusion to ensure that you program will correctly work. Being lucky, is never a good choice for parallel programming :-)




















Concurrency vs Parallelism, Concurrent Programming vs Parallel Programming
https://blogs.oracle.com/yuanlin/entry/concurrency_vs_parallelism_concurrent_programming
By yuanlin on Jun 11, 2006

THIS BLOG HAS BEEN MOVED TO touchdreams.net/blog.
In the danger of hairsplitting, ...

Concurrency and parallelism are NOT the same thing. Two tasks T1 and T2 are concurrent if the order in which the two tasks are executed in time is not predetermined,

T1 may be executed and finished before T2,
T2 may be executed and finished before T1,
T1 and T2 may be executed simultaneously at the same instance of time (parallelism),
T1 and T2 may be executed alternatively,
...
If two concurrent threads are scheduled by the OS to run on one single-core non-SMT non-CMP processor, you may get concurrency but not parallelism. Parallelism is possible on multi-core, multi-processor or distributed systems.

Concurrency is often referred to as a property of a program, and is a concept more general than parallelism.

Interestingly, we cannot say the same thing for concurrent programming and parallel programming. They are overlapped, but neither is the superset of the other. The difference comes from the sets of topics the two areas cover. For example, concurrent programming includes topic like signal handling, while parallel programming includes topic like memory consistency model. The difference reflects the different orignal hardware and software background of the two programming practices.
