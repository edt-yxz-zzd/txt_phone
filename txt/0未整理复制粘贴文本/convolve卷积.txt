
[[[
x&(y^z)==(x&y)^(x&z)
  分配律

卷积 满足 交换律
  (xs <*> ys)
    = (\k->sum~ xs[i]ys[k-i] {i})
    = (\k->sum~ xs[i]ys[j] {i+j==k})
卷积 满足 结合律？对！
  (xs <*> ys) <*> zs
    = (\k->sum~ xs[i]ys[k-i] {i}) <*> zs
    = (\n->sum~ sum~ xs[i]ys[k-i] {i} * zs[n-k] {k})
    = (\n->sum~ sum~ xs[i]ys[k-i] * zs[n-k] {i} {k})
    = (\n->sum~ xs[i]ys[j] * zs[k] {i+j+k==n})
  xs <*> ys <*> zs
可逆卷积
  ys = xs <*> ms
  xs = ys <*> ws
      = xs <*> ms <*> ws
      = xs <*> (ms <*> ws) #结合律
  I = \k->[k==0]
  !!xs = xs <*> I
  (ms <*> ws) == I


convolve__bits<ks_>(xs)=ys
  ks = 1+(ks_<<1)
  ys[0] = ks[0]&xs[0]
    xs[0] = ys[0]
  ys[1] = (ks[1]&xs[0]) ^ (ks[0]&xs[1])
    xs[1] = (ks[1]&xs[0]) ^ ys[1]
          = (ks[1]&ys[0]) ^ (ks[0]&ys[1])
  xs[2] = (ks[2]&xs[0]) ^ (ks[1]&xs[1]) ^ (ks[0]&ys[2])
        = (ks[2]&ys[0]) ^ (ks[1]&((ks[1]&ys[0]) ^ (ks[0]&ys[1]))) ^ (ks[0]&ys[2])
        = (ks[2]&ys[0]) ^ (ks[1]&ys[0]) ^ (ks[1]&ks[0]&ys[1]) ^ (ks[0]&ys[2])
        = ((ks[2]^ks[1])&ys[0]) ^ ((ks[1]&ks[0])&ys[1]) ^ (ks[0]&ys[2])
  x0 = y0
  x1 = k1y0 y1
  x2 = (k2 k1)y0 k1y1 y2
  xs[3] = (ks[3]&xs[0]) ^ (ks[2]&xs[1]) ^ (ks[1]&xs[2]) ^ (ks[0]&ys[3])
        = k3x0 k2x1 k1x2 k0y3
        = k3y0 k2k1y0 k2k0y1 k1(k2 k1)y0 k1k0y1 k1k0y2 k0y3
        = (k3 k1)y0   (k2 k1)y1   k1y2 y3



  ys[k] = xor~ (ks[k-i]&xs[i]) {i<-[0..k]}
        = xs[k] ^ xor~ (ks[k-i]&xs[i]) {i<-[0..k-1]}
  xs[k] = ys[k] ^ xor~ (ks[k-i]&xs[i]) {i<-[0..k-1]}
        = ys[k] ^ (ks[1]&xs[k-1]) ^ xor~ (ks[k-i]&xs[i]) {i<-[0..k-2]}
        = ys[k] ^ (ks[1]&(ys[k-1] ^ xor~ (ks[k-1-i]&xs[i]) {i<-[0..k-2]})) ^ xor~ (ks[k-i]&xs[i]) {i<-[0..k-2]}
        = ys[k] ^ (ks[1]&ys[k-1]) ^ (ks[1]&xor~ (ks[k-1-i]&xs[i]) {i<-[0..k-2]}) ^ xor~ (ks[k-i]&xs[i]) {i<-[0..k-2]}
        = ys[k] ^ (ks[1]&ys[k-1]) ^ xor~ (ks[1]&ks[k-1-i]&xs[i]) {i<-[0..k-2]} ^ xor~ (ks[k-i]&xs[i]) {i<-[0..k-2]}
        = ys[k] ^ (ks[1]&ys[k-1]) ^ xor~ ((ks[1]&ks[k-1-i]^ks[k-i])&xs[i]) {i<-[0..k-2]}
 ks[0]&xs[0]
 ks[0]&xs[0]
 ks[0]&xs[0]
 ks[0]&xs[0]
 ks[0]&xs[0]
 ks[0]&xs[0]
卷积convolution
deconvolution
convolve

cross-correlation convolution formula

binascii.a2b_qp
numpy.convolve
??autocorrelation<F> = convolve(F,F)
convolve(F, G)[k]=sum F[i]*G[k-i] {i}=sum F[i]*G[j] {i+j=k}
  可交换commutative
cross-correlation(F,G)[k]=sum F[i]*complex-conjugate(G[i-k]) {i}
  不可交换
  F.i - G.i === cross_correlation(F,G).i
  https://dsp.stackexchange.com/questions/2654/what-is-the-difference-between-convolution-and-cross-correlation/

The only difference between cross-correlation and convolution is a time reversal on one of the inputs. Discrete convolution and cross-correlation are defined as follows (for real signals; I neglected the conjugates needed when the signals are complex):

x[n]∗h[n]=∑k=0∞h[k]x[n−k]

corr(x[n],h[n])=∑k=0∞h[k]x[n+k]

This implies that you can use fast convolution algorithms like overlap-save to implement cross-correlation efficiently; just time reverse one of the input signals first. Autocorrelation is identical to the above, except h[n]=x[n]

, so you can view it as related to convolution in the same way.

Edit: Since someone else just asked a duplicate question, I've been inspired to add one more piece of information: if you implement correlation in the frequency domain using a fast convolution algorithm like overlap-save, you can avoid the hassle of time-reversing one of the signals first by instead conjugating one of the signals in the frequency domain. It can be shown that conjugation in the frequency domain is equivalent to reversal in the time domain.

This answer is fine for real signals, but Jason brought up complex-valued signals, in which case it is important to note that it is not quite the case that the "only difference is .... time reversal ..." Indeed, complex conjugates are needed on one of the two signals in the correlation formula (which one is conjugated is a matter of convention - some say to may to and some say to mah to - but both call a fruit a vegetable). On the other hand, neither signal is conjugated in the convolution formula. – Dilip Sarwate Jun 20, 2012 at 2:44



python bytes xor#转化为整数
how to count 1 bits of integer
https://www.geeksforgeeks.org/count-set-bits-in-an-integer/
Brian Kernighan’s Algorithm
  (n & (n-1)), we unset the rightmost set bit. If we do n & (n-1) in a loop and count the number of times the loop executes, we get the set bit count.
https://www.geeksforgeeks.org/difference-between-convolution-vs-correlation/
How to perform convolution

1. Flip the mask and do correlation.
2. The 1D mask is flipped horizontally, as there is a single row.
3. The 2D mask is flipped vertically and horizontally.
4. Mask is slid over the image matrix from the left to the right direction.
5. When the mask hovers on the image, corresponding elements of mask and image are multiplied and the products are added.
6. This process repeats for all the pixels of the image.
https://english.stackexchange.com/questions/64046/convolve-vs-convolute
math/singal-processing/image-processing: convolve+convolution,not convolute

https://www.geeksforgeeks.org/autocorrelation/




overlap-save
overlap-add
https://pypi.org/project/overlap-save/
[[
https://www.mathworks.com/help/dsp/ug/overlap-add-save.html

Overlap-Add/Save

This example shows how to filter a sinusoid with the Overlap-Add and Overlap-Save FFT methods using the Frequency-Domain FIR filter block.

Open and run the model.

The overlap-add algorithm [1] filters the input signal in the frequency domain. The input is divided into non-overlapping blocks which are linearly convolved with the FIR filter coefficients. The linear convolution of each block is computed by multiplying the discrete Fourier transforms (DFTs) of the block and the filter coefficients, and computing the inverse DFT of the product. For filter length M and FFT size N, the last M-1 samples of the linear convolution are added to the first M-1 samples of the next input sequence. The first N-M+1 samples of each summation result are output in sequence.

The overlap-save algorithm [2] also filters the input signal in the frequency domain. The input is divided into overlapping blocks which are circularly convolved with the FIR filter coefficients. The circular convolution of each block is computed by multiplying the DFTs of the block and the filter coefficients, and computing the inverse DFT of the product. For filter length M and FFT size N, the first M-1 points of the circular convolution are invalid and discarded. The output consists of the remaining N-M+1 points, which are equivalent to the true convolution.

Overlap-save and overlap-add introduce a processing latency of N-M+1 samples. You can reduce this latency by partitioning the numerator into shorter segments, applying overlap-add or overlap-save over the partitions, and then combining the results to obtain the filtered output [3]. The latency is reduced to the partition length, at the expense of additional computation compared to traditional overlap-save/overlap-add (though still numerically more efficient than time-domain filtering for long filters). In this model, we use a partition length of 30, which reduces the latency from 213 samples for traditional overlap-add/overlap-save to 30 samples.
References

[1] Overlap-Add Algorithm: Proakis and Manolakis, Digital Signal Processing, 3rd ed, Prentice-Hall, Englewood Cliffs, NJ, 1996, pp. 430 - 433.

[2] Overlap-Save Algorithm: Oppenheim and Schafer, Discrete-Time Signal Processing, Prentice-Hall, Englewood Cliffs, NJ, 1989, pp. 558 - 560.

[3] T. G. Stockham Jr., "High-speed convolution and correlation", Proc. 1966 Spring Joint Computer Conf., AFIPS, Vol 28, 1966, pp. 229-233.
]]
]]]
