
e others/数学/exponential.txt
view others/数学/continued-fraction/generalized_continued_fraction.txt

www:
    https://handwiki.org/wiki/Generalized_continued_fraction
    https://handwiki.org/wiki/Euler%27s_continued_fraction_formula
    Sardina, Manny (2007). "General Method for Extracting Roots using (Folded) Continued Fractions". Surrey (UK). http://myreckonings.com/Dead_Reckoning/Online/Materials/General%20Method%20for%20Extracting%20Roots.pdf.
    https://math.stackexchange.com/questions/18445/fastest-way-to-calculate-ex-up-to-arbitrary-number-of-decimals
        https://imathworks.com/math/math-fastest-way-to-calculate-ex-up-to-arbitrary-number-of-decimals/




generalized continued fractions
[ln2 == 1/(1+1/(2+1/(3+4/(4+4/(5+9/(6+9/(7+...)))))))]
[let k:=2*(2*z-y) in sqrt(z)==sqrt(x**2+y) == x+2*x*y/(k-y -y**2/(k-y**2/(...)))]





[[
无用，2页
The application of continued fractions and their generalizations to problems in approximation theory
A.N. Khovanskii, 1963 (P.Noordhoff)
https://www.cambridge.org/core/services/aop-cambridge-core/content/view/DF98E1D220B486A3AE70FFE10EC4949A/S0008439500032033a.pdf/the-application-of-continued-fractions-and-their-generalizations-to-problems-in-approximation-theory-by-alexey-nikolaevitch-khovanskii-translated-by-peter-wynn-p-noordhoff-n-v-groningen-1963-xii-212-p.pdf
https://www.cambridge.org/core/journals/canadian-mathematical-bulletin/article/application-of-continued-fractions-and-their-generalizations-to-problems-in-approximation-theory-by-alexey-nikolaevitch-khovanskii-translated-by-peter-wynn-p-noordhoff-n-v-groningen-1963-xii-212-pages-dfl-28/DF98E1D220B486A3AE70FFE10EC4949A
]]


[[
Handbook of continued fractions for special functions (Cuyt et al, 2008)
https://www.researchgate.net/publication/221025548_Continued_Fractions_for_Special_Functions_Handbook_and_Software
https://www.researchgate.net/profile/Annie-Cuyt/publication/221025548_Continued_Fractions_for_Special_Functions_Handbook_and_Software/links/0c96051b8428f0c284000000/Continued-Fractions-for-Special-Functions-Handbook-and-Software.pdf
ResearchGate
https://www.researchgate.net/profile/Annie-Cuyt/publication/...
[PDF]Continued Fractions for Special Functions: Handbook and…
The Handbook of continued fractions for special functions is the result of a systematic study of series and continued fraction representations for several families of mathemati- cal...
只是简介

]]
[[
wget_U 'https://medialibrary.uantwerpen.be/oldcontent/container2652/files/papers/Ba_Cu_alg_09.pdf' -O 'Algorithm 895-A Continued Fractions Package for Special Functions(Ba_Cu_alg_09).pdf'

University of Antwerp
https://medialibrary.uantwerpen.be/oldcontent/container2652/files/...
[PDF]Algorithm 895: A Continued Fractions Package for Special…
special functions and to make them available on the Web and extend them with computational facilities. This package complements the Handbook of Continued Fractions for Special Functions [Cuyt et al. 2008], which resulted from a systematic study of contin-ued fraction
]]


[[[
无用，只是%n,整数e
wget_U 'https://courses.cs.washington.edu/courses/cse311/21sp/resources/reference-modular-exponentiation.pdf' -O 'cse311-21sp-reference-modular-exponentiation.pdf'
===
courses.cs.washington.edu
https://courses.cs.washington.edu/courses/cse311/21sp/resources/...
[PDF]Fast Exponentiation Algorithm - University of Washington
PDF
WebFast Exponentiation Algorithm An application of all of this modular arithmetic Amazon …

File Size: 283KB
Page Count: 15
]]]

[[[
https://math.stackexchange.com/questions/18445/fastest-way-to-calculate-ex-up-to-arbitrary-number-of-decimals
https://imathworks.com/math/math-fastest-way-to-calculate-ex-up-to-arbitrary-number-of-decimals/
===
symmetry of the exponential function
  [e**x == 1/e**-x]
  [?f. [e**x == (1+x∗f(x**2))/(1−x∗f(x**2))]]
  [x*f(x**2) == (e**x-1)/((e**x+1)]
range reduction
  [(q,r) := x/% ln2][exp(x) == 2**q * exp(r)]
    [r <- [=0,ln2>]]
generalized continued fraction

===
===
===

Mathematics
Fastest way to calculate ex up to arbitrary number of decimals?
Asked 12 years, 7 months ago
Modified 3 years, 7 months ago
Viewed 22k times
27

What are other faster methods of calculating ex up to any number of decimals other than using the Taylor series formula?

algorithmselementary-functions
Share
Cite
Follow
edited Aug 26, 2014 at 2:10
hardmath's user avatar
hardmath
36.3k2020 gold badges7272 silver badges141141 bronze badges
asked Jan 21, 2011 at 17:25
Pushpak Dagade's user avatar
Pushpak Dagade
59922 gold badges66 silver badges1414 bronze badges
3
I'm told the series converges rapidly and is well-conditioned. Have you tried that? – 
Zhen Lin
 Jan 21, 2011 at 17:33
3
Why not use the standard series expansion ∑ixi/i! ? I'm not sure, but it may pay of to first convert to a value in [=0,1>], e.g. to calculate e10, calculate (e1/2)20 – 
Myself
 Jan 21, 2011 at 17:34 
1
For what values of x are you trying to calculate ex? The exponential series itself converges pretty fast for small values of x. Are you looking for something faster than that? Is x likely to be a large number? – 
svenkatr
 Jan 21, 2011 at 17:36 
1
I believe Haskell supports it. And many programmings languages have standard libraries which support it. E.g. Java has java.math.BigDecimal. – 
Peter Taylor
 Jan 21, 2011 at 18:10
2
I used the generalized continued fraction method (en.wikipedia.org/wiki/Generalized_continued_fraction) to find e upto large number of decimals, and it is way to fast than this series method... The only problem with is that I don`t know how deep I should go to find e^x upto a particular decimal places... I usually have to find it for large value... So if someone can help me with this it would be great!! – 
Pushpak Dagade
 Jan 22, 2011 at 9:55 
Show 4 more comments
6 Answers
Sorted by:

Highest score (default)
25

If I wanted to implement an arbitrary precision approximation to ex from "scratch" (building on an arbitrary precision numeric library such as GMP) with faster convergence than Taylor series/polynomial approximations, I would design around continued fraction/rational function approximations.

Just as the precision given by the well-known Taylor series can be extended as required by using additional terms, so too will the continued fraction expansion give any required precision by using additional convergents.

At first it may seem that evaluating the continued fraction approximation entails a significant disadvantage in comparison with the power series. Additional terms can be added to the partial sums of the power series, to obtain left-to-right sequential approximations. There is a way to achieve the same effect with continued fractions, namely evaluating the partial numerators and denominators into the convergents through a recurrence relation.

There are a couple of important ideas worth considering even if another method for evaluating the exponential function were to be used on a bounded interval such as [0,1], as for example power series or even lookup tables(!). One is symmetry of the exponential function, and the other is a method of range reduction.

Although the exponential function is not even (or odd), it satisfies a relation:

e−x=1/ex
that implies it is a simple rational transformation of an even function:

ex=(1+x∗f(x2))/(1−x∗f(x2))
which may be solved for a power series or continued fraction approximation of f(z). This is the idea of symmetry as it applies to the exponential function. Not only does it reduce the evaluaton of the exponential function on the whole real line to just the positive (or the negative) half, it also "contracts" the number of terms needed for a given accuracy by half (retaining only x2 terms in the expansion).

Although a continued fraction or Taylor series approximation to the exponential function may converge for arbitrary real (or complex) values), the rate of convergence is not uniform. The Taylor series converges faster the closer the argument is to zero. Thus a range reduction is important for expressing the exponential function at an arbitrary real value in terms of a value in some interval like [0,1]. For example, if the floating point arithmetic is binary (radix 2), it can be especially convenient to use the familiar law of exponents with multiples of ln2:

ex=2k∗er where x=r+k∗ln2
which allows ex to be evaluated, up to a change in binary exponent, using an approximation that converges rapidly over [0,ln2].

Combining these two ideas (symmetry, range reduction) the speed of convergence can be limited to the interval [0,ln2/2]. Limiting the interval of evaluation may allow you to determine in advance how many terms of the continued fraction or Taylor series expansion have to be retained to obtain a desired accuracy. When this is known the evaluation can be done more efficiently (backwards recursion for continued fractions or Horner's method for truncated Taylor series/polynomials) than if we were forced to continually introduced further terms until the desired accuracy is reached.

Added:

The "faster" continued fraction I had in mind is formula (11.1.2) here:

[Handbook of continued fractions for special functions (Cuyt et al, 2008)]
http://books.google.com/books?id=DQtpJaEs4NIC&dq=exponential+function+continued+fraction+convergence

Their reference is to this modern classic:

The application of continued fractions and their generalizations to problems in approximation theory
A.N. Khovanskii, 1963 (P.Noordhoff)

A neat webMathematic-based site by Andreas Lauschke presents some ideas for accelerating convergence of continued fractions by "contractions". The IP address changes from time to time and cannot be used as a link within StackExchange, but you can Google for it:

[Convergence Acceleration with Canonical Contractions of Continued Fractions: Exponential function -- Andreas Lauschke Consulting]

I have some notes on his formulas (derived by contraction from the one noted above) if that would be helpful. Some related material was contributed to Wolfram Demonstrations.

Computing the constant ln2

Generations of math students have been introduced to the concept of conditional versus absolute convergence by the example of the alternating harmonic series:

ln2=1−1/2+1/3−1/4+...
Of course this series, derived from a power series expansion of lnx around x=1, has such slow convergence that even if we combine consecutive pairs of terms:

ln2=1/2+1/12+1/30+...
the resulting absolutely convergent series is useless for obtaining arbitrary precision values of ln2. For convenience the first seven partial sum of this are:

0.50000000...  
0.58333333...  
0.61666666...  
0.63452381...  
0.64563492...  
0.65870518...  
Since ln2 is 0.69314718..., we have an error of about a third of a unit in the first decimal place. In other words not much more convergence than one decimal place correct.

It therefore makes a striking contrast with the nice convergence of a continued fraction expansion of the same value:

ln2=11+12+13+44+45+96+97+...
[ln2 == 1/(1+1/(2+1/(3+4/(4+4/(5+9/(6+9/(7+...)))))))]
The first seven convergents are:

0.66666666...  
0.70000000...  
0.69230769...  
0.69333333...  
0.69312169...  
0.69315245...  
The error here is about half a unit in the fifth decimal place.

Share
Cite
Follow
edited Aug 26, 2014 at 2:08
answered Jan 22, 2011 at 13:27
hardmath's user avatar
hardmath
36.3k2020 gold badges7272 silver badges141141 bronze badges
Please explain further the "idea of symmetry" that allows the number of terms needed to be halved. I don't understand it. – 
MikeM
 Oct 1, 2013 at 17:22 
2
@MikeM: Briefly the function ex can be expressed as (1+g(x))/(1−g(x)) where g(x) is an odd function of x. Try replacing g(x) with g(−x) and you will see it implies the "symmetry" e−x=1/ex. Now a power series expansion of g(x) will have only odd powers, or g(x)=xf(x2). Thus a series expansion of g(x) has only half as many nonzero terms as one for ex. If you want a detailed comparison of op counts for equal accuracy, please post that as a Question so it can be addressed at length. – 
hardmath
 Oct 2, 2013 at 12:56
@MikeM: Note that this "economy" of using only even powers of x can be realized by generalized continued fraction as well as power series expansions of ex. – 
hardmath
 Oct 2, 2013 at 13:28
2
I have asked a new question here. – 
MikeM
 Oct 2, 2013 at 15:12 
1
Coming back to this several years later (from another question on approximating logarithms!) it may be worth noting that the alternating series for ln2 is a fine candidate for the Euler transformation of alternating series, and that gives convergence much closer to the continued fraction representation. – 
Steven Stadnicki
 May 4, 2022 at 15:21
Show 10 more comments
11

The theoretically fastest way appears to be to use Newton iteration to reduce the problem to computing the logarithm function and then using an algorithm based on the arithmetic-geometric mean to compute the logarithm. See this wikipedia page. http://en.wikipedia.org/wiki/Computational_complexity_of_mathematical_operations

In practice the Taylor series should work fine, given a good implementation. The following webpage http://numbers.computation.free.fr/Constants/constants.html has an example impletation of using the taylor series to compute e. They claim it took 0.02 seconds to compute e to a thousand decimals on a PentiumII, 450 MHz processor.

Share
Cite
Follow
answered Jan 21, 2011 at 18:40
Johan's user avatar
Johan
2,19711 gold badge1313 silver badges2727 bronze badges
Add a comment
6

A very reasonable way to do this is to use

ex=1+x/1!+x2/2!+x3/3!...
as it converges really fast.

A "trick" I read in some library for calculating e1 is to calculate the series for x=1/2k where k is the root of the amount of required bits, then you have to square the result k times to get your final number, it avoids that big/small numbers make the result too inaccurate.

Edit: Also this is the exact same topic like Iterative refinement algorithm for computing exp(x) with arbitrary precision

Maybe it should be merged / closed?

Share
Cite
Follow
edited Apr 13, 2017 at 12:21
Community's user avatar
CommunityBot
1
answered Jan 21, 2011 at 17:37
Listing's user avatar
Listing
13.9k33 gold badges4848 silver badges7474 bronze badges
1
Well, this is a slow method, I know other methods which are more faster than this... I just want some other method – 
Pushpak Dagade
 Jan 21, 2011 at 17:51
I think the other question is significantly different as it asks for methods to increase the precision of computed values without starting over "from scratch". Here the emphasis seems to be on the speed with which a given accuracy can be achieved. – 
hardmath
 Jan 21, 2011 at 18:20
Add a comment
1

I don't know that this is necessarily the fastest way, but it's fun. If you want to know how it works, Google.

package com.akshor.pjt33.math;

import com.akshor.pjt33.math.symbalg.Rational;
import java.math.BigInteger;

public abstract class Spigot
{
    /** The relevant components of the prefix matrix. */
    Rational h00, h01=Rational.ZERO, h11=Rational.ONE;
    BigInteger i=BigInteger.ZERO;
    boolean verify=true;
    final int base;
    private StringBuilder sb=new StringBuilder();

    public Spigot(BigInteger multiplier) {
        this(multiplier, 10);
    }

    public Spigot(BigInteger multiplier, int base) {
        h00=new Rational(multiplier, BigInteger.ONE);
        this.base=base;
    }

    /**
     * Advances this spigot algorithm, producing as many digits as each consumption permits.
     * @param beta An upper bound (positive) on the magnitude of all subsequent term ratios.
     * @return The number of digits output.
     */
    public int advance(Rational beta) {
        if (verify && beta.signum()0) throw new IllegalArgumentException(Et_t+" exceeds bound "+beta);
        h00=h00.mul(Et_t);
        i=i.add(BigInteger.ONE);

        // Produce (if we can: without a converging bound we can't).
        int rv=0;
        if (beta.compareTo(Rational.ONE)0; i++) numdigits-=advance(beta);
        return i;
    }

    protected abstract Rational termRatio();

    public String toString() {
        return sb.toString();
    }

    /**
     * A spigot implementation which evaluates any hypergeometric sum for which you can
     * provide a term bound.
     * E.g. PI = 3 F(1/2, 1, 1, 8/5 ; 3/5, 4/3, 5/3 | 2/27) with term limit 2/27.
     */
    public static class Hypergeometric extends Spigot
    {
        private final Rational[] a, b;
        protected final Rational z;

        public Hypergeometric(Rational[] a, Rational[] b, Rational z) {
            this(a,b,z,BigInteger.ONE);
        }

        public Hypergeometric(Rational[] a, Rational[] b, Rational z, BigInteger mul) {
            super(mul);
            this.a=a.clone();
            this.b=new Rational[b.length+1];
            this.b[0]=new Rational(1,1);
            System.arraycopy(b,0,this.b,1,b.length);
            this.z=z;
        }

        protected Rational termRatio() {
            Rational rv=z;
            for (Rational num : a) rv=rv.mul(num.add(i));
            for (Rational num : b) rv=rv.div(num.add(i));
            return rv;
        }
    }

    public static class Exp extends Hypergeometric
    {
        public Exp(Rational z) {
            super(new Rational[0], new Rational[0], z);
        }

        // We rely on the fact that the term ratio for Exp always decreases.
        public int output(int numdigits) {
            int i=0;
            for (; numdigits>0; i++) numdigits-=advance(termRatio().abs());
            return i;
        }
    }

    public static void main(String[] args) {
        Exp e=new Exp(Rational.ONE);
        int count=e.output(100);
        System.out.println(e);
        System.out.println("Iterations required: "+(count+1));

        Exp e2=new Exp(new Rational(2,1));
        count=e2.output(100);
        System.out.println(e2);
        System.out.println("Iterations required: "+(count+1));

        Exp em2=new Exp(new Rational(-2,1));
        count = em2.output(100);
        System.out.println(em2);
        System.out.println("Iterations required: "+(count+1));
    }
}
Implementing the Rational class is left as an exercise. And yes, this code is an argument for limited operator overloading.

Share
Cite
Follow
edited Jan 21, 2011 at 20:42
answered Jan 21, 2011 at 18:15
Peter Taylor's user avatar
Peter Taylor
13.3k11 gold badge3030 silver badges5151 bronze badges
The spigot algorithm for e is interesting, but it does not allow one to compute ex without considerable additional work. – 
hardmath
 Jan 21, 2011 at 19:34
Oops, I haven't actually included the implementation of e^x. Most of the additional work is done, though. – 
Peter Taylor
 Jan 21, 2011 at 20:08
Add a comment
1

My webMathematica site hardmath is referring to is indeed down at the moment as I have problems getting webM work with the latest tomcat.

A few comments: - the question of the o/p was about "fastest way". That should be made a bit more precise. Usually people mean fast convergence rates with that. But "fast" in its original sense really means running time. And contractions of continued fractions are a good example of dramatically increasing the convergence rate, but at the expense of getting more and more complicated terms to compute for that. In other words, you need much fewer terms to attain higher precision, but every term is more complex than the simpler ones, of which you need more. Sometimes more cheap steps are faster, and sometimes few expensive terms are faster. It depends on how the computation is done. High-level language? A VM? Machine code? Assember? - hardmath, regarding your third paragraph. Every power series, not just Taylor series, can be converted into an EQUIVALENT continued fraction expansion. The converse is not generally true, especially for delta fractions. The continued fraction expansion is (almost?) always more stable than a power series solution as the terms don't grow as fast. In a power series you are adding many terms of which numerator and denominator are growing at very fast rates, incurring a lot of numerical problems. The c/f expansions are (usually) much more stable, in fact, the parabola theorem states that Stieltjes, C-, and several other c/f expansions are even self-correcting if the backwards recursion is used. And many power series are outright trash if the function to be approximated has poles, which isn't the case here with exp(x), so I won't go into that (just consider that the p/s for tan(x) involves Bernoulli polynomials, converges slowly, converges only in a small interval between poles, whereas the c/f expansion converges rapidly with very simple terms in the whole complex plane EXCEPT at the poles -- which form a null set -- and is very stable with small terms in the convergents). - there's also a few papers on the web that describe how sin, cos, exp, and log are computed by the chip manufacturers. The fastest way to compute these functions is to burn them on a chip and let the semiconductors do it for you, than writing software. The math they use for this is truly mind-boggling. A combination of numerical math, implementation on a chip, and sometimes GPU-based parallelization that is beyond fascinating.

Feel free to contact me through my website, www.lauschkeconsulting.com/contact.html if you need more information, I can provide you with my contraction formulas of the formulas hardmath is referring to (in the Cuyt et al book). The convergence rates are enormous, but the terms also get pretty complicated very fast, which makes numerical computations a bit slower again as more complicated terms have to be evaluated, than if you didn't contract the c/f.

Added on 20110201: My webMathematica site is live again, I solved the tomcat problem.

Share
Cite
Follow
edited Feb 2, 2011 at 3:56
answered Feb 1, 2011 at 3:18
user6463
Add a comment
1

Fastest way is to use Newton method of calculation of square root xn+1=0.5(xn+a/xn) from e, it will give you
exp(^2 .1),
exp(0b0.1),
where 2 denotes a binary number.

Then you calculate square root of square root, giving you
exp(0b0.01)

And so on. This will allow you to create tables of logarithms and exponents. This is the fastest way to do by hand calculation and it was used historically.

Pade approximations are good, but they do not converge as fast as Newton method, which effectively doubles your "accurate number count" by single iteration.

Then you multiply the required amount of "roots" you have, effectively stacking any binary number you need to exponentiate, and you also is able to reuse your roots to build an "acceleration table", where you keep exponents for often used numbers like exp(0b0.101)

Note that you can shift between different exponentiation digits by "rooting" of your number, so if you take square root you obtain
exp(0b0.101)−−−−−−−−√=exp(0b0.0101)

It is a very strong cost-efficient method, but it requires from calculator to keep square roots tables and "often used" exponents.

Especially if you are allowed to have large enough exponentiation table with separate roots of high precision, you can achieve super strong results with this. Modern computers don't do it because they are using some Taylor series or variation of Taylor series, because they are "saving" memory for each call. Also they can be using generalized continued fractions like this https://en.wikipedia.org/wiki/Exponential_function#Continued_fractions_for_ex, but in my expirience GCFs more often a compromise between "table" approach and "series". Something in between. Not super speed.

PS. You can further accelerate it by good searching algo which will determine patterns in your binary number and re-use table ot exponents for those patterns. Typical patterns are 211,2101,2111,21111,211011 and so on. Also you can further accelerate it by using stronger approximations for starting iteration for your Newton root-finder, something based on GCFs like that
z√=x2+y−−−−−√=x+2x⋅y2(2z−y)−y−y22(2z−y)−y22(2z−y)−⋱
[let k:=2*(2*z-y) in sqrt(z)==sqrt(x**2+y) == x+2*x*y/(k-y -y**2/(k-y**2/(...)))]

This will be super efficient computation-wise if you prepare some tables of squares and re-use those every time for your initial GCF guess.

PPS. Note that binary search algo could be enhanced to not only look for additive patterns, but also for negating patterns. You can think of binary sequence like that 2.1011101=21−.0100010 minimizing required roots amount from 5 to 2.

Share
Cite
Follow
edited Jan 31, 2020 at 16:57
answered Jan 31, 2020 at 15:50
sanaris's user avatar
sanaris
24311 silver badge44 bronze badges
Add a comment
]]]
[[[
wget_U 'https://arxiv.org/pdf/2309.05601.pdf' -O '2309.05601-Convergence, Finiteness and Periodicity of Several New Algorithms of p-adic Continued Fractions(2023)(Zhaonan).pdf'
===
https://arxiv.org/abs/2309.05601
arXiv:2309.05601 (math)
[Submitted on 11 Sep 2023]
Convergence, Finiteness and Periodicity of Several New Algorithms of p-adic Continued Fractions
Zhaonan Wang, Yingpu Deng
Download PDF
p-adic continued fractions, as an extension of the classical concept of classical continued fractions to the realm of p-adic numbers, offering a novel perspective on number representation and approximation. While numerous p-adic continued fraction expansion algorithms have been proposed by the researchers, the establishment of several excellent properties, such as the Lagrange Theorem for classic continued fractions, which indicates that every quadratic irrationals can be expanded periodically, remains elusive. In this paper, we present several new algorithms that can be viewed as refinements of the existing p-adic continued fraction algorithms. We give an upper bound of the length of partial quotients when expanding rational numbers, and prove that for small primes p, our algorithm can generate periodic continued fraction expansions for all quadratic irrationals. As confirmed through experimentation, one of our algorithms can be viewed as the best p-adic algorithm available to date. Furthermore, we provide an approach to establish a p-adic continued fraction expansion algorithm that could generate periodic expansions for all quadratic irrationals in Qp for a given prime p.
]]]
[[[
wget_U 'https://arxiv.org/pdf/1108.3367.pdf' -O '1108.3367.v2-On the convergence acceleration of some continued fractions(2012)(Rafał).pdf'
===
https://arxiv.org/abs/1108.3367
arXiv:1108.3367 (math)
[Submitted on 16 Aug 2011 (v1), last revised 4 Mar 2012 (this version, v2)]
On the convergence acceleration of some continued fractions
Rafał Nowak
Download PDF
A well known method for convergence acceleration of continued fraction $\K(a_n/b_n)$ is to use the modified approximants Sn(ωn) in place of the classical approximants Sn(0), where ωn are close to tails f(n) of continued fraction. Recently, author proposed a method of iterative character producing tail approximations whose asymptotic expansion's accuracy is improving in each step. This method can be applied to continued fractions $\K(a_n/b_n)$, where an, bn are polynomials in n (°an=2, °bn≤1) for sufficiently large n. The purpose of this paper is to extend this idea for the class of continued fractions $\K(a_n/b_n + a_n'/b_n')$, where an, a′n, bn, b′n are polynomials in n (°an=°a′n,°bn=°b′n). We give examples involving such continued fraction expansions of some mathematical constants, as well as elementary and special functions.
]]]

[[[

wget_U 'https://projecteuclid.org/journals/tokyo-journal-of-mathematics/volume-33/issue-2/Convergence-Rate-for-a-Continued-Fraction-Expansion-Related-to-Fibonacci/10.3836/tjm/1296483483.pdf' -O 'Convergence-Rate-for-a-Continued-Fraction-Expansion-Related-to-Fibonacci-Type-Sequences(2010)(Gabriela).pdf'
===

projecteuclid.org
https://projecteuclid.org/journals/tokyo-journal-of-mathematics/...
[PDF]Convergence Rate for a Continued Fraction Expansion Related to…
invariant measure allows us to study the optimality of the convergence rate. Actually, we obtain upper and lower bounds of the convergence rate which provide a near-optimal solution to the Gauss-Kuzmin-Lévy problem. 1. Introduction Let x ∈[=0,1>]and let k be a ﬁxed integer greater than or equal to 2. Chan [3] proved that x can be written as ...

]]]

[[[
===
https://www.researchgate.net/publication/335997723_Generalized_continued_fractions_a_unified_definition_and_a_Pringsheim-type_convergence_criterion


Generalized continued fractions: a unified definition and a Pringsheim-type convergence criterion
September 2019Advances in Difference Equations 2019(1):406
DOI:10.1186/s13662-019-2340-9
LicenseCC BY
Authors:
Hendrik Baumann
Leibniz Universität Hannover
]]]

[[[
https://math.stackexchange.com/questions/2742752/continued-fraction-rate-of-convergence
===
bound_of_cf:
[A[i]/B[i] -A[i-1]/B[i-1] == (-1)**(i+1)/B[i]/B[i-1]]
[abs(A[+oo]/B[+oo] -A[i]/B[i]) < abs(A[i+1]/B[i+1] -A[i]/B[i])]
[abs(A[+oo]/B[+oo] -A[i]/B[i]) > abs(A[i+2]/B[i+2] -A[i]/B[i])]

]]]
[[[
https://handwiki.org/wiki/Generalized_continued_fraction
Rate_of_convergence Generalized_continued_fraction
===

[tan x == x/(1-x**2/(3-x**2/(5-x**2/(7-...))))]

partial numerators and denominators
equivalence transformation:
[n[i] :*= c[i]][d[i] :*= c[i]][n[i+1] :*= c[i]]

convergent === continued fraction approximation
continuants === numerator and denominator of convergent
recurrence
the fundamental recurrence formulas of successive convergents:
[A[i] == d[i]*A[i-1] +n[i]*A[i-2]]
[B[i] == d[i]*B[i-1] +n[i]*B[i-2]]
[A[-1] == 1]
[B[-1] == 0]
[A[0] == d[0]]
[B[0] == 1]
==>>:
[A[-2] == 0]
[B[-2] == 1]
[n[0] == 1]

determinant formula:
[A[i-1]*B[i] -A[i]*B[i-1] == II(-n[k]){k :<- [1..=i]}]
  # cf x = d[0]+n[1]/(d[1] +n[2]/(d[2] +...))
  # relate the numerators and denominators of successive convergents x[i-1],x[i]
===
===
===
===
===
===
===
===
===
===
===
===
https://handwiki.org/wiki/Generalized_continued_fraction
===
wget_U 'https://handwiki.org/wiki/Generalized_continued_fraction' -O 'generalized_continued_fraction.handwiki.html'
wget_U 'https://handwiki.org/wiki/Euler%27s_continued_fraction_formula' -O 'Euler_continued_fraction_formula.handwiki.html'
xxx wget_U 'https://www.sciencedirect.com/science/article/pii/S0022314X10000193/pdfft?md5=36d08f2233a097cfd00962fe07a7378a&pid=1-s2.0-S0022314X10000193-main.pdf' -O 'A family of continued fractions(2010)(Angell).pdf'
  不行，sciencedirect很狗



wget_U 'https://core.ac.uk/download/pdf/82267532.pdf' -O 'A family of continued fractions(2010)(Angell).pdf'
CORE
https://core.ac.uk/download/pdf/82267532.pdf
[PDF]A family of continued fractions - CORE
2010 Elsevier Inc. All rights reserved. We shall require the ak and bk to be integers, all strictly positive except possibly for a0. In fact, the continued fractions under consideration in the present paper will always have a0 0. If each bk is 1 = the expression is referred to as a simple continued fraction.

===
[[
Sardina, Manny (2007). "General Method for Extracting Roots using (Folded) Continued Fractions". Surrey (UK). http://myreckonings.com/Dead_Reckoning/Online/Materials/General%20Method%20for%20Extracting%20Roots.pdf.
  good
===

wget_U 'http://myreckonings.com/Dead_Reckoning/Online/Materials/General%20Method%20for%20Extracting%20Roots.pdf' -O 'General Method for Extracting Roots using (Folded) Continued Fractions(2007)(Sardina).pdf'
  fail
curl_ -O 'General Method for Extracting Roots using (Folded) Continued Fractions(2007)(Sardina).pdf' 'http://myreckonings.com/Dead_Reckoning/Online/Materials/General%20Method%20for%20Extracting%20Roots.pdf'
  fail

wget_U 'https://studylib.net/doc/7979641/general-method-for-extracting-roots-using--folded' -O 'xxx.html'
  fail
<iframe class="viewerX-iframe" src="/viewer_next/web/study?file=%2F%2Fs3p.studylib.net%2Fstore%2Fdata%2F007979641.pdf%3Fk%3DEwAAAYqPOP0VAAACWCQJiVoMYQ-5F4R-t-vVCW4E66Z_aQnr1gOB-0KCfW-c&img=%2F%2Fs3.studylib.net%2Fstore%2Fdata%2F007979641_1-f18ac76b04f96532078efbd0027aebf6.png" frameborder="0" scrolling="no" allowfullscreen></iframe>
%2F%2Fs3p.studylib.net%2Fstore%2Fdata%2F007979641.pdf%3Fk%3DEwAAAYqPOP0VAAACWCQJiVoMYQ-5F4R-t-vVCW4E66Z_aQnr1gOB-0KCfW-c
//s3p.studylib.net/store/data/007979641.pdf?k=EwAAAYqPOP0VAAACWCQJiVoMYQ-5F4R-t-vVCW4E66Z_aQnr1gOB-0KCfW-c
https://s3p.studylib.net/store/data/007979641.pdf?k=EwAAAYqPOP0VAAACWCQJiVoMYQ-5F4R-t-vVCW4E66Z_aQnr1gOB-0KCfW-c
wget_U 'https://s3p.studylib.net/store/data/007979641.pdf?k=EwAAAYqPOP0VAAACWCQJiVoMYQ-5F4R-t-vVCW4E66Z_aQnr1gOB-0KCfW-c' -O 'General Method for Extracting Roots using (Folded) Continued Fractions(2007)(Sardina).pdf' --refer 'https://studylib.net/doc/7979641/general-method-for-extracting-roots-using--folded'
  ok!!
]]

===
===

该论文 提到 quotient-difference algorithm，用于将 麦克劳林展开式(无限长)/有理分式 转化为 连分式(部分分子为z，部分分母为实数)。
  截取 连分式 前n项，则 该有限连分式 展开后 前n项与 原多项式 相同，多了一些高阶项误差
wget_u 'https://ttu-ir.tdl.org/bitstream/handle/2346/20231/31295015507519.pdf?sequence=1' -o 'continued fractions and their application in the computation of definite riemann integrals(1973)(stanley)(tdl).pdf'
  good!!

ttu dspace repository
https://ttu-ir.tdl.org/.../2346/20231/31295015507519.pdf?sequence=1
[pdf]continued fractions and their application - tdl
mathematics, the subject of continued fractions plays an extensive, if not vital, role in analytic theory as well as arithmetic theory. powerful applications involving the use of continued fractions exist with respect to the theory of equations, orthogonal polynomials, power series, infinite matrices and quadratic forms in infinitely many
===
===
wget_U 'https://web.williams.edu/Mathematics/sjmiller/public_html/book/papers/vdp/PoortenShallit_FoldedContFrac.pdf' -O 'FOLDED CONTINUED FRACTIONS(after1989)(Poorten).pdf'
  失败，但通过浏览器下载成功

Williams College
https://web.williams.edu/.../vdp/PoortenShallit_FoldedContFrac.pdf
[PDF]FOLDED CONTINUED FRACTIONS - Williams College
6 AlfvanderPoortenandJeﬀreyShallit 4. Afoldedcontinuedfraction Theorem1. Let a be a binary decimal a =0.a 1a 2a 3..., set a 0 =0and denote by F a the formal series ...
===
===
===
===
Euler's continued fraction formula
https://handwiki.org/wiki/Euler%27s_continued_fraction_formula

[lhs == a0 +a0*a1 +a0*a1*a2 +a0*...*an == a0/(1- a1/(1+a1- a2/(1+a2- ...(an/(1+an)))))]
[a[i] := u[i]/u[i+1]][u0 == 1]:
  ...
[a[i] := x**([i=!=0])/u[i]]:
  ...
  #Taylor series
  [u[i] := 1 if i==0 else i][e**x == lhs{[a[i] := x**([i=!=0])/u[i]]}]
  [e**x == sum x**i/i! {i :<- [0..]}]
  [ln(1+x) == sum -(-x)**i/i {i :<- [1..]}]
  [arctan(x/y) == ?]
  [arctan(x/y) == (xy)/yy _+ sum<_+> ((2k+1)*xy)**2 / (2yy+(2k+1)*(yy-xx)) {k :<- [0..]}]
  [arctan(x/y) == x/y _+ sum<_+> ((k+1)*x)**2 / ((3+2k)*y) {k :<- [0..]}]
  arctan Taylor series
  [arctan(x) == 1 -x**3/3 +x**5/5 ...]

  [exp(x/y) == 1 + 2x/(2y-x) _+ sum<_+> (x**2) / ((6+4k)*y) {k :<- [0..]}]
  [ln(1+x/y) == 0 + x/y _+ sum<_+> ((k//2 +1)*x) / (2 if k%2==1 else (k+1)*y) {k :<- [0..]}]

===
[pi/4 == 1/(1+1**2/(3+2**2/(5+3**2/(7+...))))]
[ln2 == 0 + 1/1 _+ 1/2 _+ 1/3 _+ 2/2 _+ 2/5 _+ 3/2 _+ ...]
[ln2 == cf[0; 1,2,3,1,5,2/3,7,...,2k-1,2/k,...]]
===
===
===
===
===
===
===
===
Generalized continued fraction
From HandWiki

In complex analysis, a branch of mathematics, a generalized continued fraction is a generalization of regular continued fractions in canonical form, in which the partial numerators and partial denominators can assume arbitrary complex values. A generalized continued fraction is an expression of the form

[math]\displaystyle{ x = b_0 + \cfrac{a_1}{b_1 + \cfrac{a_2}{b_2 + \cfrac{a_3}{b_3 + \cfrac{a_4}{b_4 + \ddots\,}}}} }[/math]
where the an (n > 0) are the partial numerators, the bn are the partial denominators, and the leading term b0 is called the integer part of the continued fraction.

The successive convergents of the continued fraction are formed by applying the fundamental recurrence formulas:

[math]\displaystyle{ \begin{align} x_0 &= \frac{A_0}{B_0} = b_0, \\[4px] x_1 &= \frac{A_1}{B_1} = \frac{b_1b_0+a_1}{b_1}, \\[4px] x_2 &= \frac{A_2}{B_2} = \frac{b_2(b_1b_0+a_1) + a_2b_0}{b_2b_1 + a_2},\ \dots \end{align} }[/math]
where An is the numerator and Bn is the denominator, called continuants,[1][2] of the nth convergent. They are given by the recursion [3]

[math]\displaystyle{ \begin{align} A_n &= b_n A_{n-1} + a_n A_{n-2}, \\ B_n &= b_n B_{n-1} + a_n B_{n-2} \qquad \text{for } n \ge 1 \end{align} }[/math]
with initial values

[math]\displaystyle{ \begin{align} A_{-1} &= 1,& A_0&=b_0,\\ B_{-1}&=0, & B_0&=1. \end{align} }[/math]
If the sequence of convergents {xn} approaches a limit the continued fraction is convergent and has a definite value. If the sequence of convergents never approaches a limit the continued fraction is divergent. It may diverge by oscillation (for example, the odd and even convergents may approach two different limits), or it may produce an infinite number of zero denominators Bn.

Contents
1 History
2 Notation
3 Some elementary considerations
3.1 Partial numerators and denominators
3.2 The determinant formula
3.3 The equivalence transformation
3.4 Notions of convergence
3.5 Even and odd convergents
3.6 Conditions for irrationality
3.7 Fundamental recurrence formulas
4 Linear fractional transformations
4.1 The continued fraction as a composition of LFTs
4.2 A geometric interpretation
5 Euler's continued fraction formula
6 Examples
6.1 Transcendental functions and numbers
6.1.1 π
6.2 Roots of positive numbers
6.2.1 Example 1
6.2.2 Example 2
6.2.3 Example 3
6.2.4 Example 4
7 Higher dimensions
8 See also
9 Notes
10 References
11 External links
History
The story of continued fractions begins with the Euclidean algorithm,[4] a procedure for finding the greatest common divisor of two natural numbers m and n. That algorithm introduced the idea of dividing to extract a new remainder – and then dividing by the new remainder repeatedly.

Nearly two thousand years passed before (Bombelli 1579) devised a technique for approximating the roots of quadratic equations with continued fractions in the mid-sixteenth century. Now the pace of development quickened. Just 24 years later, in 1613, Pietro Cataldi introduced the first formal notation for the generalized continued fraction.[5] Cataldi represented a continued fraction as

[math]\displaystyle{ {a_0\cdot} \,\&\, \frac{n_1}{d_1\cdot} \,\&\, \frac{n_2}{d_2\cdot} \,\&\, \frac{n_3}{d_3} }[/math]
with the dots indicating where the next fraction goes, and each & representing a modern plus sign.

Late in the seventeenth century John Wallis introduced the term "continued fraction" into mathematical literature.[6] New techniques for mathematical analysis (Newton's and Leibniz's calculus) had recently come onto the scene, and a generation of Wallis' contemporaries put the new phrase to use.

In 1748 Euler published a theorem showing that a particular kind of continued fraction is equivalent to a certain very general infinite series.[7] Euler's continued fraction formula is still the basis of many modern proofs of convergence of continued fractions.

In 1761, Johann Heinrich Lambert gave the first proof that π is irrational, by using the following continued fraction for tan x:[8]

[math]\displaystyle{ \tan(x) = \cfrac{x}{1 + \cfrac{-x^2}{3 + \cfrac{-x^2}{5 + \cfrac{-x^2}{7 + {}\ddots}}}} }[/math]
Continued fractions can also be applied to problems in number theory, and are especially useful in the study of Diophantine equations. In the late eighteenth century Lagrange used continued fractions to construct the general solution of Pell's equation, thus answering a question that had fascinated mathematicians for more than a thousand years.[9] Amazingly, Lagrange's discovery implies that the canonical continued fraction expansion of the square root of every non-square integer is periodic and that, if the period is of length p > 1, it contains a palindromic string of length p − 1.

In 1813 Gauss derived from complex-valued hypergeometric functions what is now called Gauss's continued fractions.[10] They can be used to express many elementary functions and some more advanced functions (such as the Bessel functions), as continued fractions that are rapidly convergent almost everywhere in the complex plane.

Notation
The long continued fraction expression displayed in the introduction is easy for an unfamiliar reader to interpret. However, it takes up a lot of space and can be difficult to typeset. So mathematicians have devised several alternative notations. One convenient way to express a generalized continued fraction sets each nested fraction on the same line, indicating the nesting by dangling plus signs in the denominators:

[math]\displaystyle{ x = b_0+ \frac{a_1}{b_1+}\, \frac{a_2}{b_2+}\, \frac{a_3}{b_3+}\cdots }[/math]
Sometimes the plus signs are typeset to vertically align with the denominators but not under the fraction bars:

[math]\displaystyle{ x = b_0 + \frac{a_1}{b_1}{{}\atop+} \frac{a_2}{b_2}{{}\atop+} \frac{a_3}{b_3}{{}\atop+\cdots} }[/math]
Pringsheim wrote a generalized continued fraction this way:

[math]\displaystyle{ x = b_0 + \frac{a_1 \mid}{\mid b_1} + \frac{a_2 \mid}{\mid b_2} + \frac{a_3 \mid}{\mid b_3}+\cdots.\, }[/math]
Carl Friedrich Gauss evoked the more familiar infinite product Π when he devised this notation:

[math]\displaystyle{ x = b_0 + \underset{i=1}\overset{\infty}\operatorname{K} \frac{a_i}{b_i}.\, }[/math]
Here the "K" stands for Kettenbruch, the German word for "continued fraction". This is probably the most compact and convenient way to express continued fractions; however, it is not widely used by English typesetters.

Some elementary considerations
Here are some elementary results that are of fundamental importance in the further development of the analytic theory of continued fractions.

Partial numerators and denominators
If one of the partial numerators an + 1 is zero, the infinite continued fraction

[math]\displaystyle{ b_0 + \underset{i=1}\overset{\infty}\operatorname{K} \frac{a_i}{b_i}\, }[/math]
is really just a finite continued fraction with n fractional terms, and therefore a rational function of a1 to an and b0 to bn + 1. Such an object is of little interest from the point of view adopted in mathematical analysis, so it is usually assumed that all ai ≠ 0. There is no need to place this restriction on the partial denominators bi.

The determinant formula
When the nth convergent of a continued fraction

[math]\displaystyle{ x_n = b_0 + \underset{i=1}\overset{n}\operatorname{K} \frac{a_i}{b_i}\, }[/math]
is expressed as a simple fraction xn = 
An
/
Bn
 we can use the determinant formula

[math]\displaystyle{ A_{n-1}B_n - A_nB_{n-1} = \left(-1\right)^na_1a_2\cdots a_n = \prod_{i=1}^n (-a_i) }[/math]

 

 

 

 

(1)

to relate the numerators and denominators of successive convergents xn and xn − 1 to one another. The proof for this can be easily seen by induction.

Base case

The case n = 1 results from a very simple computation.
Inductive step

Assume that (1) holds for n − 1. Then we need to see the same relation holding true for n. Substituting the value of An and Bn in (1) we obtain:
[math]\displaystyle{ \begin{align} &=b_n A_{n-1} B_{n-1} + a_n A_{n-1} B_{n-2} - b_n A_{n-1} B_{n-1} - a_n A_{n-2} B_{n-1} \\ &=a_n(A_{n-1}B_{n-2} - A_{n-2} B_{n-1}) \end{align} }[/math]
which is true because of our induction hypothesis.
[math]\displaystyle{ A_{n-1}B_n - A_nB_{n-1} = \left(-1\right)^na_1a_2\cdots a_n = \prod_{i=1}^n (-a_i)\, }[/math]
Specifically, if neither Bn nor Bn − 1 is zero (n > 0) we can express the difference between the (n − 1)th and nth convergents like this:
[math]\displaystyle{ x_{n-1} - x_n = \frac{A_{n-1}}{B_{n-1}} - \frac{A_n}{B_n} = \left(-1\right)^n \frac{a_1a_2\cdots a_n}{B_nB_{n-1}} = \frac{\prod_{i=1}^n (-a_i)}{B_nB_{n-1}}.\, }[/math]
The equivalence transformation
If {ci} = {c1, c2, c3, ...} is any infinite sequence of non-zero complex numbers we can prove, by induction, that

[math]\displaystyle{ b_0 + \cfrac{a_1}{b_1 + \cfrac{a_2}{b_2 + \cfrac{a_3}{b_3 + \cfrac{a_4}{b_4 + \ddots\,}}}} = b_0 + \cfrac{c_1a_1}{c_1b_1 + \cfrac{c_1c_2a_2}{c_2b_2 + \cfrac{c_2c_3a_3}{c_3b_3 + \cfrac{c_3c_4a_4}{c_4b_4 + \ddots\,}}}} }[/math]
where equality is understood as equivalence, which is to say that the successive convergents of the continued fraction on the left are exactly the same as the convergents of the fraction on the right.

The equivalence transformation is perfectly general, but two particular cases deserve special mention. First, if none of the ai are zero a sequence {ci} can be chosen to make each partial numerator a 1:

[math]\displaystyle{ b_0 + \underset{i=1}\overset{\infty}\operatorname{K} \frac{a_i}{b_i} = b_0 + \underset{i=1}\overset{\infty}\operatorname{K} \frac{1}{c_i b_i}\, }[/math]
where c1 = 
1
/
a1
, c2 = 
a1
/
a2
, c3 = 
a2
/
a1a3
, and in general cn + 1 = 
1
/
an + 1cn
.

Second, if none of the partial denominators bi are zero we can use a similar procedure to choose another sequence {di} to make each partial denominator a 1:

[math]\displaystyle{ b_0 + \underset{i=1}\overset{\infty}\operatorname{K} \frac{a_i}{b_i} = b_0 + \underset{i=1}\overset{\infty}\operatorname{K} \frac{d_i a_i}{1}\, }[/math]
where d1 = 
1
/
b1
 and otherwise dn + 1 = 
1
/
bnbn + 1
.

These two special cases of the equivalence transformation are enormously useful when the general convergence problem is analyzed.

Notions of convergence
As mentioned in the introduction, the continued fraction

[math]\displaystyle{ x = b_0 + \underset{i=1}\overset{\infty}\operatorname{K} \frac{a_i}{b_i}\, }[/math]
converges if the sequence of convergents {xn} tends to a finite limit. This notion of convergence is very natural, but it is sometimes too restrictive. It is therefore useful to introduce the notion of general convergence of a continued fraction. Roughly speaking, this consists in replacing the [math]\displaystyle{ \operatorname{K}_{i = n}^\infty \tfrac{a_i}{b_i} }[/math] part of the fraction by wn, instead of by 0, to compute the convergents. The convergents thus obtained are called modified convergents. We say that the continued fraction converges generally if there exists a sequence [math]\displaystyle{ \{w_n^*\} }[/math] such that the sequence of modified convergents converges for all [math]\displaystyle{ \{w_n\} }[/math] sufficiently distinct from [math]\displaystyle{ \{w_n^*\} }[/math]. The sequence [math]\displaystyle{ \{w_n^*\} }[/math] is then called an exceptional sequence for the continued fraction. See Chapter 2 of (Lorentzen Waadeland) for a rigorous definition.

There also exists a notion of absolute convergence for continued fractions, which is based on the notion of absolute convergence of a series: a continued fraction is said to be absolutely convergent when the series

[math]\displaystyle{ f = \sum_n \left( f_n - f_{n-1}\right), }[/math]
where [math]\displaystyle{ f_n = \operatorname{K}_{i = 1}^n \tfrac{a_i}{b_i} }[/math] are the convergents of the continued fraction, converges absolutely.[11] The Śleszyński–Pringsheim theorem provides a sufficient condition for absolute convergence.

Finally, a continued fraction of one or more complex variables is uniformly convergent in an open neighborhood Ω when its convergents converge uniformly on Ω; that is, when for every ε > 0 there exists M such that for all n > M, for all [math]\displaystyle{ z \in \Omega }[/math],

[math]\displaystyle{ |f(z) - f_n(z)| \lt \varepsilon. }[/math]
Even and odd convergents
It is sometimes necessary to separate a continued fraction into its even and odd parts. For example, if the continued fraction diverges by oscillation between two distinct limit points p and q, then the sequence {x0, x2, x4, ...} must converge to one of these, and {x1, x3, x5, ...} must converge to the other. In such a situation it may be convenient to express the original continued fraction as two different continued fractions, one of them converging to p, and the other converging to q.

The formulas for the even and odd parts of a continued fraction can be written most compactly if the fraction has already been transformed so that all its partial denominators are unity. Specifically, if

[math]\displaystyle{ x = \underset{i=1}\overset{\infty}\operatorname{K} \frac{a_i}{1}\, }[/math]
is a continued fraction, then the even part xeven and the odd part xodd are given by

[math]\displaystyle{ x_\text{even} = \cfrac{a_1}{1+a_2-\cfrac{a_2a_3} {1+a_3+a_4-\cfrac{a_4a_5} {1+a_5+a_6-\cfrac{a_6a_7} {1+a_7+a_8-\ddots}}}}\, }[/math]
and

[math]\displaystyle{ x_\text{odd} = a_1 - \cfrac{a_1a_2}{1+a_2+a_3-\cfrac{a_3a_4} {1+a_4+a_5-\cfrac{a_5a_6} {1+a_6+a_7-\cfrac{a_7a_8} {1+a_8+a_9-\ddots}}}}\, }[/math]
respectively. More precisely, if the successive convergents of the continued fraction x are {x1, x2, x3, ...}, then the successive convergents of xeven as written above are {x2, x4, x6, ...}, and the successive convergents of xodd are {x1, x3, x5, ...}.[12]

Conditions for irrationality
If a1, a2,... and b1, b2,... are positive integers with ak ≤ bk for all sufficiently large k, then

[math]\displaystyle{ x = b_0 + \underset{i=1}\overset{\infty}\operatorname{K} \frac{a_i}{b_i}\, }[/math]
converges to an irrational limit.[13]

Fundamental recurrence formulas
The partial numerators and denominators of the fraction's successive convergents are related by the fundamental recurrence formulas:

[math]\displaystyle{ \begin{align} A_{-1}& = 1& B_{-1}& = 0\\ A_0& = b_0& B_0& = 1\\ A_{n+1}& = b_{n+1} A_n + a_{n+1} A_{n-1}& B_{n+1}& = b_{n+1} B_n + a_{n+1} B_{n-1}\, \end{align} }[/math]
The continued fraction's successive convergents are then given by

[math]\displaystyle{ x_n=\frac{A_n}{B_n}.\, }[/math]
These recurrence relations are due to John Wallis (1616–1703) and Leonhard Euler (1707–1783).[14]

As an example, consider the regular continued fraction in canonical form that represents the golden ratio φ:

[math]\displaystyle{ x = 1 + \cfrac{1}{1 + \cfrac{1}{1 + \cfrac{1}{1 + \cfrac{1}{1 + \ddots\,}}}} }[/math]
Applying the fundamental recurrence formulas we find that the successive numerators An are {1, 2, 3, 5, 8, 13, ...} and the successive denominators Bn are {1, 1, 2, 3, 5, 8, ...}, the Fibonacci numbers. Since all the partial numerators in this example are equal to one, the determinant formula assures us that the absolute value of the difference between successive convergents approaches zero quite rapidly.

Linear fractional transformations
A linear fractional transformation (LFT) is a complex function of the form

[math]\displaystyle{ w = f(z) = \frac{a + bz}{c + dz},\, }[/math]
where z is a complex variable, and a, b, c, d are arbitrary complex constants such that c + dz ≠ 0. An additional restriction that ad ≠ bc is customarily imposed, to rule out the cases in which w = f(z) is a constant. The linear fractional transformation, also known as a Möbius transformation, has many fascinating properties. Four of these are of primary importance in developing the analytic theory of continued fractions.

If d ≠ 0 the LFT has one or two fixed points. This can be seen by considering the equation
[math]\displaystyle{ f(z) = z \Rightarrow dz^2 + cz = a + bz\, }[/math]
which is clearly a quadratic equation in z. The roots of this equation are the fixed points of f(z). If the discriminant (c − b)2 + 4ad is zero the LFT fixes a single point; otherwise it has two fixed points.
If ad ≠ bc the LFT is an invertible conformal mapping of the extended complex plane onto itself. In other words, this LFT has an inverse function
[math]\displaystyle{ z = g(w) = \frac{-a + cw}{b - dw}\, }[/math]
such that f(g(z)) = g(f(z)) = z for every point z in the extended complex plane, and both f and g preserve angles and shapes at vanishingly small scales. From the form of z = g(w) we see that g is also an LFT.
The composition of two different LFTs for which ad ≠ bc is itself an LFT for which ad ≠ bc. In other words, the set of all LFTs for which ad ≠ bc is closed under composition of functions. The collection of all such LFTs, together with the "group operation" composition of functions, is known as the automorphism group of the extended complex plane.
If b = 0 the LFT reduces to
[math]\displaystyle{ w = f(z) = \frac{a}{c + dz},\, }[/math]
which is a very simple meromorphic function of z with one simple pole (at −
c
/
d
) and a residue equal to 
a
/
d
. (See also Laurent series.)
The continued fraction as a composition of LFTs
Consider a sequence of simple linear fractional transformations

[math]\displaystyle{ \begin{align} \tau_0(z) &= b_0 + z, \\[4px] \tau_1(z) &= \frac{a_1}{b_1 + z}, \\[4px] \tau_2(z) &= \frac{a_2}{b_2 + z},\\[4px] \tau_3(z) &= \frac{a_3}{b_3 + z},\\&\;\vdots \end{align} }[/math]
Here we use τ to represent each simple LFT, and we adopt the conventional circle notation for composition of functions. We also introduce a new symbol Τn to represent the composition of n + 1 transformations τi; that is,

[math]\displaystyle{ \begin{align} \boldsymbol{\Tau}_\boldsymbol{1}(z) &= \tau_0\circ\tau_1(z) = \tau_0\big(\tau_1(z)\big),\\ \boldsymbol{\Tau}_\boldsymbol{2}(z) &= \tau_0\circ\tau_1\circ\tau_2(z) = \tau_0\Big(\tau_1\big(\tau_2(z)\big)\Big),\, \end{align} }[/math]
and so forth. By direct substitution from the first set of expressions into the second we see that

[math]\displaystyle{ \begin{align} \boldsymbol{\Tau}_\boldsymbol{1}(z)& = \tau_0\circ\tau_1(z)& =&\quad b_0 + \cfrac{a_1}{b_1 + z}\\[4px] \boldsymbol{\Tau}_\boldsymbol{2}(z)& = \tau_0\circ\tau_1\circ\tau_2(z)& =&\quad b_0 + \cfrac{a_1}{b_1 + \cfrac{a_2}{b_2 + z}}\, \end{align} }[/math]
and, in general,

[math]\displaystyle{ \boldsymbol{\Tau}_\boldsymbol{n}(z) = \tau_0\circ\tau_1\circ\tau_2\circ\cdots\circ\tau_n(z) = b_0 + \underset{i=1}\overset{n}\operatorname{K} \frac{a_i}{b_i}\, }[/math]
where the last partial denominator in the finite continued fraction K is understood to be bn + z. And, since bn + 0 = bn, the image of the point z = 0 under the iterated LFT Τn is indeed the value of the finite continued fraction with n partial numerators:

[math]\displaystyle{ \boldsymbol{\Tau}_\boldsymbol{n}(0) = \boldsymbol{\Tau}_\boldsymbol{n+1}(\infty) = b_0 + \underset{i=1}\overset{n}\operatorname{K} \frac{a_i}{b_i}.\, }[/math]
A geometric interpretation
Defining a finite continued fraction as the image of a point under the iterated linear functional transformation Τn(z) leads to an intuitively appealing geometric interpretation of infinite continued fractions.

The relationship

[math]\displaystyle{ x_n = b_0 + \underset{i=1}\overset{n}\operatorname{K} \frac{a_i}{b_i} = \frac{A_n}{B_n} = \boldsymbol{\Tau}_{\boldsymbol{n}}(0) = \boldsymbol{\Tau}_{\boldsymbol{n+1}}(\infty)\, }[/math]
can be understood by rewriting Τn(z) and Τn + 1(z) in terms of the fundamental recurrence formulas:

[math]\displaystyle{ \begin{align} \boldsymbol{\Tau}_{\boldsymbol{n}}(z)& = \frac{(b_n+z)A_{n-1} + a_nA_{n-2}}{(b_n+z)B_{n-1} + a_nB_{n-2}}& \boldsymbol{\Tau}_{\boldsymbol{n}}(z)& = \frac{zA_{n-1} + A_n}{zB_{n-1} + B_n};\\[6px] \boldsymbol{\Tau}_{\boldsymbol{n+1}}(z)& = \frac{(b_{n+1}+z)A_n + a_{n+1}A_{n-1}}{(b_{n+1}+z)B_n + a_{n+1}B_{n-1}}& \boldsymbol{\Tau}_{\boldsymbol{n+1}}(z)& = \frac{zA_n + A_{n+1}} {zB_n + B_{n+1}}.\, \end{align} }[/math]
In the first of these equations the ratio tends toward 
An
/
Bn
 as z tends toward zero. In the second, the ratio tends toward 
An
/
Bn
 as z tends to infinity. This leads us to our first geometric interpretation. If the continued fraction converges, the successive convergents 
An
/
Bn
 are eventually arbitrarily close together. Since the linear fractional transformation Τn(z) is a continuous mapping, there must be a neighborhood of z = 0 that is mapped into an arbitrarily small neighborhood of Τn(0) = 
An
/
Bn
. Similarly, there must be a neighborhood of the point at infinity which is mapped into an arbitrarily small neighborhood of Τn(∞) = 
An − 1
/
Bn − 1
. So if the continued fraction converges the transformation Τn(z) maps both very small z and very large z into an arbitrarily small neighborhood of x, the value of the continued fraction, as n gets larger and larger.

For intermediate values of z, since the successive convergents are getting closer together we must have

[math]\displaystyle{ \frac{A_{n-1}}{B_{n-1}} \approx \frac{A_n}{B_n} \quad\Rightarrow\quad \frac{A_{n-1}}{A_n} \approx \frac{B_{n-1}}{B_n} = k\, }[/math]
where k is a constant, introduced for convenience. But then, by substituting in the expression for Τn(z) we obtain

[math]\displaystyle{ \boldsymbol{\Tau}_{\boldsymbol{n}}(z) = \frac{zA_{n-1} + A_n}{zB_{n-1} + B_n} = \frac{A_n}{B_n} \left(\frac{z\frac{A_{n-1}}{A_n} + 1}{z\frac{B_{n-1}}{B_n} + 1}\right) \approx \frac{A_n}{B_n} \left(\frac{zk + 1}{zk + 1}\right) = \frac{A_n}{B_n}\, }[/math]
so that even the intermediate values of z (except when z ≈ −k−1) are mapped into an arbitrarily small neighborhood of x, the value of the continued fraction, as n gets larger and larger. Intuitively, it is almost as if the convergent continued fraction maps the entire extended complex plane into a single point.[15]

Notice that the sequence {Τn} lies within the automorphism group of the extended complex plane, since each Τn is a linear fractional transformation for which ab ≠ cd. And every member of that automorphism group maps the extended complex plane into itself: not one of the Τn can possibly map the plane into a single point. Yet in the limit the sequence {Τn} defines an infinite continued fraction which (if it converges) represents a single point in the complex plane.

When an infinite continued fraction converges, the corresponding sequence {Τn} of LFTs "focuses" the plane in the direction of x, the value of the continued fraction. At each stage of the process a larger and larger region of the plane is mapped into a neighborhood of x, and the smaller and smaller region of the plane that's left over is stretched out ever more thinly to cover everything outside that neighborhood.[16]

For divergent continued fractions, we can distinguish three cases:

The two sequences {Τ2n − 1} and {Τ2n} might themselves define two convergent continued fractions that have two different values, xodd and xeven. In this case the continued fraction defined by the sequence {Τn} diverges by oscillation between two distinct limit points. And in fact this idea can be generalized: sequences {Τn} can be constructed that oscillate among three, or four, or indeed any number of limit points. Interesting instances of this case arise when the sequence {Τn} constitutes a subgroup of finite order within the group of automorphisms over the extended complex plane.
The sequence {Τn} may produce an infinite number of zero denominators Bi while also producing a subsequence of finite convergents. These finite convergents may not repeat themselves or fall into a recognizable oscillating pattern. Or they may converge to a finite limit, or even oscillate among multiple finite limits. No matter how the finite convergents behave, the continued fraction defined by the sequence {Τn} diverges by oscillation with the point at infinity in this case.[17]
The sequence {Τn} may produce no more than a finite number of zero denominators Bi. while the subsequence of finite convergents dances wildly around the plane in a pattern that never repeats itself and never approaches any finite limit either.
Interesting examples of cases 1 and 3 can be constructed by studying the simple continued fraction

[math]\displaystyle{ x = 1 + \cfrac{z}{1 + \cfrac{z}{1 + \cfrac{z}{1 + \cfrac{z}{1 + \ddots}}}}\, }[/math]
where z is any real number such that z < −
1
/
4
.[18]

Euler's continued fraction formula
Main page: Euler's continued fraction formula
Euler proved the following identity:[7]

[math]\displaystyle{ a_0 + a_0a_1 + a_0a_1a_2 + \cdots + a_0a_1a_2\cdots a_n = \frac{a_0}{1-} \frac{a_1}{1+a_1-} \frac{a_2}{1+a_2-}\cdots \frac{a_{n}}{1+a_n}.\, }[/math]
From this many other results can be derived, such as

[math]\displaystyle{ \frac{1}{u_1}+ \frac{1}{u_2}+ \frac{1}{u_3}+ \cdots+ \frac{1}{u_n} = \frac{1}{u_1-} \frac{u_1^2}{u_1+u_2-} \frac{u_2^2}{u_2+u_3-}\cdots \frac{u_{n-1}^2}{u_{n-1}+u_n},\, }[/math]
and

[math]\displaystyle{ \frac{1}{a_0} + \frac{x}{a_0a_1} + \frac{x^2}{a_0a_1a_2} + \cdots + \frac{x^n}{a_0a_1a_2 \ldots a_n} = \frac{1}{a_0-} \frac{a_0x}{a_1+x-} \frac{a_1x}{a_2+x-}\cdots \frac{a_{n-1}x}{a_n+x}.\, }[/math]
Euler's formula connecting continued fractions and series is the motivation for the fundamental inequalities[link or clarification needed], and also the basis of elementary approaches to the convergence problem.

Examples
Transcendental functions and numbers
Here are two continued fractions that can be built via Euler's identity.

[math]\displaystyle{ e^x = \frac{x^0}{0!} + \frac{x^1}{1!} + \frac{x^2}{2!} + \frac{x^3}{3!} + \frac{x^4}{4!} + \cdots = 1+\cfrac{x} {1-\cfrac{1x} {2+x-\cfrac{2x} {3+x-\cfrac{3x} {4+x-\ddots}}}} }[/math]
[math]\displaystyle{ \log(1+x) = \frac{x^1}{1} - \frac{x^2}{2} + \frac{x^3}{3} - \frac{x^4}{4} + \cdots =\cfrac{x} {1-0x+\cfrac{1^2x} {2-1x+\cfrac{2^2x} {3-2x+\cfrac{3^2x} {4-3x+\ddots}}}} }[/math]
Here are additional generalized continued fractions:

[math]\displaystyle{ \arctan\cfrac{x}{y}=\cfrac{xy} {1y^2+\cfrac{(1xy)^2} {3y^2-1x^2+\cfrac{(3xy)^2} {5y^2-3x^2+\cfrac{(5xy)^2} {7y^2-5x^2+\ddots}}}} =\cfrac{x} {1y+\cfrac{(1x)^2} {3y+\cfrac{(2x)^2} {5y+\cfrac{(3x)^2} {7y+\ddots}}}} }[/math]
[math]\displaystyle{ e^\frac{x}{y} = 1+\cfrac{2x} {2y-x+\cfrac{x^2} {6y+\cfrac{x^2} {10y+\cfrac{x^2} {14y+\cfrac{x^2} {18y+\ddots}}}}} \quad\Rightarrow\quad e^2 = 7+\cfrac{2} {5+\cfrac{1} {7+\cfrac{1} {9+\cfrac{1} {11+\ddots}}}} }[/math]
[math]\displaystyle{ \log \left( 1+\frac{x}{y} \right) = \cfrac{x} {y+\cfrac{1x} {2+\cfrac{1x} {3y+\cfrac{2x} {2+\cfrac{2x} {5y+\cfrac{3x} {2+\ddots}}}}}} = \cfrac{2x} {2y+x-\cfrac{(1x)^2} {3(2y+x)-\cfrac{(2x)^2} {5(2y+x)-\cfrac{(3x)^2} {7(2y+x)-\ddots}}}} }[/math]
This last is based on an algorithm derived by Aleksei Nikolaevich Khovansky in the 1970s.[19]

Example: the natural logarithm of 2 (= [0; 1, 2, 3, 1, 5, 
2
/
3
, 7, 
1
/
2
, 9, 
2
/
5
,..., 2k − 1, 
2
/
k
,...] ≈ 0.693147...):[20]

[math]\displaystyle{ \log 2 = \log (1+1) = \cfrac{1} {1+\cfrac{1} {2+\cfrac{1} {3+\cfrac{2} {2+\cfrac{2} {5+\cfrac{3} {2+\ddots}}}}}} = \cfrac{2} {3-\cfrac{1^2} {9-\cfrac{2^2} {15-\cfrac{3^2} {21-\ddots}}}} }[/math]
π
Here are three of π's best-known generalized continued fractions, the first and third of which are derived from their respective arctangent formulas above by setting x = y = 1 and multiplying by 4. The Leibniz formula for π:

[math]\displaystyle{ \pi = \cfrac{4} {1+\cfrac{1^2} {2+\cfrac{3^2} {2+\cfrac{5^2} {2+\ddots}}}} = \sum_{n=0}^\infty \frac{4(-1)^n}{2n+1} = \frac{4}{1} - \frac{4}{3} + \frac{4}{5} - \frac{4}{7} +- \cdots }[/math]
converges too slowly, requiring roughly 3 × 10n terms to achieve n correct decimal places. The series derived by Nilakantha Somayaji:

[math]\displaystyle{ \pi = 3 + \cfrac{1^2} {6+\cfrac{3^2} {6+\cfrac{5^2} {6+\ddots}}} = 3 - \sum_{n=1}^\infty \frac{(-1)^n} {n (n+1) (2n+1)} = 3 + \frac{1}{1\cdot 2\cdot 3} - \frac{1}{2\cdot 3\cdot 5} + \frac{1}{3\cdot 4\cdot 7} -+ \cdots }[/math]
is a much more obvious expression but still converges quite slowly, requiring nearly 50 terms for five decimals and nearly 120 for six. Both converge sublinearly to π. On the other hand:

[math]\displaystyle{ \pi = \cfrac{4} {1+\cfrac{1^2} {3+\cfrac{2^2} {5+\cfrac{3^2} {7+\ddots}}}} = 4 - 1 + \frac{1}{6} - \frac{1}{34} + \frac {16}{3145} - \frac{4}{4551} + \frac{1}{6601} - \frac{1}{38341} +- \cdots }[/math]
converges linearly to π, adding at least three digits of precision per four terms, a pace slightly faster than the arcsine formula for π:

[math]\displaystyle{ \pi = 6 \sin^{-1} \left( \frac{1}{2} \right) = \sum_{n=0}^\infty \frac {3 \cdot \binom {2n} {n}} {16^n (2n+1)} = \frac {3} {16^0 \cdot 1} + \frac {6} {16^1 \cdot 3} + \frac {18} {16^2 \cdot 5} + \frac {60} {16^3 \cdot 7} + \cdots\! }[/math]
which adds at least three decimal digits per five terms.[21]

Note: this continued fraction's rate of convergence μ tends to 3 − √8 ≈ 0.1715729, hence 
1
/
μ
 tends to 3 + √8 ≈ 5.828427, whose common logarithm is 0.7655... ≈ 
13
/
17
 > 
3
/
4
. The same 
1
/
μ
 = 3 + √8 (the silver ratio squared) also is observed in the unfolded general continued fractions of both the natural logarithm of 2 and the nth root of 2 (which works for any integer n > 1) if calculated using 2 = 1 + 1. For the folded general continued fractions of both expressions, the rate convergence μ = (3 − √8)2 = 17 − √288 ≈ 0.02943725, hence 
1
/
μ
 = (3 + √8)2 = 17 + √288 ≈ 33.97056, whose common logarithm is 1.531... ≈ 
26
/
17
 > 
3
/
2
, thus adding at least three digits per two terms. This is because the folded GCF folds each pair of fractions from the unfolded GCF into one fraction, thus doubling the convergence pace. The Manny Sardina reference further explains "folded" continued fractions.
Note: Using the continued fraction for arctan 
x
/
y
 cited above with the best-known Machin-like formula provides an even more rapidly, although still linearly, converging expression:
[math]\displaystyle{ \pi = 16 \tan^{-1} \cfrac{1}{5}\, -\, 4 \tan^{-1} \cfrac{1}{239} = \cfrac{16} {u+\cfrac{1^2} {3u+\cfrac{2^2} {5u+\cfrac{3^2} {7u+\ddots}}}} \, -\, \cfrac{4} {v+\cfrac{1^2} {3v+\cfrac{2^2} {5v+\cfrac{3^2} {7v+\ddots}}}}. }[/math]
with u = 5 and v = 239.

Roots of positive numbers
The nth root of any positive number zm can be expressed by restating z = xn + y, resulting in

[math]\displaystyle{ \sqrt[n]{z^m} = \sqrt[n]{\left(x^n+y\right)^m} = x^m+\cfrac{my} {nx^{n-m}+\cfrac{(n-m)y} {2x^m+\cfrac{(n+m)y} {3nx^{n-m}+\cfrac{(2n-m)y} {2x^m+\cfrac{(2n+m)y} {5nx^{n-m}+\cfrac{(3n-m)y} {2x^m+\ddots}}}}}} }[/math]
which can be simplified, by folding each pair of fractions into one fraction, to

[math]\displaystyle{ \sqrt[n]{z^m} = x^m+\cfrac{2x^m \cdot my} {n(2x^n + y)-my-\cfrac{(1^2n^2-m^2)y^2} {3n(2x^n + y)-\cfrac{(2^2n^2-m^2)y^2} {5n(2x^n + y)-\cfrac{(3^2n^2-m^2)y^2} {7n(2x^n + y)-\cfrac{(4^2n^2-m^2)y^2} {9n(2x^n + y)-\ddots}}}}}. }[/math]
The square root of z is a special case with m = 1 and n = 2:

[math]\displaystyle{ \sqrt{z} = \sqrt{x^2+y} = x+\cfrac{y} {2x+\cfrac{y} {2x+\cfrac{3y} {6x+\cfrac{3y} {2x+\ddots}}}} = x+\cfrac{2x \cdot y} {2(2x^2 + y)-y-\cfrac{1\cdot 3y^2} {6(2x^2 + y)-\cfrac{3\cdot 5y^2} {10(2x^2 + y)-\ddots}}} }[/math]
which can be simplified by noting that 
5
/
10
 = 
3
/
6
 = 
1
/
2
:

[math]\displaystyle{ \sqrt{z} = \sqrt{x^2+y} = x+\cfrac{y} {2x+\cfrac{y} {2x+\cfrac{y} {2x+\cfrac{y} {2x+\ddots}}}} = x+\cfrac{2x \cdot y} {2(2x^2 + y)-y-\cfrac{y^2} {2(2x^2 + y)-\cfrac{y^2} {2(2x^2 + y)-\ddots}}}. }[/math]
The square root can also be expressed by a periodic continued fraction, but the above form converges more quickly with the proper x and y.

Example 1
The cube root of two (21/3 or 3√2 ≈ 1.259921...) can be calculated in two ways:

Firstly, "standard notation" of x = 1, y = 1, and 2z − y = 3:

[math]\displaystyle{ \sqrt[3]2 = 1+\cfrac{1} {3+\cfrac{2} {2+\cfrac{4} {9+\cfrac{5} {2+\cfrac{7} {15+\cfrac{8} {2+\cfrac{10} {21+\cfrac{11} {2+\ddots}}}}}}}} = 1+\cfrac{2 \cdot 1} {9-1-\cfrac{2 \cdot 4} {27-\cfrac{5 \cdot 7} {45-\cfrac{8 \cdot 10} {63-\cfrac{11 \cdot 13} {81-\ddots}}}}}. }[/math]
Secondly, a rapid convergence with x = 5, y = 3 and 2z − y = 253:

[math]\displaystyle{ \sqrt[3]2 = \cfrac{5}{4}+\cfrac{0.5} {50+\cfrac{2} {5+\cfrac{4} {150+\cfrac{5} {5+\cfrac{7} {250+\cfrac{8} {5+\cfrac{10} {350+\cfrac{11} {5+\ddots}}}}}}}} = \cfrac{5}{4}+\cfrac{2.5 \cdot 1} {253-1-\cfrac{2 \cdot 4} {759-\cfrac{5 \cdot 7} {1265-\cfrac{8 \cdot 10} {1771-\ddots}}}}. }[/math]
Example 2
Pogson's ratio (1001/5 or 5√100 ≈ 2.511886...), with x = 5, y = 75 and 2z − y = 6325:

[math]\displaystyle{ \sqrt[5]{100} = \cfrac{5}{2}+\cfrac{3} {250+\cfrac{12} {5+\cfrac{18} {750+\cfrac{27} {5+\cfrac{33} {1250+\cfrac{42} {5+\ddots}}}}}} = \cfrac{5}{2}+\cfrac{5\cdot 3} {1265-3-\cfrac{12 \cdot 18} {3795-\cfrac{27 \cdot 33} {6325-\cfrac{42 \cdot 48} {8855-\ddots}}}}. }[/math]
Example 3
The twelfth root of two (21/12 or 12√2 ≈ 1.059463...), using "standard notation":

[math]\displaystyle{ \sqrt[12]2 = 1+\cfrac{1} {12+\cfrac{11} {2+\cfrac{13} {36+\cfrac{23} {2+\cfrac{25} {60+\cfrac{35} {2+\cfrac{37} {84+\cfrac{47} {2+\ddots}}}}}}}} = 1+\cfrac{2 \cdot 1} {36-1 - \cfrac{11 \cdot 13} {108-\cfrac{23 \cdot 25} {180-\cfrac{35 \cdot 37} {252-\cfrac{47 \cdot 49} {324-\ddots}}}}}. }[/math]
Example 4
Equal temperament's perfect fifth (27/12 or 12√27 ≈ 1.498307...), with m = 7:

With "standard notation":

[math]\displaystyle{ \sqrt[12]{2^7} = 1+\cfrac{7} {12+\cfrac{5} {2+\cfrac{19} {36+\cfrac{17} {2+\cfrac{31} {60+\cfrac{29} {2+\cfrac{43} {84+\cfrac{41} {2+\ddots}}}}}}}} = 1+\cfrac{2 \cdot 7} {36-7 - \cfrac{5 \cdot 19} {108-\cfrac{17 \cdot 31} {180-\cfrac{29 \cdot 43} {252-\cfrac{41 \cdot 55} {324-\ddots}}}}}. }[/math]
A rapid convergence with x = 3, y = −7153, and 2z − y = 219 + 312:

[math]\displaystyle{ \sqrt[12]{2^7} = \cfrac{1}{2} \sqrt[12]{3^{12}-7153} = \cfrac{3}{2} - \cfrac{0.5 \cdot 7153}{4\cdot 3^{12} - \cfrac{11\cdot 7153}{6 - \cfrac{13\cdot 7153}{12\cdot 3^{12} - \cfrac{23\cdot 7153}{6 - \cfrac{25\cdot 7153}{20\cdot 3^{12} - \cfrac{35\cdot 7153}{6 - \cfrac{37\cdot 7153}{28\cdot 3^{12} - \cfrac{47\cdot 7153}{6 - \ddots}}}}}}}} }[/math]
[math]\displaystyle{ \sqrt[12]{2^7} = \cfrac{3}{2} - \cfrac{3\cdot 7153}{12(2^{19}+3^{12}) + 7153 - \cfrac{11\cdot 13\cdot 7153^2}{36(2^{19}+3^{12}) - \cfrac{23\cdot 25\cdot 7153^2}{60(2^{19}+3^{12}) - \cfrac{35\cdot 37\cdot 7153^2}{84(2^{19}+3^{12}) - \ddots}}}}. }[/math]
More details on this technique can be found in General Method for Extracting Roots using (Folded) Continued Fractions.

Higher dimensions
Another meaning for generalized continued fraction is a generalization to higher dimensions. For example, there is a close relationship between the simple continued fraction in canonical form for the irrational real number α, and the way lattice points in two dimensions lie to either side of the line y = αx. Generalizing this idea, one might ask about something related to lattice points in three or more dimensions. One reason to study this area is to quantify the mathematical coincidence idea; for example, for monomials in several real numbers, take the logarithmic form and consider how small it can be. Another reason is to find a possible solution to Hermite's problem.

There have been numerous attempts to construct a generalized theory. Notable efforts in this direction were made by Felix Klein (the Klein polyhedron), Georges Poitou and George Szekeres.

See also
Gauss's continued fraction
Padé table
Solving quadratic equations with continued fractions
Convergence problem
Infinite compositions of analytic functions
Notes
↑ Cusick & Flahive 1989.
↑ Chrystal 1999.
↑ Jones & Thron 1980, p. 20.
↑ (Euclid 2008) - The Euclidean algorithm generates a continued fraction as a by-product.
↑ Cataldi 1613.
↑ Wallis 1699.
↑ 7.0 7.1 Euler 1748, Chapter 18.
↑ Havil 2012, pp. 104-105.
↑ Brahmagupta (598–670) was the first mathematician to make a systematic study of Pell's equation.
↑ Gauss 1813.
↑ Lorentzen & Waadeland 1992.
↑ Oskar Perron derives even more general extension and contraction formulas for continued fractions. See (Perron 1977a), (Perron 1977b).
↑ Angell 2021.
↑ Porubský 2008.
↑ This intuitive interpretation is not rigorous because an infinite continued fraction is not a mapping: it is the limit of a sequence of mappings. This construction of an infinite continued fraction is roughly analogous to the construction of an irrational number as the limit of a Cauchy sequence of rational numbers.
↑ Because of analogies like this one, the theory of conformal mapping is sometimes described as "rubber sheet geometry".
↑ One approach to the convergence problem is to construct positive definite continued fractions, for which the denominators Bi are never zero.
↑ This periodic fraction of period one is discussed more fully in the article convergence problem.
↑ An alternative way to calculate log(x)
↑ Borwein, Crandall & Fee 2004, p. 278, 280.
↑ Beckmann 1971.
References
Angell, David (2010). "A family of continued fractions". Journal of Number Theory (Elsevier) 130 (4): 904–911. doi:10.1016/j.jnt.2009.12.003. https://www.sciencedirect.com/science/article/pii/S0022314X10000193/pdfft?md5=36d08f2233a097cfd00962fe07a7378a&pid=1-s2.0-S0022314X10000193-main.pdf.
Angell, David (2021). Irrationality and Transcendence in Number Theory. Chapman and Hall/CRC. ISBN 9780367628376.
Beckmann, Petr (1971). A History of Pi. St. Martin's Press, Inc.. pp. 131–133, 140–143. ISBN 0-88029-418-3. https://archive.org/details/historyofpisymbo00beck/page/131.
Bombelli, Rafael (1579). L'algebra. https://www.maa.org/press/periodicals/convergence/mathematical-treasure-raphael-bombellis-lalgebra.
Borwein, Jonathan Michael; Crandall, Richard E.; Fee, Greg (2004). "On the Ramanujan AGM Fraction, I: The Real-Parameter Case". Experimental Mathematics 13 (3): 275–285. doi:10.1080/10586458.2004.10504540. https://projecteuclid.org/journalArticle/Download?urlid=em%2F1103749836.
Cataldi, Pietro Antonio (1613). Trattato del modo brevissimo di trovar la radice quadra delli numeri. http://mathematica.sns.it/opere/70/.
Chrystal, George (1999). Algebra, an Elementary Text-book for the Higher Classes of Secondary Schools and for Colleges: Pt. 1. American Mathematical Society. pp. 500. ISBN 0-8218-1649-7.
Cusick, Thomas W.; Flahive, Mary E. (1989). The Markoff and Lagrange Spectra. American Mathematical Society. pp. 89. ISBN 0-8218-1531-8. https://archive.org/details/markofflagranges00cusi_056.
Euclid (2008). "Elements". Clay Mathematics Institute. https://www.claymath.org/library/historical/euclid/.
Euler, Leonhard (1748). "E101 – Introductio in analysin infinitorum, volume 1". The Euler Archive. https://scholarlycommons.pacific.edu/euler-works/101/.
Gauss, Carl Friedrich (1813). Disquisitiones generales circa seriem infinitam.
Havil, Julian (2012). The Irrationals: A Story of the Numbers You Can't Count On. Princeton University Press. pp. 280. ISBN 978-0691143422.
Jones, William B.; Thron, W.J. (1980). Continued fractions. Analytic theory and applications. Encyclopedia of Mathematics and its Applications. 11. Reading, MA: Addison-Wesley. ISBN 0-201-13510-8. https://archive.org/details/continuedfractio0000jone. (Covers both analytic theory and history.)
Lorentzen, Lisa; Waadeland, Haakon (1992). Continued Fractions with Applications. Reading, MA: North Holland. ISBN 978-0-444-89265-2. (Covers primarily analytic theory and some arithmetic theory.)
Perron, Oskar (1977a). Die Lehre von den Kettenbrüchen. Band I: Elementare Kettenbrüche (3 ed.). Vieweg + Teubner Verlag. ISBN 9783519020219.
Perron, Oskar (1977b). Die Lehre von den Kettenbrüchen. Band II: Analytisch-funktionentheoretische Kettenbrüche (3 ed.). Vieweg + Teubner Verlag. ISBN 9783519020226.
Porubský, Štefan (2008). "Basic definitions for continued fractions". Interactive Information Portal for Algorithmic Mathematics. Prague, Czech Republic: Institute of Computer Science of the Czech Academy of Sciences. http://www.cs.cas.cz/portal/AlgoMath/NumberTheory/ContinuedFractions/BasicDefinitions.htm.
Press, WH; Teukolsky, SA; Vetterling, WT; Flannery, BP (2007). "Section 5.2. Evaluation of Continued Fractions". Numerical Recipes: The Art of Scientific Computing (3rd ed.). New York: Cambridge University Press. ISBN 978-0-521-88068-8. http://apps.nrbook.com/empanel/index.html?pg=206.
Sardina, Manny (2007). "General Method for Extracting Roots using (Folded) Continued Fractions". Surrey (UK). http://myreckonings.com/Dead_Reckoning/Online/Materials/General%20Method%20for%20Extracting%20Roots.pdf.
Szekeres, George (1970). "Multidimensional continued fractions". Ann. Univ. Sci. Budapest. Eötvös Sect. Math. 13: 113–140.
Von Koch, Helge (1895). "Sur un théorème de Stieltjes et sur les fonctions définies par des fractions continues". Bulletin de la Société Mathématique de France 23: 33–40. doi:10.24033/bsmf.508.
Wall, Hubert Stanley (1967). Analytic Theory of Continued Fractions (Reprint ed.). Chelsea Pub Co. ISBN 0-8284-0207-8. (This reprint of the D. Van Nostrand edition of 1948 covers both history and analytic theory.)
Wallis, John (1699). Opera mathematica.
External links
Template:WT

The first twenty pages of Steven R. Finch, Mathematical Constants, Cambridge University Press , 2003, ISBN:0-521-81805-2, contains generalized continued fractions for √2 and the golden mean.
OEIS sequence A133593 ("Exact" continued fraction for Pi)
he:שבר משולב


Public domain	
0.00
 (0 votes)
Original source: https://en.wikipedia.org/wiki/Generalized continued fraction. Read more

Retrieved from "https://handwiki.org/wiki/index.php?title=Generalized_continued_fraction&oldid=2995894"
Category:
Continued fractions
Hidden category:
Wikipedia articles needing clarification from September 2014
Computing portal

Encyclopedia of Knowledge
Portals
Main page Data analysis Astronomy & Space Biology Computer concepts Chemistry Mathematics Physics Earth studies Unsolved problems
===
]]]
[[[
https://handwiki.org/wiki/Euler%27s_continued_fraction_formula
Euler's continued fraction formula
===
Euler's continued fraction formula
From HandWiki

Short description: Connects a very general infinite series with an infinite continued fraction.
In the analytic theory of continued fractions, Euler's continued fraction formula is an identity connecting a certain very general infinite series with an infinite continued fraction. First published in 1748, it was at first regarded as a simple identity connecting a finite sum with a finite continued fraction in such a way that the extension to the infinite case was immediately apparent.[1] Today it is more fully appreciated as a useful tool in analytic attacks on the general convergence problem for infinite continued fractions with complex elements.


Contents
1	The original formula
2	Euler's formula
3	Proof by induction
4	Examples
4.1	The exponential function
4.2	The natural logarithm
4.3	The trigonometric functions
4.3.1	The inverse trigonometric functions
4.4	A continued fraction for π
4.5	The hyperbolic functions
4.5.1	The inverse hyperbolic functions
5	See also
6	References
The original formula
Euler derived the formula as connecting a finite sum of products with a finite continued fraction.

[math]\displaystyle{ a_0 + a_0a_1 + a_0a_1a_2 + \cdots + a_0a_1a_2\cdots a_n = \cfrac{a_0}{1 - \cfrac{a_1}{1 + a_1 - \cfrac{a_2}{1 + a_2 - \cfrac{\ddots}{\ddots \cfrac{a_{n-1}}{1 + a_{n-1} - \cfrac{a_n}{1 + a_n}}}}}}\, }[/math]
The identity is easily established by induction on n, and is therefore applicable in the limit: if the expression on the left is extended to represent a convergent infinite series, the expression on the right can also be extended to represent a convergent infinite continued fraction.

This is written more compactly using generalized continued fraction notation:

[math]\displaystyle{ a_0 + a_0 a_1 + a_0 a_1 a_2 + \cdots + a_0 a_1 a_2 \cdots a_n = \frac{a_0}{1 +} \, \frac{-a_1}{1 + a_1 +} \, \cfrac{-a_2}{1 + a_2 +} \cdots \frac{-a_n}{1 + a_n}. }[/math]
Euler's formula
If ri are complex numbers and x is defined by

[math]\displaystyle{ x = 1 + \sum_{i=1}^\infty r_1r_2\cdots r_i = 1 + \sum_{i=1}^\infty \left( \prod_{j=1}^i r_j \right)\,, }[/math]
then this equality can be proved by induction

[math]\displaystyle{ x = \cfrac{1}{1 - \cfrac{r_1}{1 + r_1 - \cfrac{r_2}{1 + r_2 - \cfrac{r_3}{1 + r_3 - \ddots}}}}\, }[/math].
Here equality is to be understood as equivalence, in the sense that the n'th convergent of each continued fraction is equal to the n'th partial sum of the series shown above. So if the series shown is convergent – or uniformly convergent, when the ri's are functions of some complex variable z – then the continued fractions also converge, or converge uniformly.[2]

Proof by induction
Theorem: Let [math]\displaystyle{ n }[/math] be a natural number. For [math]\displaystyle{ n+1 }[/math] complex values [math]\displaystyle{ a_0, a_1, \ldots, a_{n} }[/math],

[math]\displaystyle{ \sum_{k=0}^n \prod_{j=0}^k a_j = \frac{a_0}{1+} \, \frac{-a_1}{1+a_1+} \cdots \frac{-a_n}{1+a_n} }[/math]
and for [math]\displaystyle{ n }[/math] complex values [math]\displaystyle{ b_1, \ldots, b_{n} }[/math], [math]\displaystyle{ \frac{-b_1}{1+b_1+} \, \frac{-b_2}{1+b_2+} \cdots \frac{-b_n}{1+b_n} \ne -1. }[/math]

Proof: We perform a double induction. For [math]\displaystyle{ n=1 }[/math], we have

[math]\displaystyle{ \frac{a_0}{1+} \, \frac{-a_1}{1+a_1} = \frac{a_0}{1+\frac{-a_1}{1+a_1}} = \frac{a_0(1+a_1)}{1} = a_0 + a_0 a_1 = \sum_{k=0}^1 \prod_{j=0}^k a_j }[/math]
and

[math]\displaystyle{ \frac{-b_1}{1+b_1}\ne -1. }[/math]
Now suppose both statements are true for some [math]\displaystyle{ n \ge 1 }[/math].

We have [math]\displaystyle{ \frac{-b_1}{1+b_1+} \, \frac{-b_2}{1+b_2+} \cdots \frac{-b_{n+1}}{1+b_{n+1}} = \frac{-b_1}{1+b_1+x} }[/math] where [math]\displaystyle{ x = \frac{-b_2}{1+b_2+} \cdots \frac{-b_{n+1}}{1+b_{n+1}} \ne -1 }[/math]

by applying the induction hypothesis to [math]\displaystyle{ b_2, \ldots, b_{n+1} }[/math].

But if [math]\displaystyle{ \frac{-b_1}{1+b_1+x} = -1 }[/math] implies [math]\displaystyle{ b_1 = 1+b_1+x }[/math] implies [math]\displaystyle{ x = -1 }[/math], contradiction. Hence

[math]\displaystyle{ \frac{-b_1}{1+b_1+} \, \frac{-b_2}{1+b_2+} \cdots \frac{-b_{n+1}}{1+b_{n+1}} \ne -1, }[/math]
completing that induction.

Note that for [math]\displaystyle{ x \ne -1 }[/math],

[math]\displaystyle{ \frac{1}{1+} \, \frac{-a}{1+a+x} = \frac{1}{1-\frac{a}{1+a+x}} = \frac{1+a+x}{1+x} = 1 + \frac{a}{1+x}; }[/math]
if [math]\displaystyle{ x=-1-a }[/math], then both sides are zero.

Using [math]\displaystyle{ a=a_1 }[/math] and [math]\displaystyle{ x = \frac{-a_2}{1+a_2+} \, \cdots \frac{-a_{n+1}}{1+a_{n+1}} \ne -1 }[/math], and applying the induction hypothesis to the values [math]\displaystyle{ a_1, a_2, \ldots, a_{n+1} }[/math],

[math]\displaystyle{ \begin{align} a_0 + & a_0a_1 + a_0a_1a_2 + \cdots + a_0a_1a_2a_3 \cdots a_{n+1} \\ &= a_0 + a_0(a_1 + a_1a_2 + \cdots + a_1a_2a_3 \cdots a_{n+1}) \\ &= a_0 + a_0 \big( \frac{a_1}{1+} \, \frac{-a_2}{1+a_2+} \, \cdots \frac{-a_{n+1}}{1+a_{n+1}} \big)\\ &= a_0 \big(1 + \frac{a_1}{1+} \, \frac{-a_2}{1+a_2+} \, \cdots \frac{-a_{n+1}}{1+a_{n+1}} \big)\\ &= a_0 \big(\frac{1}{1+} \, \frac{-a_1}{1+a_1+} \, \frac{-a_2}{1+a_2+} \, \cdots \frac{-a_{n+1}}{1+a_{n+1}} \big)\\ &= \frac{a_0}{1+} \, \frac{-a_1}{1+a_1+} \, \frac{-a_2}{1+a_2+} \, \cdots \frac{-a_{n+1}}{1+a_{n+1}}, \end{align} }[/math]
completing the other induction.

As an example, the expression [math]\displaystyle{ a_0 + a_0a_1 + a_0a_1a_2 + a_0a_1a_2a_3 }[/math] can be rearranged into a continued fraction.

[math]\displaystyle{ \begin{align} a_0 + a_0a_1 + a_0a_1a_2 + a_0a_1a_2a_3 & = a_0(a_1(a_2(a_3 + 1) + 1) + 1) \\[8pt] & = \cfrac{a_0}{\cfrac{1}{a_1(a_2(a_3 + 1) + 1) + 1}} \\[8pt] & = \cfrac{a_0}{\cfrac{a_1(a_2(a_3 + 1) + 1) + 1}{a_1(a_2(a_3 + 1) + 1) + 1} - \cfrac{a_1(a_2(a_3 + 1) + 1)}{a_1(a_2(a_3 + 1) + 1) + 1}} = \cfrac{a_0}{1 - \cfrac{a_1(a_2(a_3 + 1) + 1)}{a_1(a_2(a_3 + 1) + 1) + 1}} \\[8pt] & = \cfrac{a_0}{1 - \cfrac{a_1}{\cfrac{a_1(a_2(a_3 + 1) + 1) + 1}{a_2(a_3 + 1) + 1}}} \\[8pt] & = \cfrac{a_0}{1 - \cfrac{a_1}{\cfrac{a_1(a_2(a_3 + 1) + 1)}{a_2(a_3 + 1) + 1} + \cfrac{a_2(a_3 + 1) + 1}{a_2(a_3 + 1) + 1} - \cfrac{a_2(a_3 + 1)}{a_2(a_3 + 1) + 1}}} = \cfrac{a_0}{1 - \cfrac{a_1}{1 + a_1 - \cfrac{a_2(a_3 + 1)}{a_2(a_3 + 1) + 1}}} \\[8pt] & = \cfrac{a_0}{1 - \cfrac{a_1}{1 + a_1 - \cfrac{a_2}{\cfrac{a_2(a_3 + 1) + 1}{a_3 + 1}}}} \\[8pt] & = \cfrac{a_0}{1 - \cfrac{a_1}{1 + a_1 - \cfrac{a_2}{\cfrac{a_2(a_3 + 1)}{a_3 + 1} + \cfrac{a_3 + 1}{a_3 + 1} - \cfrac{a_3}{a_3 + 1}}}} = \cfrac{a_0}{1 - \cfrac{a_1}{1 + a_1 - \cfrac{a_2}{1 + a_2 - \cfrac{a_3}{1 + a_3}}}} \end{align} }[/math]
This can be applied to a sequence of any length, and will therefore also apply in the infinite case.

Examples
The exponential function
The exponential function ex is an entire function with a power series expansion that converges uniformly on every bounded domain in the complex plane.

[math]\displaystyle{ e^x = 1 + \sum_{n=1}^\infty \frac{x^n}{n!} = 1 + \sum_{n=1}^\infty \left(\prod_{i=1}^n \frac{x}{i}\right)\, }[/math]
The application of Euler's continued fraction formula is straightforward:

[math]\displaystyle{ e^x = \cfrac{1}{1 - \cfrac{x}{1 + x - \cfrac{\frac{1}{2}x}{1 + \frac{1}{2}x - \cfrac{\frac{1}{3}x} {1 + \frac{1}{3}x - \cfrac{\frac{1}{4}x}{1 + \frac{1}{4}x - \ddots}}}}}.\, }[/math]
Applying an equivalence transformation that consists of clearing the fractions this example is simplified to

[math]\displaystyle{ e^x = \cfrac{1}{1 - \cfrac{x}{1 + x - \cfrac{x}{2 + x - \cfrac{2x}{3 + x - \cfrac{3x}{4 + x - \ddots}}}}}\, }[/math]
and we can be certain that this continued fraction converges uniformly on every bounded domain in the complex plane because it is equivalent to the power series for ex.

The natural logarithm
The Taylor series for the principal branch of the natural logarithm in the neighborhood of x = 1 is well known:

[math]\displaystyle{ \log(1+x) = x - \frac{x^2}{2} + \frac{x^3}{3} - \frac{x^4}{4} + \cdots = \sum_{n=1}^\infty \frac{(-1)^{n+1}z^{n}}{n}.\, }[/math]
This series converges when |x| < 1 and can also be expressed as a sum of products:[3]

[math]\displaystyle{ \log (1+x) = x + (x)\left(\frac{-x}{2}\right) + (x)\left(\frac{-x}{2}\right)\left(\frac{-2x}{3}\right) + (x)\left(\frac{-x}{2}\right)\left(\frac{-2x}{3}\right)\left(\frac{-3x}{4}\right) + \cdots }[/math]
Applying Euler's continued fraction formula to this expression shows that

[math]\displaystyle{ \log (1+x) = \cfrac{x}{1 - \cfrac{\frac{-x}{2}}{1+\frac{-x}{2}-\cfrac{\frac{-2x}{3}}{1+\frac{-2x}{3}-\cfrac{\frac{-3x}{4}}{1+\frac{-3x}{4}-\ddots}}}} }[/math]
and using an equivalence transformation to clear all the fractions results in

[math]\displaystyle{ \log (1+x) = \cfrac{x}{1+\cfrac{x}{2-x+\cfrac{2^2x}{3-2x+\cfrac{3^2x}{4-3x+\ddots}}}} }[/math]

This continued fraction converges when |x| < 1 because it is equivalent to the series from which it was derived.[3]

The trigonometric functions
The Taylor series of the sine function converges over the entire complex plane and can be expressed as the sum of products.

[math]\displaystyle{ \begin{align} \sin x = \sum^{\infty}_{n=0} \frac{(-1)^n}{(2n+1)!} x^{2n+1} & = x - \frac{x^3}{3!} + \frac{x^5}{5!} - \frac{x^7}{7!} + \frac{x^9}{9!} - \cdots \\[8pt] & = x + (x)\left(\frac{-x^2}{2 \cdot 3}\right) + (x)\left(\frac{-x^2}{2 \cdot 3}\right)\left(\frac{-x^2}{4 \cdot 5}\right) + (x)\left(\frac{-x^2}{2 \cdot 3}\right)\left(\frac{-x^2}{4 \cdot 5}\right)\left(\frac{-x^2}{6 \cdot 7}\right) + \cdots \end{align} }[/math]
Euler's continued fraction formula can then be applied

[math]\displaystyle{ \cfrac{x}{1 - \cfrac{\frac{-x^2}{2 \cdot 3}}{1 + \frac{-x^2}{2 \cdot 3} - \cfrac{\frac{-x^2}{4 \cdot 5}}{1 + \frac{-x^2}{4 \cdot 5} - \cfrac{\frac{-x^2}{6 \cdot 7}}{1 + \frac{-x^2}{6 \cdot 7} - \ddots}}}} }[/math]
An equivalence transformation is used to clear the denominators:

[math]\displaystyle{ \sin x = \cfrac{x}{1 + \cfrac{x^2}{2 \cdot 3 - x^2 + \cfrac{2 \cdot 3x^2}{4 \cdot 5 - x^2 + \cfrac{4 \cdot 5x^2}{6 \cdot 7 - x^2 + \ddots}}}}. }[/math]
The same argument can be applied to the cosine function:

[math]\displaystyle{ \begin{align} \cos x = \sum^{\infty}_{n=0} \frac{(-1)^n}{(2n)!} x^{2n} & = 1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \frac{x^6}{6!} + \frac{x^8}{8!} - \cdots \\[8pt] & = 1 + \frac{-x^2}{2} + \left(\frac{-x^2}{2}\right)\left(\frac{-x^2}{ 3 \cdot 4}\right) + \left(\frac{-x^2}{2}\right)\left(\frac{-x^2}{ 3 \cdot 4}\right)\left(\frac{-x^2}{ 5 \cdot 6}\right) + \cdots \\[8pt] & = \cfrac{1}{1 - \cfrac{\frac{-x^2}{2}}{1 + \frac{-x^2}{2} - \cfrac{\frac{-x^2}{3 \cdot 4}}{1 + \frac{-x^2}{3 \cdot 4} - \cfrac{\frac{-x^2}{5 \cdot 6}}{1 + \frac{-x^2}{5 \cdot 6} - \ddots}}}} \end{align} }[/math]
[math]\displaystyle{ \therefore \cos x = \cfrac{1}{1 + \cfrac{x^2}{2 - x^2 + \cfrac{2x^2}{3 \cdot 4 - x^2 + \cfrac{3 \cdot 4x^2}{5 \cdot 6 - x^2 + \ddots}}}}. }[/math]
The inverse trigonometric functions
The inverse trigonometric functions can be represented as continued fractions.

[math]\displaystyle{ \begin{align} \sin^{-1} x = \sum_{n=0}^\infty \frac{(2n-1)!!}{(2n)!!} \cdot \frac{x^{2n+1}}{2n+1} & = x + \left( \frac{1}{2} \right) \frac{x^3}{3} + \left( \frac{1 \cdot 3}{2 \cdot 4} \right) \frac{x^5}{5} + \left( \frac{1 \cdot 3 \cdot 5}{2 \cdot 4 \cdot 6} \right) \frac{x^7}{7} + \cdots \\[8pt] & = x + x \left(\frac{x^2}{2 \cdot 3}\right) + x \left(\frac{x^2}{2 \cdot 3}\right)\left(\frac{(3x)^2}{4 \cdot 5}\right) + x \left(\frac{x^2}{2 \cdot 3}\right)\left(\frac{(3x)^2}{4 \cdot 5}\right)\left(\frac{(5x)^2}{6 \cdot 7}\right) + \cdots \\[8pt] & = \cfrac{x}{1 - \cfrac{\frac{x^2}{2 \cdot 3}}{1 + \frac{x^2}{2 \cdot 3} - \cfrac{\frac{(3x)^2}{4 \cdot 5}}{1 + \frac{(3x)^2}{4 \cdot 5} - \cfrac{\frac{(5x)^2}{6 \cdot 7}}{ 1 + \frac{(5x)^2}{6 \cdot 7} - \ddots}}}} \end{align} }[/math]
An equivalence transformation yields

[math]\displaystyle{ \sin^{-1} x = \cfrac{x}{1 - \cfrac{x^2}{2 \cdot 3 + x^2 - \cfrac{2 \cdot 3 (3x)^2}{4 \cdot 5 +(3x)^2 - \cfrac{4 \cdot 5 (5x^2)}{6 \cdot 7 + (5x^2) - \ddots}}}}. }[/math]
The continued fraction for the inverse tangent is straightforward:

[math]\displaystyle{ \begin{align} \tan^{-1} x = \sum_{n=0}^\infty (-1)^n \frac{x^{2n + 1}}{2n + 1} & = x - \frac{x^3}{3} + \frac{x^5}{5} - \frac{x^7}{7} + \cdots \\[8pt] & = x + x \left(\frac{-x^2}{3}\right) + x \left(\frac{-x^2}{3}\right)\left(\frac{-3x^2}{5}\right) + x \left(\frac{-x^2}{3}\right)\left(\frac{-3x^2}{5}\right)\left(\frac{-5x^2}{7}\right) + \cdots \\[8pt] & = \cfrac{x}{1 - \cfrac{\frac{-x^2}{3}}{1 + \frac{-x^2}{3} - \cfrac{\frac{-3x^2}{5}}{1 + \frac{-3x^2}{5} - \cfrac{\frac{-5x^2}{7}}{1 + \frac{-5x^2}{7} - \ddots}}}} \\[8pt] & = \cfrac{x}{1 + \cfrac{x^2}{3 - x^2 + \cfrac{(3x)^2}{5 - 3x^2 + \cfrac{(5x)^2}{7 - 5x^2 + \ddots}}}}. \end{align} }[/math]
A continued fraction for π
We can use the previous example involving the inverse tangent to construct a continued fraction representation of π. We note that

[math]\displaystyle{ \tan^{-1} (1) = \frac\pi4 , }[/math]
And setting x = 1 in the previous result, we obtain immediately

[math]\displaystyle{ \pi = \cfrac{4}{1 + \cfrac{1^2}{2 + \cfrac{3^2}{2 + \cfrac{5^2}{2 + \cfrac{7^2}{2 + \ddots}}}}}.\, }[/math]
The hyperbolic functions
Recalling the relationship between the hyperbolic functions and the trigonometric functions,

[math]\displaystyle{ \sin ix = i \sinh x }[/math]
[math]\displaystyle{ \cos ix = \cosh x , }[/math]
And that [math]\displaystyle{ i^2 = -1, }[/math] the following continued fractions are easily derived from the ones above:

[math]\displaystyle{ \sinh x = \cfrac{x}{1 - \cfrac{x^2}{2 \cdot 3 + x^2 - \cfrac{2 \cdot 3x^2}{4 \cdot 5 + x^2 - \cfrac{4 \cdot 5x^2}{6 \cdot 7 + x^2 - \ddots}}}} }[/math]
[math]\displaystyle{ \cosh x = \cfrac{1}{1 - \cfrac{x^2}{2 + x^2 - \cfrac{2x^2}{3 \cdot 4 + x^2 - \cfrac{3 \cdot 4x^2}{5 \cdot 6 + x^2 - \ddots}}}}. }[/math]
The inverse hyperbolic functions
The inverse hyperbolic functions are related to the inverse trigonometric functions similar to how the hyperbolic functions are related to the trigonometric functions,

[math]\displaystyle{ \sin^{-1} ix = i \sinh^{-1} x }[/math]
[math]\displaystyle{ \tan^{-1} ix = i \tanh^{-1} x , }[/math]
And these continued fractions are easily derived:

[math]\displaystyle{ \sinh^{-1} x = \cfrac{x}{1 + \cfrac{x^2}{2 \cdot 3 - x^2 + \cfrac{2 \cdot 3 (3x)^2}{4 \cdot 5 - (3x)^2 + \cfrac{4 \cdot 5 (5x^2)}{6 \cdot 7 - (5x^2) + \ddots}}}} }[/math]
[math]\displaystyle{ \tanh^{-1} x = \cfrac{x}{1 - \cfrac{x^2}{3 + x^2 - \cfrac{(3x)^2}{5 + 3x^2 - \cfrac{(5x)^2}{7 + 5x^2 - \ddots}}}}. }[/math]
See also
Gauss's continued fraction
Engel expansion
List of topics named after Leonhard Euler
References
 Leonhard Euler (1748), "18", Introductio in analysin infinitorum, I
 H. S. Wall, Analytic Theory of Continued Fractions, D. Van Nostrand Company, Inc., 1948; reprinted (1973) by Chelsea Publishing Company ISBN:0-8284-0207-8, p. 17.
 This series converges for |x| < 1, by Abel's test (applied to the series for log(1 − x)).

Category: Continued fractions
]]]
[[[
https://handwiki.org/wiki/Rate_of_convergence
===
Rate of convergence
From HandWiki

Short description: Speed of convergence of a mathematical sequence

In numerical analysis, the order of convergence and the rate of convergence of a convergent sequence are quantities that represent how quickly the sequence approaches its limit. A sequence [math]\displaystyle{ (x_n) }[/math] that converges to [math]\displaystyle{ x^* }[/math] is said to have order of convergence [math]\displaystyle{ q \geq 1 }[/math] and rate of convergence [math]\displaystyle{ \mu }[/math] if

[math]\displaystyle{ \lim _{n \rightarrow \infty} \frac{\left|x_{n+1}-x^{*}\right|}{\left|x_{n}-x^{*}\right|^{q}}=\mu. }[/math][1]
The rate of convergence [math]\displaystyle{ \mu }[/math] is also called the asymptotic error constant. Note that this terminology is not standardized and some authors will use rate where this article uses order (e.g., [2]).

In practice, the rate and order of convergence provide useful insights when using iterative methods for calculating numerical approximations. If the order of convergence is higher, then typically fewer iterations are necessary to yield a useful approximation. Strictly speaking, however, the asymptotic behavior of a sequence does not give conclusive information about any finite part of the sequence.

Similar concepts are used for discretization methods. The solution of the discretized problem converges to the solution of the continuous problem as the grid size goes to zero, and the speed of convergence is one of the factors of the efficiency of the method. However, the terminology, in this case, is different from the terminology for iterative methods.

Series acceleration is a collection of techniques for improving the rate of convergence of a series discretization. Such acceleration is commonly accomplished with sequence transformations.


Contents
1	Convergence speed for iterative methods
1.1	Convergence definitions
1.1.1	Order estimation
1.1.2	Q-convergence definitions
1.1.3	R-convergence definition
1.2	Examples
2	Convergence speed for discretization methods
2.1	Example of discretization methods
2.2	Examples (continued)
3	Recurrent sequences and fixed points
4	Acceleration of convergence
5	References
6	Literature
Convergence speed for iterative methods
Convergence definitions
Suppose that the sequence [math]\displaystyle{ (x_k) }[/math] converges to the number [math]\displaystyle{ L }[/math]. The sequence is said to converge with order [math]\displaystyle{ q }[/math] to [math]\displaystyle{ L }[/math], and with a rate of convergence[3] of [math]\displaystyle{ \mu }[/math], if[math]\displaystyle{ \lim_{k \to \infty} \frac{|x_{k+1} - L|}{|x_k - L|^q} = \mu \qquad \text{(Definition 1)} }[/math]for some positive constant [math]\displaystyle{ \mu \in (0, \infty) }[/math] if [math]\displaystyle{ q \gt 1 }[/math], and [math]\displaystyle{ \mu \in (0, 1) }[/math] if [math]\displaystyle{ q = 1 }[/math].[4][5] It is not necessary, however, that [math]\displaystyle{ q }[/math] be an integer. For example, the secant method, when converging to a regular, simple root, has an order of φ ≈ 1.618.[citation needed]

Convergence with order

[math]\displaystyle{ q = 1 }[/math] is called linear convergence if [math]\displaystyle{ \mu \in (0, 1) }[/math], and the sequence is said to converge Q-linearly to [math]\displaystyle{ L }[/math].
[math]\displaystyle{ q = 2 }[/math] is called quadratic convergence.
[math]\displaystyle{ q = 3 }[/math] is called cubic convergence.
etc.
Order estimation
A practical method to calculate the order of convergence for a sequence is to calculate the following sequence, which converges to [math]\displaystyle{ q }[/math]:

[math]\displaystyle{ q \approx \frac{\log \left|\frac{x_{k+1} - x_k}{x_k - x_{k-1}}\right|}{\log \left|\frac{x_k - x_{k-1}}{x_{k-1} - x_{k-2}}\right|}. }[/math][6]
Q-convergence definitions
In addition to the previously defined Q-linear convergence, a few other Q-convergence definitions exist. Given Definition 1 defined above, the sequence is said to converge Q-superlinearly to [math]\displaystyle{ L }[/math] (i.e. faster than linearly) in all the cases where [math]\displaystyle{ q \gt 1 }[/math] and also the case [math]\displaystyle{ q = 1, \mu = 0 }[/math].[7] Given Definition 1, the sequence is said to converge Q-sublinearly to [math]\displaystyle{ L }[/math] (i.e. slower than linearly) if [math]\displaystyle{ q = 1, \mu = 1 }[/math]. The sequence [math]\displaystyle{ (x_k) }[/math] converges logarithmically to [math]\displaystyle{ L }[/math] if the sequence converges sublinearly and additionally if

[math]\displaystyle{ \lim_{k \to \infty} \frac{|x_{k+2} - x_{k+1}|}{|x_{k+1} - x_k|} = 1 }[/math].[8]
Note that unlike previous definitions, logarithmic convergence is not called "Q-logarithmic."

In the definitions above, the "Q-" stands for "quotient" because the terms are defined using the quotient between two successive terms.[9]:619 Often, however, the "Q-" is dropped and a sequence is simply said to have linear convergence, quadratic convergence, etc.

R-convergence definition
The Q-convergence definitions have a shortcoming in that they do not include some sequences, such as the sequence [math]\displaystyle{ (b_k) }[/math] below, which converge reasonably fast, but whose rate is variable. Therefore, the definition of rate of convergence is extended as follows.

Suppose that [math]\displaystyle{ (x_k) }[/math] converges to [math]\displaystyle{ L }[/math]. The sequence is said to converge R-linearly to [math]\displaystyle{ L }[/math] if there exists a sequence [math]\displaystyle{ (\varepsilon_k) }[/math] such that

[math]\displaystyle{ |x_k - L|\le\varepsilon_k\quad\text{for all }k \,, }[/math]
and [math]\displaystyle{ (\varepsilon_k) }[/math] converges Q-linearly to zero.[3] The "R-" prefix stands for "root". [9]:620

Examples
Consider the sequence

[math]\displaystyle{ (a_k) = \left\{1, \frac{1}{2}, \frac{1}{4}, \frac{1}{8}, \frac{1}{16}, \frac{1}{32}, \ldots, \frac{1}{2^k}, ... \right\}. }[/math]
It can be shown that this sequence converges to [math]\displaystyle{ L = 0 }[/math]. To determine the type of convergence, we plug the sequence into the definition of Q-linear convergence,

[math]\displaystyle{ \lim_{k \to \infty} \frac{\left| 1/2^{k+1} - 0\right|}{\left| 1/ 2^k - 0 \right|} = \lim_{k \to \infty} \frac{2^k}{2^{k+1}} = \frac{1}{2}. }[/math]
Thus, we find that [math]\displaystyle{ (a_k) }[/math] converges Q-linearly and has a convergence rate of [math]\displaystyle{ \mu = 1/2 }[/math]. More generally, for any [math]\displaystyle{ c \in \mathbb{R}, \mu \in (-1, 1) }[/math], the sequence [math]\displaystyle{ (c\mu^k) }[/math] converges linearly with rate [math]\displaystyle{ |\mu| }[/math].

The sequence

[math]\displaystyle{ (b_k) = \left\{1, 1, \frac{1}{4}, \frac{1}{4}, \frac{1}{16}, \frac{1}{16}, \ldots,\frac{1}{4^{\left\lfloor \frac{k}{2} \right\rfloor}} ,\, \ldots \right\} }[/math]
also converges linearly to 0 with rate 1/2 under the R-convergence definition, but not under the Q-convergence definition. (Note that [math]\displaystyle{ \lfloor x \rfloor }[/math] is the floor function, which gives the largest integer that is less than or equal to [math]\displaystyle{ x }[/math].)

The sequence

[math]\displaystyle{ (c_k) = \left\{ \frac{1}{2}, \frac{1}{4}, \frac{1}{16}, \frac{1}{256}, \frac{1}{65,\!536}, \ldots, \frac{1}{2^{2^k}}, \ldots \right\} }[/math]
converges superlinearly. In fact, it is quadratically convergent.

Finally, the sequence

[math]\displaystyle{ (d_k) = \left\{1, \frac{1}{2}, \frac{1}{3}, \frac{1}{4}, \frac{1}{5}, \frac{1}{6}, \ldots, \frac{1}{k + 1}, \ldots \right\} }[/math]
converges sublinearly and logarithmically.

Plot showing the different rates of convergence for the sequences ak, bk, ck and dk.
Linear, linear, superlinear (quadratic), and sublinear rates of convergence
Convergence speed for discretization methods
A similar situation exists for discretization methods designed to approximate a function [math]\displaystyle{ y = f(x) }[/math], which might be an integral being approximated by numerical quadrature, or the solution of an ordinary differential equation (see example below). The discretization method generates a sequence [math]\displaystyle{ {y_0,y_1,y_2,y_3,...} }[/math], where each successive [math]\displaystyle{ y_j }[/math] is a function of [math]\displaystyle{ y_{j-1},y_{j-2},... }[/math] along with the grid spacing [math]\displaystyle{ h }[/math] between successive values of the independent variable [math]\displaystyle{ x }[/math]. The important parameter here for the convergence speed to [math]\displaystyle{ y = f(x) }[/math] is the grid spacing [math]\displaystyle{ h }[/math], inversely proportional to the number of grid points, i.e. the number of points in the sequence required to reach a given value of [math]\displaystyle{ x }[/math].

In this case, the sequence [math]\displaystyle{ (y_n) }[/math] is said to converge to the sequence [math]\displaystyle{ f(x_n) }[/math] with order q if there exists a constant C such that

[math]\displaystyle{ |y_n - f(x_n)| \lt C h^{q} \text{ for all } n. }[/math]
This is written as [math]\displaystyle{ |y_n - f(x_n)| = \mathcal{O}(h^{q}) }[/math] using big O notation.

This is the relevant definition when discussing methods for numerical quadrature or the solution of ordinary differential equations (ODEs).[example needed]

A practical method to estimate the order of convergence for a discretization method is pick step sizes [math]\displaystyle{ h_\text{new} }[/math] and [math]\displaystyle{ h_\text{old} }[/math] and calculate the resulting errors [math]\displaystyle{ e_\text{new} }[/math] and [math]\displaystyle{ e_\text{old} }[/math]. The order of convergence is then approximated by the following formula:

[math]\displaystyle{ q \approx \frac{\log(e_\text{new}/e_\text{old})}{\log(h_\text{new}/h_\text{old})}, }[/math][citation needed]
which comes from writing the truncation error, at the old and new grid spacings, as

[math]\displaystyle{ e = |y_n - f(x_n)| = \mathcal{O}(h^{q}). }[/math]
The error [math]\displaystyle{ e }[/math] is, more specifically, a global truncation error (GTE), in that it represents a sum of errors accumulated over all [math]\displaystyle{ n }[/math] iterations, as opposed to a local truncation error (LTE) over just one iteration.

Example of discretization methods
Consider the ordinary differential equation

[math]\displaystyle{ \frac{dy}{dx} = -\kappa y }[/math]
with initial condition [math]\displaystyle{ y(0) = y_0 }[/math]. We can solve this equation using the Forward Euler scheme for numerical discretization:

[math]\displaystyle{ \frac{y_{n+1} - y_n}{h} = -\kappa y_{n}, }[/math]
which generates the sequence

[math]\displaystyle{ y_{n+1} = y_n(1 - h\kappa). }[/math]
In terms of [math]\displaystyle{ y(0) = y_0 }[/math], this sequence is as follows, from the Binomial theorem: [math]\displaystyle{ y_{n} = y_0(1 - h\kappa)^n = y_0\left(1 - nh\kappa + n(n-1)\frac{h^2\kappa^2}{2} + ....\right). }[/math]

The exact solution to this ODE is [math]\displaystyle{ y = f(x) = y_0\exp(-\kappa x) }[/math], corresponding to the following Taylor expansion in [math]\displaystyle{ h\kappa }[/math] for [math]\displaystyle{ h\kappa \ll 1 }[/math]: [math]\displaystyle{ f(x_n) = f(nh) = y_0\exp(-\kappa nh) = y_0\left[\exp(-\kappa h)\right]^n = y_0\left(1 - h\kappa + \frac{h^2\kappa^2}{2} + ....\right)^n = y_0\left(1 - nh\kappa + \frac{n^2h^2\kappa^2}{2} + ...\right). }[/math]

In this case, the truncation error is

[math]\displaystyle{ e = |y_n - f(x_n)| = \frac{nh^2\kappa^2}{2} = \mathcal{O}(h^{2}), }[/math]
so [math]\displaystyle{ (y_n) }[/math] converges to [math]\displaystyle{ f(x_n) }[/math] with a convergence rate [math]\displaystyle{ q = 2 }[/math].

Examples (continued)
The sequence [math]\displaystyle{ (d_k) }[/math] with [math]\displaystyle{ d_k = 1/(k+1) }[/math] was introduced above. This sequence converges with order 1 according to the convention for discretization methods.[why?]

The sequence [math]\displaystyle{ (a_k) }[/math] with [math]\displaystyle{ a_k = 2^{-k} }[/math], which was also introduced above, converges with order q for every number q. It is said to converge exponentially using the convention for discretization methods. However, it only converges linearly (that is, with order 1) using the convention for iterative methods.[why?]

Recurrent sequences and fixed points
The case of recurrent sequences [math]\displaystyle{ x_{n+1}:=f(x_n) }[/math] which occurs in dynamical systems and in the context of various fixed-point theorems is of particular interest. Assuming that the relevant derivatives of f are continuous, one can (easily) show that for a fixed point [math]\displaystyle{ f(p)=p }[/math] such that [math]\displaystyle{ |f'(p)| \lt 1 }[/math], one has at least linear convergence for any starting value [math]\displaystyle{ x_0 }[/math] sufficiently close to p. If [math]\displaystyle{ |f'(p)| = 0 }[/math] and [math]\displaystyle{ |f''(p)| \lt 1 }[/math], then one has at least quadratic convergence, and so on. If [math]\displaystyle{ |f'(p)| \gt 1 }[/math], then one has a repulsive fixed point and no starting value will produce a sequence converging to p (unless one directly jumps to the point p itself).

Acceleration of convergence
Many methods exist to increase the rate of convergence of a given sequence, i.e. to transform a given sequence into one converging faster to the same limit. Such techniques are in general known as "series acceleration". The goal of the transformed sequence is to reduce the computational cost of the calculation. One example of series acceleration is Aitken's delta-squared process. These methods in general (and in particular Aitken's method) do not increase the order of convergence, and are useful only if initially the convergence is not faster than linear: If [math]\displaystyle{ (x_n) }[/math] convergences linearly, one gets a sequence [math]\displaystyle{ (a_n) }[/math] that still converges linearly (except for pathologically designed special cases), but faster in the sense that [math]\displaystyle{ \lim (a_n-L)/(x_n-L)= 0 }[/math]. On the other hand, if the convergence is already of order ≥ 2, Aitken's method will bring no improvement.

References
 Ruye, Wang (2015-02-12). "Order and rate of convergence".
 Senning, Jonathan R.. "Computing and Estimating the Rate of Convergence".
 Bockelman, Brian (2005). "Rates of Convergence".
 Hundley, Douglas. "Rate of Convergence".
 Porta, F. A. (1989). "On Q-Order and R-Order of Convergence". Journal of Optimization Theory and Applications 63 (3): 415–431. doi:10.1007/BF00939805. Retrieved 2020-07-31.
 Senning, Jonathan R.. "Computing and Estimating the Rate of Convergence".
 Arnold, Mark. "Order of Convergence".
 Van Tuyl, Andrew H. (1994). "Acceleration of convergence of a family of logarithmically convergent sequences". Mathematics of Computation 63 (207): 229–246. doi:10.2307/2153571. Retrieved 2020-08-02.
 Nocedal, Jorge; Wright, Stephen J. (2006). Numerical Optimization (2nd ed.). Berlin, New York: Springer-Verlag. ISBN 978-0-387-30303-1.
Literature
The simple definition is used in

Michelle Schatzman (2002), Numerical analysis: a mathematical introduction, Clarendon Press, Oxford. ISBN 0-19-850279-6.
The extended definition is used in

Walter Gautschi (1997), Numerical analysis: an introduction, Birkhäuser, Boston. ISBN 0-8176-3895-4.
Endre Süli and David Mayers (2003), An introduction to numerical analysis, Cambridge University Press. ISBN 0-521-00794-1.
The Big O definition is used in

Richard L. Burden and J. Douglas Faires (2001), Numerical Analysis (7th ed.), Brooks/Cole. ISBN 0-534-38216-9
The terms Q-linear and R-linear are used in; The Big O definition when using Taylor series is used in

Nocedal, Jorge; Wright, Stephen J. (2006). Numerical Optimization (2nd ed.). Berlin, New York: Springer-Verlag. pp. 619+620. ISBN 978-0-387-30303-1..
]]]
[[[
https://mathworld.wolfram.com/GeneralizedContinuedFraction.html
===
Generalized Continued Fraction
A generalized continued fraction is an expression of the form

 b_0+(a_1)/(b_1+(a_2)/(b_2+(a_3)/(b_3+...))), 	
(1)
where the partial numerators a_1,a_2,... and partial denominators b_0,b_1,b_2,... may in general be integers, real numbers, complex numbers, or functions (Rockett and Szüsz, 1992, p. 1). Generalized continued fractions may also be written in the forms

 x=b_0+(a_1)/(b_1+)(a_2)/(b_2+)... 	
(2)
or

 x=b_0+K_(n=1)^infty(a_n)/(b_n). 	
(3)
Note that letters other than a_n/b_n are sometimes also used; for example, the documentation for ContinuedFractionK[f, g, {i, imin, imax}] in the Wolfram Language uses f_n/g_n.

Padé approximants provide another method of expanding functions, namely as a ratio of two power series. The quotient-difference algorithm allows interconversion of continued fraction, power series, and rational function approximations.

A small sample of closed-form continued fraction constants is given in the following table (cf. Euler 1775). The Ramanujan continued fractions provide another fascinating class of continued fraction constants, and the Rogers-Ramanujan continued fraction is an example of a convergent generalized continued fraction function where a simple definition leads to quite intricate structure.

continued fraction	value	approximate	OEIS
K_(n=1)^(infty)1/k	(I_1(2))/(I_0(2))	0.697774...	A052119
K_(n=1)^(infty)k/k	(e-1)^(-1)	0.581976...	A073333
1+K_(n=1)^(infty)k/1	sqrt(2/(epi))[erfc(2^(-1/2))]^(-1)	1.525135...	A111129
K_(n=1)^(infty)k/k	(sqrt(e)-1)^(-1)	1.541494...	A113011
The value

 (A_n)/(B_n)=b_0+K_(k=1)^n(a_k)/(b_k) 	
(4)
is known as the nth convergent of the continued fraction.

A regular continued fraction representation (which is usually what is meant when the term "continued fraction" is used without qualification) of a number x is one for which the partial quotients are all unity (a_n=1), b_0 is an integer, and b_1, b_2, ... are positive integers (Rockett and Szüsz, 1992, p. 3).

Euler showed that if a convergent series can be written in the form

 c_1+c_1c_2+c_1c_2c_3+..., 	
(5)
then it is equal to the continued fraction

 (c_1)/(1-(c_2)/(1+c_2-(c_3)/(1+c_3-...))) 	
(6)
(Borwein et al. 2004, p. 30).

To "round" a regular continued fraction, truncate the last term unless it is +/-1, in which case it should be added to the previous term (Gosper 1972, Item 101A). To take one over a simple continued fraction, add (or possibly delete) an initial 0 term. To negate, take the negative of all terms, optionally using the identity

 [-a,-b,-c,-d,...]=[-a-1,1,b-1,c,d,...]. 	
(7)
A particularly beautiful identity involving the terms of the continued fraction is

 ([a_0,a_1,...,a_n])/([a_0,a_1,...,a_(n-1)])=([a_n,a_(n-1),...,a_1,a_0])/([a_n,a_(n-1),...,a_1]). 	
(8)
There are two possible representations for a finite simple fraction:

 [a_0,...,a_n]={[a_0,...,a_(n-1),a_n-1,1]   for a_n>1; [a_0,...,a_(n-2),a_(n-1)+1]   for a_n=1. 	
(9)
SEE ALSO
Continued Fraction, Continued Fraction Constants, Convergent, Lehner Continued Fraction, Padé Approximant, Partial Denominator, Partial Numerator, Ramanujan Continued Fractions, Regular Continued Fraction, Rogers-Ramanujan Continued Fraction, Simple Continued Fraction
]]]

