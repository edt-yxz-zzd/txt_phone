
e others/数学/编程/差量编程-可逆计算-声明式语言.txt

[[[
范畴论 教科书
可计算性
e others/book/category-theory.txt
e others/book/computability.txt
  view /mnt/m_external_sd/000edt/0my_files/book/math/category\ theory/
  view /mnt/m_external_sd/000edt/0my_files/book/math/computability/

[[
ls /mnt/m_external_sd/000edt/0my_files/book/math/category\ theory/
'Abstract and concrete categories--the joy of cats(1990ed+2004update-web)(Adamek).pdf'
'Axiomatic Method and Category Theory (2014)(Andrei Rodin).pdf'
'Basic Category Theory (2014)(Leinster).pdf'
'Categorical Logic and Type Theory (1999)(Bart Jacobs).djvu'
'Categories for the Working Mathematician (2ed)(1998)(Mac Lane).pdf'
'Category Theory (2ed)(2010)(Steve Awodey).pdf'
'Category Theory for Computing Science (1995-rev20200423)(Michael Barr).pdf'
'Category Theory for Programmers (20181021)(v1.0.0-0-g41e0fc3)(Milewski).pdf'
'Category Theory for Programmers (20190812)(v1.3.0-0-g6bb0bc0)(Milewski).pdf'
'Category Theory for Scientists (dynamic-20130514).pdf'
'Category Theory for Scientists (static-20130205).pdf'
'Category Theory in Context (2014)(Emily).pdf'
'Conceptual Mathematics--A First Introduction to Categories (2ed)(2009)(Lawvere).pdf'
'Introduction to CATEGORY THEORY and CATEGORICAL LOGIC (Thomas Streicher).pdf'
'Introduction to Categories and Categorical Logic (Samson Abramsky)(2006-2011).pdf'
'Introduction to Categories and Categorical Logic (Samson Abramsky).pdf'
'Topoi--The Categorial Analysis of Logic (1983)(Robert Goldblatt).pdf'
'范畴论(2006)(贺伟)(书签+去水印).pdf'
]]
[[
ls /mnt/m_external_sd/000edt/0my_files/book/math/computability/
'Higher-Order Computability (2015)(Longley).pdf'
'Hilbert Tenth Problem--Intro to Logic,Number Theory,Computability (2019)(Murty).pdf'
'The Foundations of Computability Theory (2ed)(2020)(Borut).pdf'
'The Incomputable--Journeys Beyond the Turing Barrier (2017)(Cooper).pdf'
]]
]]]
[[[[
e others/数学/编程/差量编程-可逆计算-声明式语言.txt
[[
类型/接口 是 公开的稳定的部分
数值/实现 是 细节的特定于平台的特定于版本的多变的不可用作跨模块推导的部分(但可用于 推导/匹配 声明的类型约束)

对称卷积?:
  输入输出的近期历史/完整历史？:
    y[n] = f(y[n-1]..y[n-p],x[n-1]..x[n-q]; x[n])
    可逆:x[n] = g(y[n-1]..y[n-p],x[n-1]..x[n-q]; y[n])

流-树
  码流->码流
    编码/解码:bytes<->str
    语境无关-词法分析:str->[token]
    宏展开
    ==
    基础有限状态码 byte/char 单值 #可对 整值 归类，也可直接将值当成 种类
    复合结构状态码 token = 种类+属性表
    ==
    地址，多层次地址
  码流->{(中途状态,半切树/构造中途的不完整的树)}
    语境无关-句法分析
  树->树
    ==
    节点路径
    面向切面编程，切入点 需要收集 所有信息
      而调用函数本身功能并不需要太多信息
      ==>>应用层不可拆包的信息封装传递##穿透性环境感知+封装隔离保证
        应用:i->o
        切入点:
          (g, g->IO())
          (g, g->i->IO())
          (g, g->i->o->IO())
          (g, g->i->mid->o->IO())
          g=全局整体状态+当前节点路径
  树->码流 #序列化/扁平化

]]
[[

可逆:
  * 原子性可逆
  * 组合 <-> 拆分
    文本拼凑 <-> 正则表达式 不越界
    组合 时：冗余信息 校验，缺失信息 推导
    元素次序？
    元素多路变换，可逆性识别
  ##
  高层操作 映射到 底层操作，语义丢失
    高层：删除 过滤器 指定的行
      动机/原由 驱动
    底层：删除 第几行
      直接地址驱动
    高层操作不变，当目标表格改变时，底层操作发生改变，即 底层操作序列 依赖于输入，不具可分离性
      补丁 完全 锚定 唯一输入
      可移植差量:
        d=A'-A=B'-B
        B'=B+(A'-A)
  ===
  绝对差量vs相对差量vs幂等差量
  绝对差量
    (+=1)
  相对差量
    (*=1.5)
  幂等差量
    (+=1 until >=4)#允许的变换序列+终态判定条件
  ===
  f(x)=y
  f(x+dx)=y+dy
  Df(x,dx)=dy
  可移植差量？
  ===
  中间节点-节省算力
    人为？自动化搜索等同别名(引用透明-反向整合)？
    存储用紧凑表达形式(抽象概念，强调等同)vs动态修改快速访问用带冗余展开表达形式(具象构造树，强调等价)
  ===
  输入相容与否
    输出与输入相容与否:检查 输入相容性 乃至 算法正确性
  ===
  输入分量-正交vs相互约束带冗余-覆盖vs狭义抽取
    狭义视图 #不可逆 用作 构造器
  ===
  同畴映射？畴内映射？endofunction
  同象映射？象内映射？endofunction
    允许哪些变换作用于输入？==>>解空间
      棋盘状态行棋规则
      命题推导证明
      term rewrite
    单个输出满足哪些约束？==>>可行解
      枚举/搜索
      离散枚举、正交随机构造、连续梯度
    输出在所有可行解中是什么地位？==>>稳定性
      最小化某个特征
    ===同畴？整体状态分解为多个子分量，单一同畴映射分解为多个多中间状态分量到单中间状态分量的触发动作函数，wanted/wanting消息洪流自动填充
    =畴domain #类/种类
  ===
  [i->(o1,o2)] <==> [i->o1][i->o2]
  [(i1|i2)->o] <==> [i1->o][i2->o]
  但[(i1,i2)->(o1|o2)]无法拆分
  ===
  外延 内涵
  当将对象进行编码，通常是对内涵的编码
    很难判断函数是否外延等价，更别说针对外延编码
  高阶函数:将 某些输入数据 解码 用作 函数
    编码~内涵
  ===
]]

[[[
声明式语言
  定义实体/命名  +  关系描述
    事实+规则？fact+rule
  关系描述 = 谓词-连词 + 名词?
    但考虑一下cmake，输入相同，也可以有很多选项
      额外参数/带外信息/注解
        一份数据 如果带有 额外信息，则意味着 有多种用途
        多用途/多切面 数据
          标注 参数/选项 的 目的/用途/应用
  关系描述 = 谓词-连词 + 修饰谓词的副词 + 名词 + 修饰名词的形容词
  ===
  直接描述 结果状态/输出
[[
]]
[[
]]
[[
]]
[[
xxxxxx
]]
[[
https://zhuanlan.zhihu.com/p/19908708
尹璋琦
科研等 2 个话题下的优秀答主
从可逆经典计算到量子计算
7 年前 · 来自专栏 量子世界

最近在从新读有关可逆经典计算的文献，学到一些有趣的结果，在这里记录一下。

我们知道经典逻辑门很多都是不可逆的，比如说与门，或门。后来Toffoli和Fredkin等人发现，实际上经典物理也允许可逆的逻辑门存在。比方说，Toffoli定义了一个可逆的Toffoli逻辑门，包含三个输入，三个输出。如果我们只用到其中的某个输出，那么可以构造出逻辑上不可逆的与非门，用这个逻辑门完全可以构造出任意的经典逻辑电路出来。换句话说，用Toffoli门就可以构造出可逆的经典计算电路。再完成计算之后，再把逻辑门按照逆序操作一次，我们会发现整个计算过程并没有消耗能量。

量子计算兴起之后，我们发现量子系统演化的幺正性天然保证了计算的可逆性。人们也在寻找什么是通用的量子逻辑门。最早确认的一组是两比特的控制非门和两个正交的单比特逻辑门。有没有可能找到更少的通用量子逻辑门呢？后来Yaoyun Shi发现只用Toffoli门加上单比特的Hadamard 门就可以构造出任意的量子电路。

这个结论有可以用下面这句话概括：量子计算超越经典计算的地方就在于多了单比特的Hadamard门，或者说所有的量子计算算法不过就是经典计算机加上Hadamard门。
编辑于 2015-03-18 17:24

]]
[[
https://zhuanlan.zhihu.com/p/344845973
[
领域抽象是发现领域中的本质性要素和它们之间的作用关系，换句话说，其实就是削减不必要的需求。当我们在一个领域浸淫多年，有了充分的领域知识之后，我们会发现很多需求都是没必要的细节，我们完全可以选择只做性价比高的事情。如果将这种领域知识沉淀为某种领域特定的描述语言，则我们就可以极大的降低信息的表达量。举个例子，前端css框架bootstrap库本质上是对前端结构的重新认识，它将颜色限定为success/info/warning/danger等少数几种，将尺寸限制为sm/md/lg等，而将布局限制为一行仅有12个可选位置。用惯了bootstrap之后，我们会发现实际上多数时候我们并不需要那么丰富的颜色搭配，也不需要那么多种尺寸选择。通过主动限制自己的能力之后，我们通过自律反而获得了某种自由--减少了不必要的决策和要求，同时达到了风格上的统一。

模型对于复杂性的化简往往是乘性的。比如说，100种可能情况如果通过两个基本要素的交叉组合来描述，100 = 10*10, 则我们只需要定义20个基本要素和一个组合规则即可。不止于此，模型的更大的价值在于它提供了关于系统的全局性的知识。比如，在有限自动机模型中，a->b->c->a，一系列状态迁移后系统并不会发散，而必然会回归到某个已知状态。而在自相似的嵌套模型中，整体由部分组成，部分结构放大后又回归到已知的描述。

全局性的知识极大的便利了信息的传播和推导。例如，如果所有组件实例在运行时都有唯一的名称和稳定的定位路径，则我们可以利用它来实现数据自动绑定（与Store中的数据项自动对齐），客户点击追踪等。而在传统的编程活动中，我们所依赖的主要是通用的、领域无关的程序语言和组件库等，缺少全局性的统一的结构约束，很容易就会破坏全局性的结构假定，导致自动推理链条的中断，只能通过程序员的手工工作负责接续。现代软件设计范式中强调约定优于配置（convention over configuration），其要点也正在于利用和保留全局知识。
]

canonical
千山万水
从可逆计算看LowCode
1 年前 · 来自专栏 可逆计算

2020年低代码（LowCode）这一buzzword频繁亮相于主流技术媒体，大背景下是微软/亚马逊/阿里/华为等巨头纷纷入场，推出自己的相应产品。一时之间，大大小小的技术山头，无论自己原先是搞OA/ERP/IOT/AI的，但凡认为自己有点技术的厂商，不说改旗易帜，至少也要加绣一条LowCode的花边，表示不落人后。

根据Gartner 2019年的LowCode报告，LowCode未来的钱景可谓是一片光明：

    到2024年，四分之三的大型企业将使用至少四种低代码开发工具进行IT应用程序开发和公民开发（citizen development，可以认为是非IT背景的用户进行开发，例如：业务用户/产品经理/业务顾问等）。 到2024年，低代码应用程序开发将承担65%以上的应用程序开发活动。

向LowCode转型意味着软件将进入工业化生产阶段。但自从上世纪七十年代以来，这种转向尝试早已不是什么新鲜事情，这一轮的LowCode运动又有什么特殊之处？它凭什么能完成前辈未竟之事业？本文试图从可逆计算理论的角度针对LowCode中的一些技术问题谈谈自己的看法。
canonical：可逆计算：下一代软件构造理论131 赞同 · 41 评论文章
一. LowCode的本质是什么？

LowCode，顾名思义就是 Code Low，在软件产品的构建过程中大幅降低所谓代码编程活动所占的比例。显然，LowCode这一说法仅仅是一种愿望表达，即我们希望大幅降低代码编程量，这意味着更少的工作、更快的交付、更稳的系统，然后从老板的角度，它带来更低的成本、更高的利润和更广的市场等。作为一种朴素而美好的愿望，LowCode的本质与FastCode/CleanCode一样，那就是它没有什么本质，或者说它的本质就是对理想中的一种现象的描述。当所有其他指标都相同的情况下，FastCode肯定比SlowCode强，同样的，在提供同样功能特性的前提下，LowCode肯定比HighCode更让人青睐。

相比于Case工具、模型驱动、产生式编程等等看似高大上，但实际不知所云的专业概念，LowCode无疑是更具体的、更亲民的，特别是结合可视化拖拉拽取代程序员、全流程免运维等这些商业上鼓吹的具有立竿见影的经济效益的卖点，更容易打动圈外的人。

实际上LowCode更像是一面旗帜，所有能够减少Code的实践和理念都可以归于其麾下，而且我们几乎可以肯定的说，LowCode一定是走在正确的技术发展道路上。你能想象500年后人们还像今天一样人肉码代码吗？如果那时候人类还没有灭绝，大概也不会再需要现在这种程序员去写什么业务代码了吧。坚信Code不会被LowCode取代的人明显是缺乏未来视角。在走向智能社会的过程中，我们一定会经历一个智力工作逐步向机器转移，Code逐步减少的过程，那LowCode岂不就是通向未来之路吗？

LowCode具体的技术内涵与外延目前并没有确定下来，现有LowCode产品厂商的具体做法也很难被定性为最佳实践，甚至可以说按照现有的方案实际上是很难兑现其商业宣传中的各种神奇疗效的。如果LowCode真的能深刻的改变技术和商业领域，那还需要我们做出更多革命性的探索才行。
二. LowCode一定需要可视化设计吗？

LowCode减少编码工作无外乎有两种方式：

    实质性的减少针对特定业务所需要编写的代码量
    将传统上需要编码的工作转化为非编码的活动

可视化设计在LowCode中的作用就对应于第二种方式。相比于编程，它有两个优点：

    可视化交互更加直观具体，所需编程知识更少
    可视化交互约束性更强，更不容易出错

可视化设计无疑是目前LowCode平台厂商的核心卖点之一。但如果第一种抽象方式做得足够简单，我们并不一定需要可视化设计器。买不起豪华设计的穷人一样可以LowCode。很多时候我们只需要针对业务领域制定一个专用的领域语言就可以在很大程度上解决问题。例如目前所有创作类网站广泛使用的MarkDown语法，相比于复杂的文字排版软件其功能无疑弱到了极点，但关键是它在大多数日常场景下够用啊，而且具有内生的扩展机制，允许通过自定义扩展来适应各种特殊情况（比如嵌入公式、图表，甚至任意HTML等）。通过这种设计上的偏置，我们可以极大简化常见场景的复杂度，从而使得可视化设计成为次级的设计目标。

一个很有趣的问题是，可视化设计是否生产力更高？很多程序员估计是要举双手双脚反对的。实际上，按照目前可视化设计工具的现状，设计器的输出产物有可能复杂度会超过直接手写的代码。更不用说，设计器相比于代码还存在多种缺陷：

    无法像代码文本那样采用多种工具、多种手段对目标进行自由编辑。
    无法像代码中的函数封装那样以简单的方式实现二次抽象，很多设计器甚至连简陋的组件组合和暂存机制都不提供。
    无法像代码中的继承和接口注入机制那样，对设计工具和设计产物进行局部修正和调整。

可逆计算理论针对以上问题提出了自己的解决方案，它指出可视化设计是可逆性的一种自然推论：

[公式]

领域特定语言DSL具有多种表达形式（文本和图形化），这些展现形式之间可以可逆转换。DSL内置通用的二次封装和差量扩展机制。设计器本身不是固化的产品，而是由元设计器结合DSL的结构信息动态生成，从而实现设计器与应用描述之间的协同演化。
三. LowCode要怎么Low?

如果把软件产品生产看作是对信息的一种加工过程，那么上一节所提到的LowCode的变Low的策略实际就是：

    减少信息表达
    采用Code之外的形式表达

如果我们仔细观察一下市面上的LowCode产品，会发现一些有趣的现象。以http://ivx.cn为例，它面向的用户是非专业程序员，能够以完全免编程的方式来设计界面和后台逻辑。这种所谓NoCode的方式确实可以降低对使用者的技术要求，它所依赖的除了可视化设计器所提供的直观性之外，还在于它主动的限制了使用者所面对的设计空间，放弃了编程中的很多便利性和灵活性，通过降低设计空间中的信息密度来达到降低技术能力要求的目的。

比如说，在一般的编程实践中，我们需要了解各种变量的作用域以及作用域之间的关系，在ivx中没有这些概念，都类似全局变量。编程时，我们可以写复杂的链式调用a.b(g(3)).f('abc')，在ivx中也不存在这种概念，设计器中的一行只能表达单一一个动作。对于完成工作这一基本要求来说，我们编程中所习惯的大量特性确实是没有必要的，限制“做一件事只有一种方式，执行一个动作只会产生一种后果”使得入门变得更加容易。

但是，需要警惕过度的简化会限制平台自身的能力上限，导致难以参与到更加复杂和更加高价值的生产活动中。

如果要求LowCode能够辅助专业开发，那么它一定要能在某种程度上本质性的减少信息表达。为了做到这一点，我们已知的策略大概有如下几种：

    系统化的组件重用基于领域抽象的模型驱动全端、全流程、全生命周期的一体化设计

3.1 组件重用

组件重用是降低系统复杂度的一种通用策略：将复杂的对象分解，然后识别出重复的组分。LowCode的不同之处在于，它鼓吹一种系统化的组件重用，比如提供完整的开箱即用的组件库，无需程序员到处收集，而且确保所有组件可以正确组合，并提供适当的文档和良好的设计器支持，同时组件的生产和消费过程也可以被纳入LowCode平台的管理范围，比如提供公开的物料库和组件市场等。目前LowCode领域所缺乏的是一种得到广泛支持的组件描述标准（可以类似Jetbrains公司的web-types标准 https://github.com/JetBrains/web-types），它使得不同来源的组件库可以在统一的层面得到管理。

    组件重用属于哲学上还原论的一种应用。还原论最成功的范例无疑是原子论。纷繁芜杂的世界表象下竟然是区区百来种原子的支撑，这无疑是关于我们这个世界的最深刻的洞察。但是，认识了原子并不等于认识了世界，大量的信息存在于原子的组合过程中，我们还需要对这个世界的多层次的、整体性的认识。

当前组件技术所面临的挑战在于，我们对于组件的动态性、可组合性、环境适应性等要求越来越高，因此必须要引入超越单个组件视角的、更加系统化的解决方案。比如，我们可能希望一套组件能够适应桌面端、移动端、小程序等多种运行环境。LowCode平台所提供的标准的解决方案是转译技术：把同一套组件描述针对不同的运行环境翻译为不同的具体组件实现（而不是把针对多种运行环境的实现细节封装在组件内部）。当转译成为一种日常之后，我们也就开始走入了模型的世界。
3.2 模型驱动

根据量子力学，在我们的世界中信息是守恒的。如果向一个系统投入少量信息就能够产生大量有价值的结果，那只可能是两个原因：

    看似多样化的结果背后存在一个简单的逻辑内核，系统的本质复杂性并不如表面上看起来那么高。
    结合其他信息源和全局知识，系统自动推导出了大量的衍生结果。

为了构造这样一个非线性（投入和产出不成正比）的生产系统，我们首先需要建立领域抽象，然后基于领域抽象建立一个可以被少量信息驱动的产品工厂。

领域抽象是发现领域中的本质性要素和它们之间的作用关系，换句话说，其实就是削减不必要的需求。当我们在一个领域浸淫多年，有了充分的领域知识之后，我们会发现很多需求都是没必要的细节，我们完全可以选择只做性价比高的事情。如果将这种领域知识沉淀为某种领域特定的描述语言，则我们就可以极大的降低信息的表达量。举个例子，前端css框架bootstrap库本质上是对前端结构的重新认识，它将颜色限定为success/info/warning/danger等少数几种，将尺寸限制为sm/md/lg等，而将布局限制为一行仅有12个可选位置。用惯了bootstrap之后，我们会发现实际上多数时候我们并不需要那么丰富的颜色搭配，也不需要那么多种尺寸选择。通过主动限制自己的能力之后，我们通过自律反而获得了某种自由--减少了不必要的决策和要求，同时达到了风格上的统一。

模型对于复杂性的化简往往是乘性的。比如说，100种可能情况如果通过两个基本要素的交叉组合来描述，100 = 10*10, 则我们只需要定义20个基本要素和一个组合规则即可。不止于此，模型的更大的价值在于它提供了关于系统的全局性的知识。比如，在有限自动机模型中，a->b->c->a，一系列状态迁移后系统并不会发散，而必然会回归到某个已知状态。而在自相似的嵌套模型中，整体由部分组成，部分结构放大后又回归到已知的描述。

全局性的知识极大的便利了信息的传播和推导。例如，如果所有组件实例在运行时都有唯一的名称和稳定的定位路径，则我们可以利用它来实现数据自动绑定（与Store中的数据项自动对齐），客户点击追踪等。而在传统的编程活动中，我们所依赖的主要是通用的、领域无关的程序语言和组件库等，缺少全局性的统一的结构约束，很容易就会破坏全局性的结构假定，导致自动推理链条的中断，只能通过程序员的手工工作负责接续。现代软件设计范式中强调约定优于配置（convention over configuration），其要点也正在于利用和保留全局知识。

模型描述所提供的知识，其用途往往是多样化的，可以参与多种推导过程。例如，根据数据模型，我们可以自动生成数据库定义/数据迁移脚本/界面描述/数据存取代码/接口文档等。而在传统的编程方式中，一段代码它的用途往往是唯一的。

LowCode平台目前的主流做法首先是试图提供一个“更好”的编程模型，然后再内置或者集成大量的领域特定的服务或程序模板。这个所谓的更好当然是仁者见仁，智者见智。有一些相当于是弥补当前编程语言的不足，提供增强的语法特性。比如自动将符合某些条件的同步操作翻译为异步调用，自动实现远程调用代理等，甚至自动实现分布式调度等。有一些是整合最佳实践，降低开发难度，比如将底层的React/Redux封装为类Vue的响应式数据驱动模型。而另一些则是引入更强的假定，缩小了编程模型的适用范围但是增强了平台的控制力，比如简化前端模板语言，自动将模板与前后端模型对象绑定，提供模板到多端的渲染能力支持等。

LowCode平台一般都会内置表单模型、规则模型、流程模型、BI图表模型等通用开发领域常见的模型引擎，同时可能提供丰富的前端界面模板、大屏展示模板等物料资源。很多还会提供领域特定的服务支持，比如针对IOT数据的流式数据处理服务等。
3.3 一体化设计

根据热力学，对于我们所观察到的世界，信息总是耗散的。当信息经过系统的边界不断传递时，它可能会丢失，会扭曲，会冲突。在日常工作中，我们很大一部分工作量不是在做什么新的事情，而是重复实现数据的格式调整、完整性验证、接口适配等本质上属于对接转换的工作。

我们所处的技术环境本身一直处在变动不居的持续演化过程中，这也成为持久的混乱之源。把编译环境架设起来，保证持续集成能够稳定运行并不是一件很简单的事情。经常会发现新人下载源码之后，半天编译打包不成功。移动端、云环境、分布式等复杂的运行环境使得非功能性需求的重要性不断上升，相应所需的知识量也在不断的膨胀。

监控运维和运营数据分析目前已经成为在线软件不可或缺的组成部分，也倒逼着功能开发必须要为运维埋点和数据分析提供支持。

目前LowCode平台对这一系列挑战的回答一般是一个涵盖各种输入输出端点、开发部署测试发布全流程、软件生产运维退役全生命周期的大统一的解决方案。一体化的设计便于减少信息的损耗，避免信息的重复表达，维护模型语义的一致性，屏蔽底层工具遍地是坑的悲惨现实。但无疑，这也是一柄双刃剑。维持一个遗世独立的稳定的乌托邦，需要非常大的投入。可能巨型的公司可以利用LowCode形式来作为自身基础能力的输出，反正它们本身就需要再造很多工具，而且希望其他人绑定到自身所提供的技术生态上，而第三方本身对依赖巨头也存在着默认可接受的事实。
四. LowCode与模型驱动有区别吗？

从目前的实际技术路线来看，LowCode平台目前所采用的策略方针与传统模型驱动领域并无本质的区别。只不过是在新时代的技术场景下，新技术的诞生使得一些事情变得更加简单，而开源技术的广泛流行使得各人能够操纵的技术元素和技术范围变得更加广泛了而已。确实，如果能够把稳定性问题完全外包给云计算基础设施，小团队借助适当工具后的开发能力完全可以支撑传统上的大型软件的研发工作。

新的时代也产生了新的需求，新的需求会促生新的思想。LowCode可以定位为继组件技术之后，试图实现超越组件粒度的、粗粒度、系统级的软件复用的一种集大成的实践集合。

    从编程思想上说，传统的模型驱动基本还是把整体研发逻辑适配到某种面向对象编程范式上，而目前随着函数式和流处理的兴起，多模型范式是一种必然的选择。传统的复用虽然目标设想的很大，但实际的操作路线比较粗糙，大多数情况下只是简单的实现参数化。

从可逆计算理论角度考察，我认为LowCode与传统模型驱动的一个差别可以是基于差量模型驱动的、拥抱模型演化的设计。对于任何一个模型，我们可以问一个简单的问题：能否允许定制，如何定制？追加一个问题就是：模型如何分解，如何在模型基础上实现二次抽象？

对模型可以增加一个衡量标准：是否可逆。很多问题，当我们明确意识到可逆性的存在和必要性之后，就开始变得明晰起来。

从适用的技术手段上说，随着转译技术的发展，和编译器技术的普及，目前在语言级别动刀子也不再是一件难以想象的事情。实际上，很多库作者的实际做法就已经是进入传统编译技术的领域了。在我们的武器库中增加了这一手段之后，特别是在应用层开放使用这种能力之后，很多拓扑结构上难以处理的大范围的信息传导问题就很容易解决。形式稳定性问题在使用本征表示之后往往也得以解决。

抽象最基本的方法是参数化。建立一个函数，把可变的部分作为参数抽象出去F ==> F(x)。如果有很多变化，就变成了

​    F(X1, X2, X3, ....)

如果从很粗糙的角度考虑，一个模型的复杂度我们可以从所需参数的个数来衡量，参数少的就是复杂度低，参数多的就是复杂度高。比如，如果参数X1,X2,X3之间是相互独立的，则模型所描述的可变范围显然和 X1, X2, X3的交叉积的个数直接对应。但是，实际的世界往往更加复杂，参数足够多之后，它们并不是互相独立的！

我们理解F(X1,X2,X3)的前提是，我们需要理解F，还需要理解X1,X2,X3在F内部传播并与F发生相互作用的具体过程。如果参数是相互影响的，情况可能还要更加糟糕，那就是我们需要理解这种相互影响到底是如何以微妙的方式发生的。但是，一个真正有趣的情况在于，如果我们为X1,X2,X3建立规范化的结构约束后会怎样？当参数足够复杂之后，它有可能自身构成一个有序变化的整体，我们可以用一个领域模型M来对它进行描述，从而使得我们可以在不依赖于F的情况下独立的理解M。

我们这个世界底层的逻辑是层展的。也就是说我们可以在不同的层面基于不同的结构建立对系统的理解。从一个层面进入到另一个层面时，我们对它们的理解可能是独立的（一个完备的参数系统升华为一个独立的概念空间）。当我们引入结构，并主动的管理概念结构时，我们所面对的复杂性情况就完全不同了。

参数化演变的终点是 f(DSL), 所有x构成一个有机变化的整体，从而实现整体领域逻辑的一种描述方式，而f成为领域的支撑能力。当然一个有效的DSL只能是描述某个业务切面，所以需要 f(DSL1) + g(DSL2）+ 。。。， 总结下来就是 Y = G(DSL) + delta

抽象的一个常见问题是抽象泄露。如果我们抽象出的DSL与实际情况不符合怎么办？在可逆差量的视角下，这个问题可以这么解决:

Biz = App - G(DSL1)

把剥离领域描述DSL1之后剩下的部分Biz看作是一个独立的研究对象。这类似于物理上我们可以把高斯模型作为系统的零阶解, 然后把原始方程重新表述为修正量所对应的1阶方程。

从底层技术的基本逻辑来说，很多业务问题背后的技术结构是似曾相识的，但是目前主流的技术手段并不足以我们把相应的技术实现从一种技术场景迁移到其他技术场景。总是有很多技术实现和业务内容强绑定，需要程序员拷贝粘贴过来之后手工进行剪裁修正。通过DSL抽象和差量化处理，我们可以实现不同层面逻辑的一种新的拆分模式，例如在不打开引擎盖的情况下换发动机。

程序员是站在上帝视角看待软件系统的，他并不需要完全被动的接收系统中的事实。上帝说，要有光，于是就有了光。程序员可以自己设计规则（Rule/Law），并约束所有元素的行为。现在有些人认为LowCode只能做从0到1的原型开发，最终还是要通过DDD之类的传统技术重构，这大概是认为LowCode只能是把业务对齐到少数内置的模型上，而不能根据领域的实际情况提供最合适的逻辑分解。而可逆计算的视角不同，它强调DSL本身应该是可定制的，可以根据需求变化做自由扩展。同时类似JetBrains公司的MPS系统，可逆计算的支撑技术应该是一种领域语言工作台，它为领域语言的开发/运行提供完整的解决方案。
五. LowCode需要技术中立吗？

LowCode试图实现更高级的复用，那么技术生态的分裂所导致的这种偶然的依赖性必然是它要试图屏蔽的内容。同样的逻辑内容为什么使用java实现了之后在typescript不能被直接使用？

技术中立存在几种策略：

    微服务。通过技术中立的通信协议实现分离，这是一种非常规范而成熟的方案。而且随着内核网络栈的优化，例如引入RDMA和DPDK技术，Sidecar模式下跨进程调用的性能极度优化后可以与进程内调用可比。
    虚拟机。GraalVM提供了通过编译混杂不同的技术栈的作用，这也是非常有前途的一种方向，它的好处是可以跨越技术边界实现协同优化。而在微服务的方案中，Java调用JavaScript的代码不能进行统一优化。
    领域语言。这是一种低成本的，控制权由普通程序员掌握的方案。如果编写解释器的复杂性能够进一步降低，比如类似于一个解释规则就是简单对应于一个函数调用，它可以成为我们解决日常业务问题的一种常规手段。

如果把每种具体的实现技术看作是一种不同的坐标系，那么采用不同的技术去实现就相当于是把一个确定的逻辑使用不同的坐标系统去表示。那么数学上是如何处理坐标无关量的？物理学的所有原理都是所谓参照系无关的，也就是坐标无关的，它们都采用所谓的张量（Tensor）来表示。张量的坐标无关本质上说的是，一个物理量在不同的坐标系里有不同的具体表示，这些具体的表示之间通过某种可逆的结构变换联系在一起。坐标中立并不意味着绑定到某种坐标系中，而是不同的坐标之间可以可逆转换。

所以依据可逆计算理论，我们并不一定要强求大一统设计，强求所有地方的信息表达都只有唯一的一种形式。而可以是多种表达，只要存在某种预定义的可逆机制可以从系统中反向抽取信息并自动进行转换即可。比如，现有的接口定义都存在接口描述，无论是采用protobuf描述，还是jsonrpc，抑或是grpc。因为它们都是描述式信息。原则上我们是可以根据其中一种描述，补充部分信息实现这些结构描述之间的自由转换的。如果我们的产品可以随时根据接口描述自动生成，它就可以不是一种固化的二进制代码。延迟生成，实际上就是一种多阶段编译技术，它可以是未来LowCode的发展方向。

可逆性是可以分而治之的。当一个庞大模型的每个局部都是可逆的时候，我们就有可能自动得到整体的可逆性。可逆性本身也是可以跨系统的。LowCode的未来不应该是单一的产品或者单一的SAAS应用，而是内与外、上下游可以实现信息的自由传递与转换，突破技术形式的绑定。

坐标中立的体系存在一个特例--零，它为系统带来了一种本质性的化简机制。一个坐标中立的零在所有的坐标系中都仍然保持为零。它的含义在于，有很多运算我们完全可以在坐标中立的表象中完成。大量的判断和结构转换/加工都可以在纯形式的层面完成，它们完全不涉及到复杂的运行时依赖。

可逆计算的一个核心观点是，坐标中立是形式层面的事情，可以完全脱离运行时来讨论。通过编译期的元编程技术，我们可以实现运行时结构与直接手写代码完全相同。LowCode在运行期可以不引入额外的间接处理层。
六. LowCode需要图灵完备吗？

说实话，图灵完备这个概念完全是计算机圈子内部的行话。说起模型，一个模型的重要性和有效性与图灵完备有半毛钱的关系吗？比如，化学分子式无疑是描述分子结构的一种非常有效的领域特定语言，化学反应方程是对具体化学反应过程的一种模型化的描述，它需要是图灵完备的吗？牛顿万有引力方程将天上的星星和地上的苹果联系在一起，是伟大的建模成就，它的计算可以指导四季耕作。微分方程模型的建立和求解需要图灵完备吗？

领域内最核心的知识并不需要图灵完备。我们需要图灵完备的地方是当我们需要做一些“通用”的计算和处理过程的时候，当我们需要机器代替我们去自动化处理某些平平无奇的动作的时候。当我们要以某种未预料的方式来处理某些事情时，我们需要保留图灵完备的处理能力。如果我们已经遇到过这种情况，往往我们能够进行算法封装，把复杂的逻辑运算封装到算法内部，外部使用者并不需要图灵完备。

LowCode为了完成足够广泛范围的工作，它肯定是要保留图灵完备的能力的。但是它所提供的核心的领域模型并不需要图灵完备。图灵完备反而可以只是某种边缘场景的应用。

图灵完备能力的获得可以是通过内嵌的DSL语言。当然这是一种非常廉价的方式，特别是可以充分利用IDE对语言本身的支持来免费获得实现对DSL的支持。但是这种做法的问题在于，嵌入式DSL往往只关注于正确表达的形式直观性，对于偏离DSL形式的情况缺乏约束。也就是说，如果使用者不按照约定的方式去编写DSL是完全可能的，虽然语义上是完全一致的，但从形式上就不符合原始DSL的要求。面向DSL的结构转换也就难以进行下去。

JSX这种方式是一种有趣的扩展形式。因为执行时我们可以获得虚拟DOM节点，相当于是拥有对结构的比较大的控制权限的。但是typescript的问题在于它没有明确的编译期。jsx的编译期处理非常复杂，运行期得到的是具体的VDOM节点。而在编译期我们需要分析代码结构，而因为停机问题的存在，普遍来说代码结构是难以分析的。所以vue template这种编译期可分析的结构是非常重要的。

图灵完备并不是信息完备。反向解析得到信息是目前所有主流技术都缺乏的。图灵完备实际上不利于信息逆向分析。习惯于手写代码的传统导致程序员对于程序结构的自动分析并不重视，因为这些工作此前都是编译器编写者的责任。而如果LowCode可以大规模在应用层使用这种技术，还需要更多的普及教育。现在所有语言的运行时能力很强，但是编译期的逆向能力都很差。很多人倾向于用json，本质上是想把逆向分析/转换的能力掌握到手里。

DSL也不一定意味着特殊的程序语法。我们对于可逆计算的具体实现是直接使用xml模板技术作为前后台统一的结构描述，相当于是直接编写AST抽象语法树。相比于LISP，好处在于结构形式更加丰富一些。显然html格式对于一般人员来说，比lisp还是要更加容易阅读。

可逆计算提供了将扩展能力累加到领域特定逻辑之上的方法。
七. 为了LowCode我们会失去什么？

一个有趣的问题是，LowCode带给我们的都是好处吗？使用LowCode我们会失去什么？

我的回答是，LowCode将使得程序员失去一家独大的控制权。传统的编程方式，所有软件结构的构造都源自于程序员的输入，因为程序员成为了应用和需求人员不可回避的中介。而LowCode技术所带来的一种变革在于，通过将逻辑分层分解，多种信息来源可能独立的参与系统构建。需求人员完全可能绕过程序员直接指示业务模型的构造，并在系统智能的支持下自主的完成业务设计-反馈的循环。当这些人员直接掌握控制权之后，可能他们也不想再回到此前那个需要被动等待的时代。

LowCode的技术策略虽然看来看去似乎并不新鲜，但是它确实在表述和立意上有所不同。它明确强调citizen programming，而此前的model driven本质上还是程序员内部的问题。

任何一场技术革命实质性的结果都是生产力和生产关系的变革。我们已经站在时代的边缘，使得多种信息掌控者：程序员、业务人员、人工智能等等可以通过分工协作、齐头并进的方式参与逻辑系统的构建，使得信息的流动有望突破形式的限制，绕过人类载体，跨越系统边界和时间演化进程。LowCode在传达这一核心概念的时候是不清晰的、存在误导性的。

基于可逆计算理论，我提出了一个新的概念： 下一代软件生产范式-NOP（非编程，NOP is Not Programming）。
canonical：NOP --- 下一代软件生产范式35 赞同 · 9 评论文章

NOP强调了这种生产范式转换所带来的本质性变化。从桌面互联网转向移动互联网技术之后，一个新的理念诞生，那就是所谓的移动优先。当我们设计一个系统时，首先考虑移动端的处理过程，然后再考虑桌面端。类似的，在LowCode的时代，我们在软件生产中需要考虑“描述优先”，通过领域模型将系统的逻辑结构以可以进行差量修正的形式明确表达处理，它作为一种后续的财富，使得我们的系统逻辑可以越来越多的摆脱某种当时当地的技术实现约束的限制，明确记录我们的业务意图。

描述的部分应该和常规代码的部分具有明确的边界。以Antlr4为例，此前的设计中，我们会在描述式的EBNF范式中增加action标注来控制语法解析器的行为，而在Antlr4中明确提出语法文件中只描述语法结构，一些特定的处理过程全部集中到Listener和Visitor处理器中。描述信息完全被隔离之后，antlr立刻摆脱了java的束缚，它可以根据同一份语法定义，生成java/go/typescript等不同语法实现的解析器，同时根据语法描述自动生成IDE语法解析插件，格式化处理器，IDE自动提示等，产生了多种用途。

在我看来，传统上的code使用的逻辑是机器运行的逻辑，把所有逻辑的表述形式都适配到适合图灵机或者lamba演算机运行的形式。但是领域逻辑具有自己特定的表述形式，它的组成元素有自己的作用方式，这些方式可以被直接理解，而不必非要划归为某个图灵机上执行的步骤去理解。一个语言就是一个世界，不同的世界有不同世界观。LowCode不是说code有多low, 而应是表述的方向不同。

LowCode并不等价于让不懂逻辑的人写代码（虽然很多产品试图给人这种错觉让人买单）。实际上很多数学家也不会写程序，但是他们非常懂逻辑。5-10年以后市场上会有不少40岁以上的曾经的程序员，但他们不一定再懂最新的开发技术，用一个更高层的逻辑描述不还是能开发业务逻辑并享用到最新的技术进展吗？
编辑于 2021-01-18 15:18

]]
[[
https://zhuanlan.zhihu.com/p/191845544

NiLang - 可逆计算，微分万物
Leo
理论物理博士
NiLang - 可逆计算，微分万物
1 年前 · 来自专栏 Julia中文社区

人类产生的能源中有2.5%用于计算，其中越来越多的部分用于人工智能产业。1961年，Landauer 从热力学第二定律出发，证明了凡是涉及信息擦除的不可逆过程，都伴随能量的耗散。因此，要解决能耗问题，可逆计算被认为是一种不仅理论严谨，而且在实践层面也很实际的方案，尤其是绝热CMOS技术具有很强的实际可行性。但是，可逆计算在最近的15年逐渐被打入了冷宫，在软件层面有两个原因，

    可逆计算要求现在的软件生态从底层开始重新设计，需要可逆的指令集，可逆的语言，可逆的应用，可逆编程比起传统计算往往具有需要额外的内存或者计算时间的开销

本文将会告诉大家，在人工智能时代，可逆计算的强制计算可逆的缺点将会变成它的优点，它将会是实现程序语言级别自动微分的一个现实的方案。文中，我们使用Julia中的嵌入式编程语言（eDSL）NiLang作为我们的主要可逆编程工具，它是由GiggleLiu（鄙人）和thautwarm一起开发的开源工具。关于这个工具的Tutorial，除了官方文档外，还可以看B站视频
Julia中文社区2020夏季会议（Day3 可逆编程与高性能自动微分）_哔哩哔哩 (゜-゜)つロ 干杯~-bilibili​
www.bilibili.com/video/BV1m64y1c7fT/

以及和这个视频配套的Pluto notebook。在此非常感谢Julia中文社区的工作者们提供这个做Tutorial的机会并上传这个视频。看完Tutorial后，想看更加理论和技术的部分可以查阅参考文献arXiv: 2003.04617。
什么是全语言自动微分？

当我们接触机器学习的时候，一个很重要的过程就是理解后向传播技术，很多小伙伴们跟着吴恩达老师的视频从推导矩阵乘法的后向传播规则开始了解什么是自动微分。我们把矩阵操作和激活函数联结起来构成神经元网络，通过后向传播得到整体神经元网络的导数。人们把常见的可以微分的操作做成了一个集合（软件包），这个操作的集合越来越大，表达能力越来越强。如今人们开始用微分编程，或者是自动微分这些新概念来表现这些自动微分库在对代码微分时候的强大。但是我还是要提醒大家，仍然有很大部分的需要自动微分的代码并不能很好的表达成常见的张量操作，自动微分远没有想象的自动(见：Leo：微分编程（一）：传统自动微分的三宗罪)。比如，你是否思考过这样一个问题，我们可以把矩阵乘法本身看成一个巨型神经元网络，里面的基础操作是"+"和"*"，我们发现其实可以通过基础四则运算的链式法则对矩阵乘法进行求导。但不会有人真的用主流的机器学习库从基础指令开始微分代码，因为这样做内存和时间都是问题。这些库都是为机器学习这个特定领域设计的，适合在张量层面操作的自动微分，他们包括

    TensorFlowPyTorchJax

而我们今天要讨论的另一类是通用的，可以微分整个编程语言，包括自动推导上述的矩阵乘法的自动微分规则，如

    ZygoteTapenadeNiLang

全语言微分无疑是机器学习和科学计算中的一个圣杯一样的存在。结合作者的领域物理学，有了全语言自动微分，很多变分算法以及逆向工程都会变得巨简单。比如微分量子力学含时演化可以帮助人们做量子控制，微分配分函数计算过程可以得到能量密度和比热容以及微分变分平均场和变分蒙特卡洛中的ansatz计算求梯度，人们可以自由的设计各种ansatz而不用手推梯度。
为什么说全语言微分需要可逆编程？

主流的机器学习库没法做到全语言微分，本质是因为后向传播过程要求回溯计算的中间变量。变量回溯是一个非常困难的问题，尤其对于非张量操作，传统checkpointing技术会带来的额外内存和时间的开销巨大。
传统自动微分中的checkpointing技术

Checkpointing 是一种通过往全局堆栈缓存数据的方式回溯中间状态的方案。
蓝色和黄色的多边形分别代表计算和重计算过程

示意图中，每隔100步，就有一个中间状态（虚线处）被自动缓存。当我们 要获得一个没有被存储的状态（图中状态100），我们只需要找到离这个目标状态往前数最近的被缓存的状态（状态1），并重新计算想要的状态。 这里，缓存状态不是拷贝整个磁盘，而是记录发生变化的变量。这种方案的一些较为致命的弊端，比如我们要改变一个矩阵的一个元素的时候，我们必须完整的拷贝整个矩阵，否则之前缓存的数据可能会失效。因为处理可变张量内存开销巨大，PyTorch和TensorFlow中会直接禁止改变单个矩阵元素（除了一些特殊的计算图叶子节点）。同时频繁的操作全局堆栈会导致一些计算密集的for循环效率变低，这在微分类似BLAS函数中的循环中尤为重要。

那么怎么样才可以做到真正的全语言微分呢？那就得看接下来要介绍的反计算技术。
反计算技术
菱形都是可逆过程，蓝色和黄色的分别代表了运算与逆运算。(a) 中红色立方体代表可逆计算过程中为了保证可逆性产生的额外内存消耗。(b) 当可逆性不带来额外的内存。

反计算是可逆计算中回溯中间状态，同时也是释放内存的过程。如图 (a) 所示，因为可逆计算每个过程都是可以倒着执行，所以并不需要额外的堆栈来缓存数据。但是没有免费的午餐，为了保证可逆，可逆计算也会显式的引入一些辅助空间（红色方块）。有时候为了控制辅助空间不要增长太快，需要用户自己在正确的时间通过反计算主动释放内存（时间换空间）。通过反计算而不是checkpointing更加容易做到全语言微分有如下的优点

    内存分配是显式的，用户有足够的管理内存，以及权衡内存与计算时间的自由度。同时没有全局堆栈的特点也使得GPU代码和CPU代码之间更加兼容。支持可变数组可以利用可逆性节省内存，如图(b)所示让用户倾向于写出更适合回溯状态的可逆风格的代码，因此实际内存消耗会小很多

因此，在编程语言或者指令层面，一般用可逆计算更加省内存和时间。更加详细的探讨请参阅 Nextjournal 上的一篇博文
Reverse computing is not checkpointing​
nextjournal.com/giggle/reverse-checkpointing
现实生活中的应用和NiLang的性能

NiLang 以Julia语言为宿主，实现了基于可逆编程语言，并实现了指令级别的高性能微分。随着NiLang拥有越来越多的用户，我们看到了越来越多的有趣的应用。这边简单介绍下其中6个，并着重对第1个进行基准测试。

1. Bundle Adjustment

Bundle adjustment是计算机视觉中一个比较重要的应用，训练中很重要的一步是计算一个稀疏的Jacobian，微软的一个研究中人们曾经对一些自动微分软件做过基准测试
不同自动微分框架在Bundle Adjustment应用中的基准测试。

测试中, 除了手动微分之外，表现最好的Tapenade和手动微分的结果接近。Tapenade 是在自动微分圈内有名的基于 C/Fortran 的经过充分优化的全语言自动微分框架，同时也是一个商业闭源软件。于是我们作了NiLang和Tapenade的对比如下
NiLang，ForwardDiff和Tapenade在Bundle Adjustment应用中的基准测试。

这个图中，我们发现在单核CPU上，NiLang的自动微分甚至比Tapenade还要快一些。同时我们仅仅用了不到10行代码就用KernelAbstractions把它放到了GPU上执行，并成功的加速了200多倍。

设备

    CPU: Intel(R) Xeon(R) Gold 6230 CPU @ 2.10GHzGPU: Nvidia Titan V. 

参考资料

    Srajer, Filip, Zuzana Kukelova, and Andrew Fitzgibbon. "A benchmark of selected algorithmic differentiation tools on some problems in computer vision and machine learning." Optimization Methods and Software 33.4-6 (2018): 889-906.microsoft/ADBenchJuliaReverse/NiBundleAdjustment.jl

2. 微分Gaussian Mixture Model

3. 优化NICE神经元网络 (一种Normalizing flow模型)的内存开销，代码可以在NiLang的文档中找到。

4. 微分Tropical张量网络算法求取自旋玻璃基态

5. 微分一段量化金融的代码并获得相较于Zygote 600x的加速，这段代码的作者的博文猴子掷骰子中可以找到.

6. 加速变分平均场理论中的性能关键的部分并获得相较于Zygote 600倍的性能提升。
结语：可逆计算与未来

让我们再回到文章开头埋下的伏笔，之前人们觉得可逆计算的软件层面有一些缺点导致这种计算模式不是很实际，现在我们站在人工智能时代我们再审视这两个缺点。首先，第一个缺点是软件生态尚未建立。但我们发现我们可以在没有可逆指令集的情况下，从可逆编程语言开始解决微分编程这个特定的问题，并不需要完整的生态。第二个缺点是可逆计算存在额外的内存或时间的开销，但我们发现这部分额外开销带来的可逆性恰好是机器学习回溯中间状态最好的解决方案之一。它给予用户规划内存开销和计算时间的自由度，使得代码兼容GPU设备，支持可变数组，并且比起传统checkpointing能够很好的利用可逆性节省内存。

此外，可逆编程给予我们更多的未来编译到可逆硬件的可能性，超低能耗可逆的硬件的发展将会成为AI技术的大规模普及的基石。
编辑于 2020-08-22 08:07

]]
[[
https://zhuanlan.zhihu.com/p/434703462
叶凌远
-
计算系统的结构II——计算模型的数学框架
6 个月前 · 来自专栏 数理逻辑随笔
前言

在上一篇文章 计算系统的结构I——对可计算性概念的反思 中我们对可计算性的一般概念进行了一个反思，为今天的这篇文章提供了观念基础和动机。在这篇文章中，我们将用更加技术化的语言来更加深入地了解 Higher-Order Computability 这本书的理论框架，以及它对我们理解可计算性起到什么作用。全文共 8000 字左右。

在正式进入主题之前，我们先规定一些这篇文章讲要使用的符号。对于两个集合间的部分函数 [公式] 和任意 [公式] 中的元素 [公式] ，我们规定：

    [公式] 表示 [公式] 有定义， [公式] 表示 [公式] 无定义；[公式] 表示 [公式] 均有定义，且两者的值相等；[公式] 表示如果 [公式] 二者之中一个有定义，则另一个也有定义，且这种情况下二者的值相等。

计算模型

在上一篇文章中我们提到了，在数学和计算机领域中，计算这个概念不总是基于自然数的。因此我们需要一个能够处理多种数据类型之间的可计算函数的理论框架。很自然的，不同的数据结构可以看作是不同的类型 [type]；我们假设我们有一个集合 [公式] ，其是所有数据类型名称 [type names] 的集合。例如如果我们只想考虑自然数和真值上的计算函数，集合 [公式] 应就只包含两个元素 [公式] 。

我们将 [公式] 上的一个计算模型 [公式] 定义为包含如下信息的对象：

    其给出了以 [公式] 为索引的一系列集合 [公式] ，其中每一个集合 [公式] 都可以看作是类型 [公式] 下的数据集；对于任意两个类型 [公式] ，其给定一个集合 [公式] ，其中的每一个元素都是从 [公式] 到 [公式] 的一个部分函数 [partial function]；我们要求 [公式] 在部分函数的复合操作下构成一个范畴。

简单地说，一个 [公式] 上的计算模型 [公式] 便是一个对象集合同构于 [公式] 的 Setp 的子范畴 [subcategory]，其中 Setp 是集合和部分函数所构成的范畴。注意，对于我们所关心的大多数计算模型而言， [公式] 都不是 Setp 的一个满子范畴 [full subcategory]，因为一般而言不是所有从 [公式] 到 [公式] 部分函数都是可计算的。

这样的定义是符合我们对于可计算性的直观的。对于不同的数据类型，其必定对应着不同的数据集合作为它的值，这便是 [公式] 这些集合所代表的含义。当然，也有可能不同的类型对应着相同的（或同构的）数据集合；我们将在后面看到这一点。在不同的数据类型之间，显然一个从 [公式] 到 [公式] 的可计算函数应该至少为一个从 [公式] 到 [公式] 的部分函数。直观上来说，至少所有恒等映射应该是可计算的，且两个可计算函数的复合也应该是可计算的。因此，要求 [公式] 构成一个范畴看起来是其构成一个计算模型的必要条件。从这个定义出发，我们来看看常见的一些计算结构如何融入到我们所定义的框架中来。

例子1: 自然数的计算模型. 从现有的研究来看，自然数应该算得上是最基础的计算模型了。我们能很自然地将其纳入上面的框架当中。此时的类型名称集合 [公式] 只包含一个元素，且自然地我们有 [公式] 。而对于态射我们自然也有 [公式] 是所有从 [公式] 到 [公式] 地部分可计算函数所构成的集合。容易验证其构成一个范畴。

例子2: untyped [公式] -calculus. Church 最早对于可计算性地研究基于 [公式] -calculus，是一种语形（syntactical）的进路。假设我们固定了一个变元集合 [variable set] [公式] （通常其是可数无穷的），则我们可以如下递归定义所有 untyped [公式] -calculus 的项 [terms]:

[公式]

我们定义 [公式] 为所有的项构成的集合在模掉 [公式] -等价后所得到的集合（我们假设读者熟悉 [公式] -等价的概念，其表示的是对于限制变元 [bounded variable] 的重命名）。在 [公式] 上我们还可以进一步定义 [公式] -等价关系，即由下面的条件所生成的最小等价关系：

[公式]

其中 [公式] 表示将 [公式] 中的自由变元 [free variable] [公式] 替换为 [公式] 后所得到的项（为了避免 [公式] 中的自由变元在替换到 [公式] 后被限制我们可能需要先替换 [公式] 中限制变元，但这是良定义的，因为在 [公式] 中 [公式] -等价的项代表同一个元素）。我们用 [公式] 表示项 [公式] 在 [公式] -等价关系下所对应的等价类，将 [公式] 记为 [公式] 在这个等价关系下的商。则我们同样有一个只有一个类型 [公式] 的计算模型，其中 [公式] 。对于任意 [公式] ，其都对应着一个良定义的映射函数 [公式] ，其定义为 [公式] 。这样的映射称为 [公式] -可定义函数，在我们的计算模型中，我们也令 [公式] 为所有 [公式] -可定义函数所构成的集合。值得注意的是，所有这样的函数都是完全函数而不是部分函数。感兴趣的读者应自行验证 [公式] 构成一个范畴，即 [公式] 上的恒等映射是 [公式] -可定义的，且若两个映射均为 [公式] -可定义，则其复合映射同样为 [公式] -可定义。

在 Higher-Order Computability 一书中还给出了许许多多的可计算模型的例子，有基于图灵机的，有基于编程语言的，还有和传统递归论和可计算理论中所研究的计算模型更贴近的，限于篇幅我们就不一一介绍了。我们后面的理论介绍将都基于上面给出的这两个最基本的计算模型的例子。
计算模型上的弱笛卡尔闭 [Weakly Cartesian Closed] 结构

在上一篇文章 计算系统的结构I——对可计算性概念的反思 我们提到了，我们有许许多多地理由关心高阶的可计算性，但高阶可计算性的具体数学结构只有在今天介绍了详细的计算模型的定义后才能展开说明。对应到我们前面提到的计算模型的范畴结构，高阶计算性表示这个范畴是弱笛卡尔闭的。这一节我们便详细地谈谈这一点。

给定一个 [公式] 上的可计算模型 [公式] ，我们说 [公式] 上有一个弱笛卡尔结构 [weak Cartesian structure] 当满足条件：对于 [公式] 中的任意两个类型 [公式] 我们有一个对应的类型 [公式] 和两个投影映射 [projection map] [公式] ， [公式] ，使得对于任意 [公式] 和任意 [公式] ，存在一个函数 [公式] 使得对于任意 [公式] 我们有：

    [公式] 当且仅当 [公式] 且 [公式] ；在这种情况下， [公式] ， [公式] 。

值得注意的是，在上面的定义中我们仅仅要求函数 [公式] 的存在性而不要求其唯一性，这是我们说它构成一个“弱”笛卡尔结构的原因。同时一般地，我们并不一定有 [公式] ，因为可能对于某些 [公式] ， [公式] 但 [公式] ，因此根据定义我们必定有 [公式] ，这表示 [公式] 。当某个 [公式] 满足 [公式] ， [公式] 时，其中 [公式] ， [公式] ，我们称 [公式] 表示了 [公式] 这个有序对。对于一般计算模型上的弱笛卡尔机构，不一定任意 [公式] 中的有序对都由一个 [公式] 中的元素表示，但对于许多常见的计算模型，如我们下面会提到的两个例子，这是成立的。

完全类似的，我们可以定义什么是 [公式] 中的一个弱终对象 [weak terminal object]：它由一个类型 [公式] 和一个元素 [公式] 构成，使得对于任意的类型 [公式] ，将所有 [公式] 中的元素都映射到 [公式] 的常函数是 [公式] 中的一个可计算函数。

感兴趣的读者可以尝试思考，在什么意义下弱笛卡尔积结构和弱终对象是不依赖于我们具体选择的，即当对于两个类型 [公式] 我们有多个类型和多个投影映射都满足是 [公式] 的弱笛卡尔积时它们之间有什么关系；或者当我们有多个弱终对象时，它们之间是什么关系。这些问题的答案应该是与范畴论中在同构的意义上定义笛卡尔积和终对象类似。有了如上定义，我们可以来看看之前提到的两个计算模型的例子。事实上，它们上面都有弱笛卡尔结构以及弱终对象。

例子1: 自然数的计算模型. 在这个例子中我们的类型结合 [公式] 中只有一个类型 [公式] ，因此我们别无选择只能有 [公式] 和 [公式] 的弱笛卡尔积就是其本身！这样定义的确能够构成一个弱笛卡尔积结构是由于我们有许多从 [公式] 到 [公式] 的可计算函数构成它们之间的双射，比如下面定义的这个可计算函数 [公式] ：

[公式]

显然，当我们有了这个双射 [公式] ，在弱笛卡尔积结构中我们所需要的两个投影映射可以分别定义为

[公式]

容易验证，对于任意两个部分可计算函数 [公式] ，我们可令 [公式] 为 [公式] ，显然其满足我们上面陈述的两个条件。由此可见，对于我们第一个非常基础的自然数的计算模型，其有一个弱笛卡尔积结构。同时由于 [公式] 是一个双射且 [公式] ， [公式] 都为完全函数，对于任意自然数的有序对 [公式] 它都由某一个自然数表示。我们选取不同的 [公式] 和 [公式] 之间的双射能够得到不同的弱笛卡尔积结构。这个计算模型具有一个弱终对象是显然的，因为任意 [公式] 到 [公式] 的常映射都是可计算的。

例子2: untyped [公式] -calculus. 对于第二个 [公式] -calculus 所对应的计算模型的例子，熟悉一些基本的 untyped [公式] -calculus 理论的读者应该都应该能够猜想到其也必定具有弱笛卡尔积结构。和例子1完全类似，在这个计算模型中我们也只有一个类型，因此其笛卡尔积必定只能是其自身。我们同样需要找到一个 pairing 函数使得 [公式] 本身就能够表达 [公式] 的信息。由我们的定义可知，在此计算模型中所有的可计算函数都由一个项生成。特别地，我们如下可以定义 [公式] 中的一个项：

[公式]

其中 [公式] 是 [公式] 的缩写；还有如下的两个项：

[公式]

此时，对于任意两个 [公式] 中的可计算函数，即两个项 [公式] ，我们这个有序对所对应的可计算函数可以选为 [公式] （注意，在 [公式] -calculus 的语境下项都默认为是左侧结合的）。由于 [公式] 中全是完全函数，因此我们可以直接结算 [公式] 和这个函数的复合；在项的层面这就是将这两个项相作用：

[公式]

上面的计算完全遵从于 (2) 中提到的 [公式] -等价关系。完全类似地，大家可以计算 [公式] ，其结果也必定和 [公式] 相等。由此可见， [公式] -calculus 所对应的计算模型也具有弱笛卡尔积的结构，且同样地对于任意一个有序对都有一个表示项与其对应。和例子1类似，任意 [公式] 到其自身的常映射都是 [公式] -可定义的，因此其上也具有弱终对象。

由此可见，对于前面提到的两个基本的计算模型的例子，尽管它们都只有一个数据类型，但它们都具有弱笛卡尔积结构，其原因也符合我们的直观：利用它们本身的数据集合就能够编码它们自身成对的信息。

目前为止，我们还不涉及高阶计算的内容，因为弱笛卡尔积结构从直观上只是说明在我们的计算模型中能够表达成对的数据值。与高阶计算内容密切相关的是弱笛卡尔积闭的结构。换句话说，我们要求可计算函数本身作为数据也能够在我们的计算模型中进行表达。这也就是我们接下来要阐述的。

我们称一个 [公式] 上的具有弱笛卡尔积和弱终对象的可计算模型 [公式] 上具有一个弱笛卡尔积闭 [weakly Cartesian closed] 结构，当我们给出如下信息：

    对于任意两个类型 [公式] ，我们指定一个类型 [公式] ；一个部分函数 [公式] ；

使得对于任意 [公式] 和任意部分函数 [公式] ，下面两个条件是等价的：

    [公式] 存在一个 [公式] 中的部分函数 [公式] 为其表示，即对于任意 [公式] ，若其是 [公式] 的表示，则 [公式] ；在 [公式] 中有一个完全函数 [公式] 满足对于任意 [公式] ， [公式] ， [公式] 。

直观上来说，高阶计算性或者弱笛卡尔闭结构是想说明 [公式] 这样的部分函数可以由 [公式] 这个类型的值，即 [公式] 中的元素表示。这个定义和一般范畴论中的笛卡尔积闭结构最大的不同在于，对于任意的一个函数 [公式] 若其表示存在，我们并不要求其表示函数 [公式] 是唯一的。换句话说， [公式] 中的元素是内涵性物体 [intensional objects]，如一段程序或者是一个算法（对于可计算函数的内涵与外延的探讨参见上一篇文章 计算系统的结构I——对可计算性概念的反思），我们可以有多个内涵性物体对应着同一个可计算函数的外延。从如上的定义中我们也可以看出， [公式] 这个部分函数也必定由某个 [公式] 中的函数表示，因为在 [公式] 中我们有 [公式] 上的恒等映射；我们把这个函数记为 [公式] 。我们再次来看看前面提到的两个计算模型的例子上的高阶计算结构。

例子1: 自然数的计算模型. 和之前类似，由于我们只有一个类型 [公式] ，因此如果其上有高阶计算结构我们也必定有 [公式] 。在考虑高阶计算结构的时候我们需要对可计算函数的具体实现方式作出更多的说明，因为如前所述，高阶计算模型不仅要考虑可计算函数的外延，还要考虑其内涵。因此此时，可计算函数的具体实现方式变得相关了。假设我们采用了图灵机的表述（换用其他常见的可计算函数表述，如传统递归论的或是其他类型的也是可以的，只是我们得到的高阶模型会有些细微的差别），则高阶计算结构（把自然数本身看作是某个程序，因为我们此处有 [公式] 和 [公式] 是同一个类型）具体实现方式是通过对所有的图灵机进行编码。假设我们选取了一个合适的编码，并用 [公式] 表示第 [公式] 号图灵机（由于有不同的图灵机计算相同的可计算函数，这显示了当我们把自然数本身看作是可计算函数的编码时其所表示的是内涵的结构，而不单纯是可计算函数的外延）。可计算理论中一个很重要的结果便是存在一个通用图灵机 [公式] 使得当我们输入一个有序对 [公式] 时，我们有 [公式] 。显然，我们可以把 [公式] 对应的可计算函数作为我们的部分函数 [公式] 。在自然数的计算模型中由于我们的函数 [公式] 是一个双射，因此任意可计算的 [公式] 都有一个对应的函数 [公式] 为其表示，其可以自然地选为如下的函数：

[公式]

此时我们也有另一个完全可计算函数 [公式] 满足 [公式] 。这来自于基本递归论中的 Kleene s-m-n 定理：对于任意一个图灵机 [公式] ，存在另一个完全图灵机 [公式] 使得对于任意 [公式] ， [公式] 。由此可见，我们基于自然数的计算模型是一个完整地高阶计算模型；在计算理论的文献中，这个模型一般被称为第一 Kleene 模型 [Kleene's first model]，记为 [公式] 。

例子2: untyped [公式] -calculus. untyped [公式] -calculus 的高阶可计算性某种意义上要比自然数模型的高阶性要更自然也显然一些。显然同样的，在这个模型中我们也必定有 [公式] 。其上的函数 [公式] 非常自然的就是项之间的作用函数。假设我们有一个项 [公式] 表示了某个函数 [公式] ，使得对于任意两个项 [公式] 我们有 [公式] ，则此时我们可以令 [公式] 为表示 [公式] 的项。此时我们有，

[公式]

这同样说明了 untyped [公式] -calculus 的计算模型是弱笛卡尔积闭的，其上很自然的有高阶计算结构。
剩余的问题

在前面两节中我们表述了最基础的高阶计算模型的数学结构，并陈述了我们常见的两个计算模型，即基于图灵机的自然数上的可计算模型和基于 [公式] -calculus 的可计算模型，如何融入到我们所定义的数学框架中。但这仅仅是一个开始。在本篇文章的最后我们阐述一下在此基础之上我们还应该关心什么基本问题。这一节可以看作一个预告，里面提到的内容将会在下一篇文章中具体地阐述。
问题1: 计算模型之间的关系？

首先，范畴的基本思想仍然指导着我们，一旦当我们定义了某种数学对象（比如我们这里定义的高阶计算模型），我们应该立刻关心这些数学对象之间的关系，即什么应该是它们之间的态射。在计算模型的语境下，两个计算模型之间的态射 [公式] 直观上来说应该对应着某种用 [公式] 来模拟 [公式] 中的计算的方式。在理解态射之后，进一步我们便可以询问什么情况下两个计算模型之间是等价的？

我们可以从上面所提到的两个计算模型的例子入手。在基础的可计算性理论中一个非常重要的结果便是，在 untyped [公式] -calculus 中定义的可计算函数和用图灵机定义的可计算函数是完全相等的——在我们的话语体系中更准确地应说它们定义了相同的可计算函数的外延。更具体一些，我们在 untyped [公式] -calculus 中可以定义形如 [公式] 这样的闭项 [closed term] 作为数字 [numeral]，其中 [公式] 是 将 [公式] 作用在 [公式] 上 [公式] 次，即 [公式] 的简写。则在 untyped [公式] -calculus 模型中的可计算函数（即由某个项所表示的函数）和图灵可计算函数在外延上是完全一致的。

更进一步，从直观上来讲我们似乎也的确能够用其中一个模型来模拟另一个模型的计算。对于用自然数模型来模拟 [公式] -calculus 的模型，我们只需要使用我们非常常见的编码手段，将 untyped [公式] -calculus 的语形用自然数编码，便非常容易能够看出 [公式] -calculus 上语形的操作能够用自然数的操作来进行模拟。但反过来也同样，对于任意自然数上的操作我们可以用前面定义的 [公式] -calculus 中的数字和闭项来模拟。因此直观上讲，对于这两个模型而言我们能够在一个模型中模拟另一个模型的计算。

但再继续深入地问，这样的双向模拟表示这两个计算模型之间是等价的吗？事实上，由前面的论述我们可以看出这两个模型也有许多非常不同的地方。比如在 untyped [公式] -calculus 当中所有的可计算函数全是完全函数，但在自然数模型中显然不是。它们到底是否是等价的，我们留到在下一篇文章中详细探讨。
问题2: 我们有没有类似代数拓扑中的不变量来描述计算模型之间的等价性？

在拓扑的语境下，我们一个很基本的问题是判断两个空间是否是同胚的。我们能够写下的所有连续函数都不构成同胚这件事并不能说明这两个拓扑空间之间没有任何的连续函数使得它们同胚，这个问题使用传统的办法是非常难以回答的。为了解决这个问题，在拓扑的语境下我们发展了代数拓扑的工具使得对于一个拓扑空间我们能够赋予其一系列代数的不变量；通过比较这些不变量，我们能够在某种含义的等价下（如同伦、弱同伦等价）判断两个拓扑空间是否属于同一个等价类。

这样的想法其实是非常普世的。在我们之前的一篇文章 范畴逻辑 I——逻辑与数学结构的对应 中介绍了将一阶逻辑片段扩展到一般范畴上的语义学，并阐释了在范畴语义下一阶逻辑模型的表示和完全性定理。但同样，我们或许不希望在最为普遍范畴的意义上考虑一个逻辑系统的模型。比如，任意的完全格 [complete lattice] 都是一个笛卡尔范畴，但显然我们几乎不在任何意义上希望考虑格上的代数理论。比如任意格上的群都是 trivial 的，这是因为格 [公式] 上的终对象是最大元，而对于任意元素 [公式] ，若其是 [公式] 中的一个群我们要求有一个态射 [公式] ，换句话说即有 [公式] 。这表明 [公式] 。因此，考虑一般范畴上的某个逻辑系统的模型太普遍了，对我们没有太大的作用。一个更加好的范畴类别是拓扑斯 [topos]，这是一类具有和 Set 十分结构的范畴，每一个拓扑斯都可以看作是某种构造性的数学宇宙 [constructive universe]；因此，在所有拓扑斯中看待逻辑系统的模型看起来至少是更为合理的。而由此我们生成了一种新的逻辑系统的 Morita 等价观念，即我们称两个系统是 Morita 等价的当且仅当它们在所有的拓扑斯中具有相同的模型。在这种等价观念下，我们在之前文章中介绍的逻辑系统的分类拓扑斯 [classifying topos] 便可看作是这种等价观念下逻辑系统所对应的完全不变量，即两个逻辑系统是 Morita 等价的当且仅当它们的分类拓扑斯是等价的。

回到我们的可计算模型上来。若我们对之前问题1有了一个好的答案，即我们有了一个计算模型之间的等价概念，我们能否找到这种等价概念下所对应的不变量，使得我们能够更加直接地判断两个计算模型之间是否是等价的？对这个问题的我们也会在下一篇文章中进行解答；事实上，和分类拓扑斯的构造类似，对于每一个计算模型 [公式] 我们也能够构造一个代表其计算结构的范畴 [公式] ，称为 the category of assemblies of [公式] 。这个范畴和拓扑斯一样有着非常丰富的范畴结构，可以看作是对于计算模型的某种分类空间 [classifying space] 其能够解决很多我们关于计算模型的问题。
结语

在这篇文章中我们简单地介绍了高阶计算模型的基本数学定义，并用了两个常见的例子阐述了这个数学框架如何将这些例子囊括在内，希望大家能够从更细节的角度理解高阶计算模型的数学结构，以及对于为什么要这么定义有一个直观上的把握。在文章的最后我们提到了一些剩余的问题，这些问题将会在下一篇文章中进行介绍。在下一篇文章中我们也会简单地总结一下高阶计算模型的应用，请拭目以待。
编辑于 2021-11-18 13:05

]]
[[
https://zhuanlan.zhihu.com/p/432584254

叶凌远
-
计算系统的结构I——对可计算性概念的反思
6 个月前 · 来自专栏 数理逻辑随笔

前言

这次终于要换一个主题了，我们不再讲述与范畴逻辑相关的内容，转为开始介绍可计算性 [computability] 这个概念了——但如果你学过范畴论，你就会知道范畴的思想无处不在。对我而言，在大一学习和一阶逻辑以及不完备性定理时，可计算性这个概念就引起了我非常大的兴趣。但由于国内没有非常好的关于递归论和可计算理论的课程，我那时和后来关于可计算性的疑惑也无处解答。直到当我大四时看见一本 2015 年出版的书 Higher-Order Computability[1]，我才醍醐灌顶。这本书真正意义上解答了我心中关于对可计算性这个概念许许多多的疑惑，因此我想向大家简单介绍一下这本书的内容和想法（其实这本书大一的时候就躺在我的 iBook 中了，但那时对于范畴论一无所知的我完全无法理解这本书介绍的深刻思想）。我目前总共打算分两篇文章来介绍这本书的内容。今天这篇文章会主要从可计算性的概念反思入手，几乎不包含任何技术性的内容。下一篇则会更加详细地介绍基于这样的概念反思这本书对可计算性的研究所采用的数学框架。如果大家看完这一篇或这两篇觉得感兴趣，请一定去阅读这本书。这两位作者的写作非常清晰，并且有非常好的导论和对可计算性概念历史发展地阐释，在技术细节和概念解释上有非常好的平衡，具有很高的可读性！显然我两篇字数有限的文章完全无法传达整本书的内容，仅仅能起到一个非常简略的介绍作用。全文共 7200 字左右。
可计算性不总是基于自然数

我相信如果大家了解过一些递归论或者是可计算理论的内容，大多都会有一个模糊的印象，认为计算理论研究的是从 [公式] 到 [公式] 的一个函数什么时候是可计算的，或者与之类似的相关问题。这个印象不能说是错的，对于自然数上可计算函数的研究的确是可计算性理论刚兴起时非常重要的内容。但在我们日常生活中或者在面对许许多多的数据结构的时候，这真的是我们唯一的对可计算性这个概念的理解方式吗？

首先，我们似乎不仅仅关心 [公式] 上的可计算性问题。或许首先一个比较微不足道的观察是，在计算机理论中我们对 [公式] 有不同的表示方式，比如经常采用的是二进制数。因此严格来说，此时可计算性和可计算函数所基于的对象变成了 [公式] ，即 01-字符串构成的集合。当然，很多人会说这两者没有本质的区别，因此采用哪一个发展可计算性的理论没有关系；我们的经验也的确支持这种看法，因为它们二者是同构的。

但我们在日常生活中遇到的例子不是都像改变自然数的进制这样微不足道的。比如在编程中或者在理论计算机的研究中，我们经常遇见的情况是我们所想要考虑可计算性的数据集合上有更多的结构存在：比如在数据结构中我们经常使用树、图或者是表这样类型的数据结构，这些结构本质上和自然数的结构是不同的。如果采用递归类型 [inductive type] 或者是许多函数式编程 [functional programming] 语言中的表示方式，自然数 [公式] 可以看作是如下的递归类型：

inductive N : Type :=
| zero : N
| succ : N -> N

换句话说， [公式] 的结构是由 0 和后继函数 [successor function] 递归生成的自由结构。我们同样可以类似地定义二元树的数据类型：

inductive Btr : Type :=
| leaf : Btr
| node : Btr -> Btr -> Btr

可以看见的是，二元树的递归生成方式是和 [公式] 不同的。自然数生成的方式是给定一个自然数，生成一个其后继；而二元树是给定两个二元树，可以通过一个点将二者连起来形成一个新的二元树。我们还有许多其他的递归数据类型，其上的结构也自然和二元树与自然数都是不同的。但几乎在任何一个高级编程语言中，我们都可以编写输入为自然数 [公式] 输出为二元树类型的程序；根据 Church-Turing Thesis, 所有由这样定义的函数都应是可计算的。因此，尽管 [公式] 和二元树的数据结构不同，我们仍然可以谈论什么是不同数据结构之间的可计算函数，并且对此具有一定的直观。

在一般的可计算理论分析中，我们解决上面这个问题的方式是考虑从一个结构到另一个结构的编码 [coding]。比如对于上面 [公式] 和二元树的数据结构，我们很容易看出来的是我们可以用二元树编码自然数。比如我们可以令满的二元树代表自然数，其层高对应着自然数的值；原则上，自然数的任意操作都可以在这套编码下采用二元树的操作来表达。但在实际的理论研究中我们更加熟悉的是用自然数来编码二元树。自然数这个集合是非常丰富的，其上的操作可以编码我们遇到许多数据结构。从某种程度上，这也是我们在可计算理论中主要考虑自然数上的可计算函数的原因之一。大家脑海中或多或少都会认为，由于这些编码函数的存在，我们只需要有了自然数这个结构上的可计算理论，其他的可计算函数均可以通过各种不同的编码来实现。

但这样对待可计算性理论的方式是有些不自然的。首先，采用编码的方式其实严格意义上并不能完全地解决我们的问题。如果我们使用自然数来编码二元树，通常的编码方式是找到一个从二元树到自然数的单射（或双射）Btr -> N。通过这个编码函数，我们便可以将自然数上的可计算性概念迁移到二元树这个结构上。但为了使这个方法成立，我们必须要求这个编码函数本身是可计算的！如果我们选取了一个本身不可计算的编码函数，那么一个根据 Church-Turing Thesis 不可计算的二元树上的函数 Btr -> Btr，根据这个编码转换成自然数上的函数后其也可能变成是可计算的。因此，为了选取一个合理的编码，从概念上我们还是无法逃脱需要首先知道什么是从二元树到自然数的可计算函数。

当然，在实际的可计算理论中，我们之所以可以不用发展更为一般的从二元树到自然数的可计算理论的原因是我们能找到许多直观上可计算的编码函数；一旦我们确定了这样一个编码，似乎我们就可以绕过上面这个问题了。但是，如果我们回到可计算性观念的层面，这样任意选取的编码函数对于我们理解可计算性这个概念的作用是微乎其微的。从更大的层面上来讲，可计算性这个概念没有任何先验的理由是特殊针对自然数 [公式] 的；对非常广泛的一类数学结构我们都能够非常直观地谈论它上面的可计算性，特别是在默认了 Church-Turing Thesis 成立的条件下。

另外从技术的角度，许多现代对于计算这个概念的发展和研究所基于的数学对象和结构并不全都能够用自然数来进行编码了。例如在最近十多年发展得越来越多的基于余代数 [coalgebra] 或者自动机 [automata] 来模拟的无穷计算 [infinite computation]，其考虑的就是诸如 [公式] 这一类集合上的可计算性。再或者我们想要模拟物理世界的可计算性，我们需要考虑的是在无穷时间的延伸下可能发生的各个物理事件之间的集合上的可计算性。和之前的二元树或其他的递归定义的数据结构不同的是，这些集合都不再是可数的了，因此用自然数编码来研究这些集合结构上的可计算性是根本行不通的了。这些无穷计算不仅仅是有理论研究价值的，目前一些函数式编程语言早已支持对这些无穷的数据进行编程操作了（如 Haskell 中非常重要的 lazy 特性就能够支持这一点）；另外，如果我们考虑人和计算机之间的交互，我们在一连串时间中不断按下的键盘和点击的鼠标也可以被模拟成在连续时间上的无穷事件。这些应用也都侧面地印证了，考虑这些不可数集合上的计算结构同样是重要的。

回到观念的层面上来看，我们所需要的是一个更加广泛与抽象的框架来研究与描述一般对象上的可计算性概念，而不仅仅是聚焦在自然数这单单一个集合上。此处可以跟我们对一般空间的研究做一个类比。我们对几何的研究有非常深的历史，早在古希腊我们对平面几何和立体几何就有了非常多的知识。但所有的这些知识都是对某几个空间中的某几类几何结构作出的描述，因此它们都可以看作是我们对某一些常见的数学对象所收集的知识。但我们对空间——或者以范畴论的视角来看，连续性——这个抽象概念的一般认识是要到在数学中发明了一般拓扑空间的这个抽象概念之后才真正有了质的突破。正因如此，拓扑这个概念在现代数学中的重要性怎样强调似乎也不为过。事实上，可计算性和连续性这两个概念有着千丝万缕异常紧密的联系，这个联系也是我们介绍的这本书中的一大主题。但限于篇幅，在这篇文章中或许我们没有机会提到了，只能如此非常粗略地告诉大家这个结论而已。与几何的发展完全类似的是，在可计算性领域许多顶尖的数学家以及逻辑学家，包括 Turing、Church、Kleene 等的工作之后，我们收集了许许多多的对于某些具体的计算模型的知识，并对于它们之间的关系有了很多初步的结果。但我们目前缺乏的是如同拓扑的概念一样谈论一般可计算性概念的抽象框架。基于拓扑的概念，我们能够谈论一般空间之间的连续函数；同样的，我们或许也需要有一个对可计算性的一般框架来考虑一般不同数据结构之间的可计算函数，同时比较不同计算模型之间的关系。

从某种意义上来说，我们介绍的这本书初步地解决了上面的这个问题。在书中给出了一般抽象意义上的计算模型的定义，并据此研究了一般可计算函数的性质。根据上一段的描述，书中自然地采取了范畴的框架。在这篇文章中我们并不会介绍书中给出的计算模型的具体数学定义；这将会是下一篇文章的内容。接下来我则会继续探讨一下对于可计算性这个概念其他方面的反思。
可计算性是一个高阶的概念

我们这次介绍的这本书的名字叫 Higher-Order Computability，即高阶可计算性。高阶可计算性的含义是，如果对于两种不同的数学结构 [公式] 我们有了什么是从 [公式] 到 [公式] 的可计算函数的概念，则我们同样需要考虑的是某种函数空间 [公式] （目前可以粗略地看作所有从 [公式] 到 [公式] 的可计算函数集合）上的可计算性。比如，我们希望知道以什么方式选择一系列从 [公式] 到 [公式] 的可计算函数其本身是可计算的；采用更加数学化的语言，即我们同样想要了解什么是 [公式] 到 [公式] 的可计算函数。当然完全类似的，我们还可以考虑相应更高阶的可计算性，如集合 [公式] 上的可计算性。

为了说明高阶可计算性的概念与直观，我们这里将其和拓扑进行一个类比。很多人或许会认为拓扑是在研究空间的性质，但基于范畴的观点更加自然地描述或许是拓扑空间是在描述连续函数的性质。完全类似的，计算理论实际上是在研究可计算函数的性质。在拓扑空间的语境下，我们需要考虑什么是两个空间之间的连续函数；但更进一步，我们还需要知道如何连续地选择两个拓扑空间上的连续函数。因此自然地，连续性也本质上是一个高阶的概念，而连续的高阶性在现代拓扑中起着非常重要的作用。如果采用范畴的语言，无论是可计算性还是连续性，高阶的含义实质上是要求我们所考虑的某个范畴是 Cartesian closed 的（在可计算性中由于我们要考虑部分函数 [partial function] 因此所有的范畴结构我们都只考虑弱版本的，即泛性质 [universal property] 只考虑存在性而不考虑唯一性）。对于所有的拓扑空间我们没有一个很好的解决方案，因为 Top 这个范畴并不是 Cartesian closed 的；但如果局限在紧致的 Hausdorff 空间下我们可以拓扑化两个拓扑空间之间连续函数所构成的空间，这个构造对高阶的连续性作出了一个很好的解答。在可计算性的语境下，我们也需要类似的 Cartesian closed 的结构来模拟高阶的可计算性。

为什么考虑可计算性时我们一定需要考虑高阶的可计算结构呢？其原因是多样的。在这里我们仅仅讨论两个和数理逻辑以及可计算理论最相关的原因。

首先，让我们对可计算函数的外延和内涵做一个区分。如果我们简单地采用程序语言的叙述方式，在某种意义上我们可以说任何一段输入输出均是自然数的程序都定义了一个部分可计算函数 [partial computable function]。但从直观上来讲，这一段程序比这一个单独的部分可计算函数包含了更多的信息，因为一段程序不仅仅能够给出正确的结果，它还包含了如何具体计算这个函数的步骤与方式。从另一个角度来讲，我们可以有另一段完全不一样的程序使用了另一种计算方式，但它们计算的是同一个部分可计算函数。换句话来说，尽管我们经常把程序和可计算的函数等价起来，在观念的层面它们是不一样的：一段程序是有内涵的 [intensional]，其对应的那个部分可计算函数仅仅表征了这一段程序的外延 [extension] 而已。因此，如果只单纯地考虑从 [公式] 到 [公式] 的可计算函数这个集合，我们是仅仅在外延的层面考察可计算性，而忽略了其内涵。

对于大多数的编程语言，特别是许多现代的函数式编程语言比如 Lisp, Haskell 或者是 Lean，它们都支持将它们本身的一段程序作为数据而对它们进行编程和各种操作；直观地来说，它们都在它们的语言中包含了一份自身 [contains a copy of themselves]。在这些语言中，输入输出为 [公式] 的程序本身也能够成为输入和输出来考虑其上的可计算性。因此对这些编程语言而言，仅仅考虑可计算函数的外延是不够的。计算函数的内涵性往往是通过高阶可计算性来刻画和表达的。换句话说，在我们的高阶计算模型中，前面提到的 [公式] 这个集合并不是所有从 [公式] 到 [公式] 的可计算函数的外延构成的集合，而是它们的内涵构成的集合。因此，如果我们想要刻画这一类编程语言的抽象结构，考虑高阶计算性是不可或缺的。高阶可计算模型的研究也的确有很大一部分是为了解决和许多程序语言的计算语义相关的问题。

高阶可计算性以及对可计算函数内涵和外延的区分，更是直接地与直觉主义逻辑的构造性或可计算性阐释息息相关，因此它对数理逻辑的研究也非常的重要。从高阶可计算性研究的历史来讲，的确也有很大一部分贡献和发展来自于对数理逻辑中直觉主义逻辑相关的研究。直观上来讲，我们常常声称直觉主义逻辑有某种构造性阐释，即某个命题在直觉主义逻辑下可证明当且仅当我们能够给出某种构造来直接地验证或说明它是正确的。在现代数学的语境下，构造数学 [constructive mathematics] 和直觉主义数学 [intuitionistic mathematics] 在很多时候是作为同义词被大多数数学家使用的。例如，在直觉主义的构造性阐释下，对于推出连接词 [公式] 的证明或构造指的是一个把 [公式] 的证明或构造转化成 [公式] 的证明或构造的一个程序。但在这种解释下，如果没有对高阶可计算性的刻画我们是无法理解有嵌套的推出连接词，如 [公式] 等公式的构造性解释的：套用前面的说法，对 [公式] 的一个证明是一个把将 [公式] 的证明转化到 [公式] 的证明的程序转化为 [公式] 的证明的程序（这句话用自然语言写出来非常难读，正是因为其涉及可计算性的高阶嵌套）。对于涉及到多个存在量词嵌套时直觉主义逻辑公式的构造性解释也完全类似。为了能够给这些嵌套的直觉主义逻辑公式一个严格地构造性阐释，有一个准确的语言来描述高阶的可计算性是必要的。
比较不同计算模型之间的关系

本文的最后一节我们来探讨一下不同计算模型之间的关系。在上世纪三十年代，Turing、Church、Kleene 等人的工作让我们非常惊讶地发现，许许多多完全不同的定义 [公式] 上可计算函数的方式所给出的是完全一样的同一族函数。Church 对于可计算函数的刻画是基于 [公式] -calculus 的，其中对数字和可计算函数的表示都是基于 [公式] -calculus 中的项 [terms]，是一个完全从语言和语形出发给出的构造。Turing 定义的图灵机则有完全不同的直观，它是基于某种特殊的物理可实现的机器，这些机器也被称为图灵机 [Turing machine]。而 Kleene 创立的递归论则是一个从复合 [compositionality] 和递归 [recursion] 结构出发的进路。事实上我们还有许许多多的计算模型，比如和现代计算机更加接近的基于暂存器 [register machine] 的计算结构，或者从纯逻辑的证明角度出发基于一阶算数系统的计算结构。所有关于这些计算模型的讨论可以参见[2]。令人震惊的是，这些看似完全不同——有着完全不同直观且基于完全不同的出发点——的计算模型所最终定义的可计算函数是完全一样的！这个事实也可以看作是可计算性能够作为一个数学中值得研究的抽象概念存在的最有力证据。

但值得注意的是，这里我们所谓的这些不同的计算模型给出完全一样的可计算函数指的是在外延的层面上。换句话说，从 [公式] 到 [公式] 的部分可计算函数这个外延集合具有非常高的鲁棒性。但这些不同的计算模型给出相同的可计算函数外延是否真的表明这系计算模型是等价的？这个问题从我刚开始接触可计算理论就一直困惑着我；直到我看到这本书，才感到有一个足够普遍的数学理论框架能够真正意义上对这个问题进行一个回答。

首先，现代数学或者说范畴论的经验告诉我们，要回答关于等价的问题，事实上是要回答态射的问题（顺嘴一提，这一点也说明有等价这个概念的地方就有范畴论的身影，如果再推广到无穷范畴则是有若等价这个概念的地方就有无穷范畴的身影；这从侧面解释了为何范畴和无穷范畴能够作为现代数学的语言而存在）。在可计算性的语境下，我们要考虑的态射则应该是某种模拟 [simulation]，即在一个计算模型中能够作出的计算能否平行的用另一个计算模型来进行模拟。

给定两个计算模型我们是可能有多种模拟方式的。比如给定一个有有限字母表的图灵机，我们可以有非常多种不同的方式来表达自然数；假设我们想要把基于递归论的可计算性用图灵机的方式进行模拟，则任意一种不同的表示自然数的方式应该都对应着不同的模拟方式（当然，表达自然数的方式只是一个计算模拟中很小的一个方面，由于在此处我们没有介绍其严格数学定义，我们仅以此为例；在下一篇文章中我们会更加严格地阐述计算模型和模拟的数学定义）。在这些不同的模拟方式下，有些模拟方式之间是能够可计算转换地（再一次，对于可计算转换地直观我们可以参考在拓扑的语境下连续转换的直观）。对于熟悉范畴论的读者，上面的描述很自然地构成了一个 2-阶范畴 [2-category]。在 2-阶范畴的语境下，我们有非常一般的有关等价 [equivalence] 的定义，而我们对于计算模型的等价也就定义为这个 2-阶范畴中的等价了。

也许大家读到这里已经有些云里雾里了；没有关系，在下一篇中我们更加仔细地介绍上面用自然语言阐述的思想背后的具体数学内容。在这里我们仅仅给出一个结论：上面提到的众多可计算模型在我们更加精细的等价定义下并不全是等价的！尽管它们都给出了外延相等的一族可计算函数，但当我们考虑高阶可计算性或者是其他可计算模拟之间的转换时，不同的计算模型之间有着更为细微的差别。如果我们再考虑更为广泛的计算模型，比如前面提到的许多无穷计算模型，则它们之间的差别会更为巨大。对笔者个人而言，这样的结论是符合我的直观的；并且它们的不等价性反应在了更多数学性质的不同上，这也间接地证明这样的考虑是有必要的。再说最后一次，这些内容的讨论详见下一篇文章！
结语

在这篇文章中我们对可计算性和计算模型进行了一个概念反思。对笔者个人而言，这样的思维过程是重要的，因为最终和空间以及连续性的概念一样，我们是想要对什么是空间这样一个抽象的概念进行理解与研究，而不仅仅是局限在研究三维欧式空间中的几何。尽管不能说拓扑的概念是我们对空间这个概念所作出的最终答案，但这的确是第一个抽象的框架使得我们能够阐述有关连续函数的一般性质。完全类似的，关于可计算性这个概念我们也需要这样的一套框架使得我们能够对一般的可计算性进行研究。我相信这样的思维方式一定会极大地扩展可计算性相关研究的视野及内容，对我们更加深入地理解数学的本质一定是有很大的帮助的。希望感兴趣的同学能够开始思考相关的问题。
参考

    1. ^Longley, J., & Normann, D. (2015). Higher-order computability (Vol. 100). Heidelberg: Springer.
    2. ^Cooper, S. B. (2017). Computability theory. Chapman and Hall/CRC.

编辑于 2021-11-12 17:28

]]
[[
https://zhuanlan.zhihu.com/p/64007521
[
基于逆元可以在任意元素之间建立关联，从而实现任意元素之间的转化。这样元素之间的关系就突破了简单的整体-部分或者一般-特殊等关系的范畴，进入更加抽象的结构运算范畴。这种思想上的变革启发了哲学中的结构主义思潮。

在哲学上，结构主义提出结构具有三个要素：整体性，转换性（具有转换规律或法则），自律性（自身调整性）。整体性意味着结构不能被简单的切分，其构成要素通过内在的关系运算实现大范围的关联与转换，整体之所以成为整体正是以转换/运算的第一性为保证的。这种转换可以是共时的（同时存在的各元素），也可以是历时的（历史的转换构造过程），这意味着结构总要求一个内在的构造过程，在独立于外部环境的情况下结构具有某种自给自足的特性，不依赖于外部条件即可独立的存在并保持内在的活动。自律性意味着结构内在的转换总是维持着某种封闭性和守恒性，确保新的成分在无限地构成而结构边界却保持稳定。注意到这里对结构的评判并不是来自外在规范和约束，而是基于结构内在的规律性，所强调的不是结构对外部条件的适应性，而是自身概念体系的完备性。实际上，一个无法直接对应于当前实际环境的结构仍然可能具有重要的价值，并在解决问题的过程中扮演不可或缺的角色。在合理性这个视角下，我们所关注的不仅仅是当前的现实世界，而是所有可能的世界。结构独立于内容存在于抽象的数学世界中，一个“合理”的结构的价值必能在它所适应的具体世界中凸显出来。
]

canonical
千山万水
可逆计算的方法论来源
26 天前 · 来自专栏 可逆计算

对于软件领域的大量设计原则和所谓的方法论，我一直持有很深的怀疑态度。为什么会存在这些原则，能否从科学的层面证明它们的有效性？可逆计算理论试图为软件构造提供一个更加坚实的理论基础，它明确提出应该将“差量”提升为第一性的概念，将全量看作是差量的一种特例（全量=单位元+全量），围绕差量概念去重建整个领域概念体系。可逆计算的思想来源不是计算机科学本身，而是理论物理学，它将软件看作是处于不断演化过程中的抽象实体， 在不同的复杂性层次上由不同的运算规则所描述，它所关注的是演化过程中产生的微小差量如何在系统内有序的传播并发生相互作用。本文将介绍可逆计算从作为其思想来源的统计物理学和量子力学所获得的启发。
（一）熵增原理

在香农的原始定义中，信息是能够用来消除不确定性的东西。而在物理学中，所谓的不确定性就是系统的混乱程度，而用于度量系统混乱程度的物理量就是熵（Entropy）。接收到信息后，不确定性降低，也就意味着混乱程度的减少，因此信息也就被认为是负熵。

熵是物理学中的一个核心概念，它甚至比能量概念还要重要。热力学第一定律就是能量守恒定律，它指出能量只能被转化，而不可能被创造或者消灭。而热力学第二定律指出，即使有了能量，也不一定能够对外做功，必须考虑到热力学过程内在的不可逆性：热力学系统从一个平衡态演化到另一平衡态的过程中，其熵永不减少，若过程可逆，则熵不变，若不可逆，则熵增加，这 也就是所谓熵增原理。

熵增原理控制了所有自然发生的过程，驱动所有事物自发的向着混乱最大化的方向发展。因此，在软件开发过程中，我们同样可以观察到大型软件产品普遍存在着从有序到混乱的发展历程。伴随着人员的更替、需求的变迁，在软件中增加新的功能变得越来越困难，修改bug经常引入新的bug，没人能够说清楚如何才能抽取系统中的一小部分进行复用，最终只能推翻重建。

可逆计算的核心是可逆性，而可逆性之所以重要，不仅仅在于它方便了软件元素的灵活复用，深层次的原因是它体现了我们这个世界本质的运作规律。通过遵循可逆计算原则，我们能够有效的控制软件演进过程中的熵增速度。理想情况下，如果系统能够做到完全可逆，则熵是保持不变的。

在软件架构设计中，我们总是说要高内聚、低耦合、关注点分离，但是什么是高、什么是低、需要分离到什么样的程度？可逆计算给出了一个可操作性更强的标准：分离到可逆的程度就好了。对于具体的软件开发，可逆计算所提出的要求是，任何增加的功能都应该有配对的逆向取消机制，任何输入到系统中的信息都应该存在一种自动反向提取出来的方法。

可逆性是可以复合的，即如果每个部分都可逆，且部分之间的结合关系也可逆，则系统整体可逆。这一特点使得逐步构建大型的可逆系统成为可能。具体方式可以参考设计模式中的Command模式

[公式]

每个Command都包含一组配对的execute和undo操作，则一系列按顺序执行的Command可以被封装成一个BatchCommand，它的execute和undo操作可以由子命令复合得到。

现实世界中，熵增是无法逃避的宿命。但是即使无法完全消除熵增，我们仍然可以选择熵增发生的地方，例如将熵增集中在差量△中。特定客户的需求总是包含着大量随机的、偶然的因素，把它们纳入系统不可避免的会破坏原先统一均衡的系统结构，如果能够把这些偶然因素集中在一个可抛弃的差量△中，则可以保护核心架构不会受到侵蚀。当系统交付给新的客户时，我们不必携带上一个客户的个性化需求，可以始终从一个低熵的状态开始。
（二）量子力学中的世界图景

量子力学是描述宇宙的基本理论，它所研究的问题可以归结为算符（Operator）作用到所谓的态函数（State Vector）上，如何驱动系统发生演化的问题。

1925年海森堡提出了量子力学的第一种表述形式：矩阵力学，它也被称为海森堡图景。在这一图景中，态函数ψ为固定的对象，不随时间演化，而可观测算符A的演化满足方程

[公式]

1926年薛定谔提出了量子力学的第二种表述形式：波动力学，它也被称为薛定谔图景。在这一图景中，算符为固定的对象，不随时间演化，而态函数的演化满足大名鼎鼎的薛定谔方程

[公式]

其后不久，薛定谔证明了矩阵力学和波动力学的等价性。

1927年狄拉克提出所谓的“变换理论”，引出了量子力学的第三种表述形式：相互作用图景，它也被称为狄拉克图景。在这一图景中，首先将系统的Hamilton量拆分为已知的部分和待研究的微小扰动

[公式]

然后研究系统如何偏离已知模型进行演化，即我们所关心的是差量描述的演化情况。在相互作用图景下，态函数和算符都随时间演化

[公式]

[公式]

根据这三种图景都可以得到完全一致的物理测量结果

[公式]

相互作用图景是物理学家在实际工作中使用最多的图景。事实上，数学物理中存在一个专门的分支：微扰论（Perturbation Theroy），它系统化的研究在已知模型的基础上添加微小的扰动量，新的模型如何演化的问题。而理论物理中绝大多数有价值的计算都是在微扰论的框架下进行。

如果把量子力学和计算机理论做个对比，我们会发现量子力学中的世界图景和计算机理论的世界观之间存在一个有趣的对应关系

    薛定谔图景 <--> 图灵机海森堡图景 <--> lambda演算 狄拉克图景 <--> 可逆计算 

图灵机和lambda演算建立了通用计算机的概念基础，在理论上解决了计算的可行性问题，即为什么可以存在一种通用的机器执行机械化的动作，使用有限资源来完成所有我们能够想见的计算。在通用计算机已经普及的今天，我们所面临的最大的实际问题是如何有效的进行计算的问题。计算效率的提高依赖于我们发现计算中的“捷径”，而这依赖于我们对问题本质的洞察，而洞察的产生与问题的表述形式息息相关。表象（representation）变换本身甚至就是解决问题的一种方式，因为变换后的问题表象有可能使得解决方案变得清晰可见。可逆计算借助于领域模型和差量描述，使我们的注意力得以聚焦在待解决的新问题上。
（三）群和结构主义

自从爱因斯坦发现相对论以来，现代物理学的大多数基本原理都建筑在群概念的基础之上。例如，狭义相对论对应于Lorentz群，量子电动力学对应于U(1)规范群等。

​ 所谓群（Group），就是定义了一个二元运算（不妨记为符号+），并满足如下四条群公理的非空集合G。

    封闭律。集合中任意两个元素的运算结果仍属于该集合。 [公式] 结合律。运算可以局部进行，运算的最终结果与运算的结合顺序无关。 [公式] 幺元律。集合中存在单位元0,它对任何元素的作用结果都是无作用。 [公式] 逆元律。集合中对每一个元素a, 存在对应的逆元素-a，它可以完全取消a的作用。 [公式] 

这四条公理看似非常简单，却蕴含着非常深刻的数学内容。例如，如果只考虑元素个数有限的所谓有限群，不用增加任何其他假定，仅依赖这四条公理，即可推导出大量数学定理。在1955年至2004年间共100多位数学家在500多篇期刊文章中写下了上万页的证明，才完成了对有限群分类的工作。

封闭律是为了确保所有的运算结果都仍然在定义范围之内，不会出现运算结果无法描述的情况，这样运算就可以一直持续下去，构成很长的推理链条。例如，Lisp语言具有所谓的同像性（homoiconicity），Lisp宏的输出仍然是合法的Lisp语言，这正是封闭律的一种体现。

结合律意味着可以进行局部运算，而不用依赖于全局结构，这样才可能实现子结构的二次封装。例如，

[公式]

对于满足结合律的运算，可以将 B和C抽象为一个新的结构X，而将D和E抽象为一个新的结构Y，X和Y的组合可以被再次抽象为结构Z。

满足结合律的运算可以实现局部优化，即我们可以选择在合适的地方加上括号，实现局部的预计算。例如

[公式]

所谓的分而治之（Divide And Conquer）技术，之所以能够加速计算，很多时候所利用的也就是结合律，比如说归并排序。

幺元律的作用在于它使得差量成为第一性的概念。在具有单位元的系统中，任何量都可以被看作是与单位元之间的差量。例如

[公式]

从哲学上说，物理学格物以致知，我们所知的一切都只是世界的变化，世界的本体是不可观测的。所谓的差量（有正有负）实际上就是我们知识的全部。

如果满足封闭律，结合律和幺元律，在数学上就可以称之为“幺半群”。函数式编程中著名的Monad，只不过是自函子范畴上的幺半群而已。

Monad只是幺半群，它不满足逆元律。在群的四条公理中，最难被人们所认识的也是逆元律。从自然数发展的历史来看，欧洲数学家直到17世纪才接受负数的概念，这反映出本质上逆元的概念存在令人困惑之处。在当时的人们看来，负数对应于不存在的事物，既然对应的对象不存在，负数本身怎么能够存在呢？

逆运算对于很多数学推导来说都是必不可少的。例如在引入负数之前，

[公式]

这两个方程的结构是完全不同的，它们需要不同的求解技术，因此也就不可能利用符号抽象出二次方程的标准形式

[公式]

引入负数才使得我们能够以统一的方式提出问题，并研究通用的求解技术。

基于逆元可以在任意元素之间建立关联，从而实现任意元素之间的转化。这样元素之间的关系就突破了简单的整体-部分或者一般-特殊等关系的范畴，进入更加抽象的结构运算范畴。这种思想上的变革启发了哲学中的结构主义思潮。

在哲学上，结构主义提出结构具有三个要素：整体性，转换性（具有转换规律或法则），自律性（自身调整性）。整体性意味着结构不能被简单的切分，其构成要素通过内在的关系运算实现大范围的关联与转换，整体之所以成为整体正是以转换/运算的第一性为保证的。这种转换可以是共时的（同时存在的各元素），也可以是历时的（历史的转换构造过程），这意味着结构总要求一个内在的构造过程，在独立于外部环境的情况下结构具有某种自给自足的特性，不依赖于外部条件即可独立的存在并保持内在的活动。自律性意味着结构内在的转换总是维持着某种封闭性和守恒性，确保新的成分在无限地构成而结构边界却保持稳定。注意到这里对结构的评判并不是来自外在规范和约束，而是基于结构内在的规律性，所强调的不是结构对外部条件的适应性，而是自身概念体系的完备性。实际上，一个无法直接对应于当前实际环境的结构仍然可能具有重要的价值，并在解决问题的过程中扮演不可或缺的角色。在合理性这个视角下，我们所关注的不仅仅是当前的现实世界，而是所有可能的世界。结构独立于内容存在于抽象的数学世界中，一个“合理”的结构的价值必能在它所适应的具体世界中凸显出来。

在建立领域模型时，我们可能经常会问这个模型是否是对业务的准确描述，是否可以适应需求的变更，是否允许未来的各种扩展等等。但是如果换一个思维方向，我们会发现这些问题都假定了存在最适合业务领域的唯一理想的模型，我们想知道当前模型和理想的模型之间相差多远。这些问题都是针对最终确立的模型而发问的，而在模型构建的过程中，那些可被利用的，已存在的或者可以存在的模型又是哪些呢？每一个信息模型都对应着某种自动推理机，可以接收信息并做一定的推导综合工作。一个可行的问题是，如何才能更有效的利用已有的信息进行推导，如何消除冗余并减少各种转换成本。我们经常可以观察到，某一信息组织方式更充分的发掘了信息之间的内在关联（表现为它对信息的使用不是简单的局域化的，而是在多处呈现为互相纠缠的方式，难以被分解），这种内在关联足够丰富，以至于我们不依赖于外部因素就可以独立的理解。这种纠缠在一起的信息块自然会成为我们建模的对象。

如果我们不再强求单一的、大而全的模型，使得模型的“覆盖能力”不再是我们关注的重点，那么建模的思维图式将会发生深刻的转变：最终的模型可以由一系列微模型交织构成，每一个微模型在某种程度上说都是自己自足、自圆其说的，它的存在合理性由其内在逻辑的自洽性决定。在这种图式下，所谓的模型就相当于是已经确立的数学定理，如果增加新的假设，我们可以通过已有的定理推导出新的定理，也就是建立新的模型。
编辑于 2022-04-24 22:16

]]
[[
https://zhuanlan.zhihu.com/p/66548896
[
其实仔细思考一下人在软件开发中所承担的工作内容，就可以发现为什么我们需要如此多的人工。大部分程序工作并不是去建立新的抽象（编写复杂的组件、算法、框架），而是在做某种逻辑等价的形式转换。比如，将用户的查询请求转换成数据库可以理解的SQL语言，将流程流转逻辑适配到工作流引擎所要求的接口格式等。

同样的软件功能，会ios开发的一般并不会android开发，反之亦然。在某种意义上，很多程序员的工作其实类似于古时候代人写信的秀才，他们负责将人类普遍理解的逻辑翻译成计算机所理解的API调用，而且每个人掌握了回字的不同写法，写出来的东西也五花八门。
]

canonical
千山万水
NOP --- 下一代软件生产范式
25 天前 · 来自专栏 可逆计算

作者： Canonical

什么是NOP？NOP是Nop is nOt Programming 以及 Nop Oriented Programming的递归缩写，它代表了一种以可逆计算理论为指导，采用非编程的方式，通过人机智能协作，批量化进行软件定制生产的下一代软件生产范式。NOP的目标是在提升10倍生产率的同时提升10倍软件质量，在软件开发、测试、文档、部署、维护的全生命周期内降低10倍人力需求，为智能时代实现软件全面普及化奠定基础。
一. 智能时代的软件需求

大数据和人工智能的发展带来了第四次工业革命（工业4.0）的曙光，工业4.0所描绘的图景应该是万物互联、自主协同、实时感知、在线演化，而这一切智能都需要由软件来赋予，软件就是智能时代的电力和能源。2017年中国国际软件博览会全球软件产业发展高峰论坛的主题就是“软件定义未来”。但是软件定义未来，谁来定义软件？

反观软件生产自身，我们不得不正视一个令人尴尬的事实：软件研发一点都不智能，它是严重依赖大量程序员手工劳动的一种效率极其低下的过程。即使是一名高级工程师，一整年能输出的有效代码量也很难超过2万行，软件研发的成本让世界顶级奢侈品都相形见绌。

软件的经济学与物质生产具有本质不同：构造成本很高，但是复制成本近乎为0，在完全不修改的情况下没有折旧一说，增加一个使用者的边际成本极低。如果投入大量人力物力维护唯一的软件产品，让所有人都使用同样的功能集，那么软件的生产成本可以被摊薄，创造出远超物质生产的价值产出，这是互联网经济的内在技术逻辑。

但是随着互联网进入下半场，to B市场的逻辑开始挑战to C市场的成功经验。互联网巨头们都在强调千人千面，展现给每位用户的都是针对该用户通过AI算法”精心优化“的界面。但是千人千面，却没有一面是用户可以随意指定的一面，没有一面是用户真正能够掌控的一面。

企业客户不是沉默的看客，而是需要为生存拼尽全力的主动猎食者。企业软件需要实现客户需求，而客户需求就是客户为适应自身商业环境所需要特化的逻辑。现在的AI可以识别、可以预测，但却不能产生新的逻辑。一个有趣的现象是，大数据和人工智能公司在真正项目实施时投入大量人工，所做的却都是普通开发工作（这里编个接口，那里做个界面），与大数据和人工智能没有半点关系。

企业软件面临的现实是，任何一个功能点的潜在用户数都是极其有限的，而所有投入都要量入而出。大部分企业用不起定制软件，用得起的也多半养不起。就算软件开发商倒闭了，相关硬件绝版了，企业软件的用户一般也是宁肯操作系统降级、软硬件型号绑死，也坚决不升级。智能要进入企业市场成为一门挣钱的生意，难度要远超消费者市场。即使是SalesForce那样可扩展的云端SAAS应用，它的二次开发成本以及支持用户自定义逻辑的深度，也是远远不足以支撑工业4.0的目标蓝图的。
二. 智能时代的软件生产

如果我们做一点逆向思维，假设智能时代已经实现，想象一下此时的软件生产场景。

首先，人类社会传统的专业分工将会发生根本性改变，人与人之间靠着专业化、熟练度形成的隔离将被打破。未来的分工首先是人与机器之间的分工，所有依赖经验性的、可机械化的工作将由机器承担，人所负责的是创造性、探索性的工作。限制我们的，是每个人的想象力和他可以输出的逻辑要求，而不是这种逻辑的具体实现方式。

第二，劳动生产率的大幅提升使得小团队即可掌控复杂产品，传统软件工程为了控制人这一最复杂、最不确定的生产要素所提出的按功能细分纵向划分成多个团队的组织原则将变得不再有意义。

第三，机器与机器之间存在大量的直接交互，不再需要人作为中介参与。软件接口的设计原则向机器容易理解的方向倾斜，而不单纯强调适合人类的阅读理解。理想的软件接口应该具有多种展现形式，方便人和机器选择各自适合的方式进行处理，便于双方协作。

目前主流的软件开发技术所考虑的受众都只有人，认为只有人是软件生产的参与者和理解者。大部分程序语言以及领域特定语言（DSL）的设计强调类似自然语言（其实只是类似英语语法），并不利于机器解析和扩展。

互联网开发因为团队庞大，很多人推崇polyglot多语言编程，方便不同背景的程序员在实现特定业务功能时选择采用最适合的编程语言和开发工具，但是如果原本需要50人协作开发的产品最终交由一个5人团队完成，多语言开发就不可能成为一个合适的选择。

其实仔细思考一下人在软件开发中所承担的工作内容，就可以发现为什么我们需要如此多的人工。大部分程序工作并不是去建立新的抽象（编写复杂的组件、算法、框架），而是在做某种逻辑等价的形式转换。比如，将用户的查询请求转换成数据库可以理解的SQL语言，将流程流转逻辑适配到工作流引擎所要求的接口格式等。

同样的软件功能，会ios开发的一般并不会android开发，反之亦然。在某种意义上，很多程序员的工作其实类似于古时候代人写信的秀才，他们负责将人类普遍理解的逻辑翻译成计算机所理解的API调用，而且每个人掌握了回字的不同写法，写出来的东西也五花八门。

第一次工业革命发明了蒸汽机，将化石能源转化为热能再转化为机械能，推动机器代替了手工劳动。而第二次工业革命发明了电，经由电这个媒介，能量可以在各类形态之间发生自由转化，促使生产方式发生了进一步变革。智能时代的驱动力是信息，但目前信息却经常固化在特定的表达形式中, 只有受过专门训练的程序员才能理解软件中的信息并转化信息的表达形式。

近20年来软件世界的繁荣离不开开源软件的贡献，借助于人这一最高级别的智能转化媒介不断的对已有信息进行理解和改写，信息终于可以在各个公司之间、各种技术应用场景之间、各种表达形态之间发生流动了。使用单一公司提供的产品会发生供应商锁定问题，如果供应商倒闭，不仅仅供应商本身的软件功能无法使用，更重要的是我们基于供应商的软件所表达的业务逻辑也被锁定为固定形态而无法继续向前发展了。

使用开源软件避免了供应商锁定，但是仍然无法避免技术形态锁定。我们花费了巨额开发成本，基于某种技术开发的应用随着技术升级换代将会迅速过时，很多新兴技术自身的生存周期只有1-3年，而我们的业务逻辑却需要长久的存在下去，这就造成了循环往复的形态转化需求。

面向未来的软件生产范式应该是支持信息自由转化，支持人与机器更好的分工协作，支持用户特定的逻辑很自然的融入系统、驱动系统运行的。
三. NOP --- 让信息无界流动

NOP是以可逆计算理论为指导，综合利用模型驱动、差量编程、大数据和人工智能等技术所实现的一种新型软件生产范式，它致力于满足未来智能社会的软件生产需求。

目前企业软件的开发模式一般采用我们所谓编程（Programming）的方式：

    使用适用于所有业务领域的通用开发语言（例如Java/C#）和开发框架（如SpringBoot/dotNet Core）开发团队成员包括项目经理、需求人员、架构师、UI设计、程序员、测试和文档编写人员等开发过程一般由项目经理组织架构师、UI设计和需求人员进行沟通、讨论，确定界面展现形式和业务功能点对应的业务逻辑规则等。设计人员和需求人员讨论完毕后，编写出需求规格说明书、软件功能设计说明书等。开发人员拿到需求文档和设计文档后，理解文档编写人员的意图，使用熟悉的开发语言和开发框架，将其翻译为具体的技术实现代码。开发人员开发完毕之后，由测试人员负责进行初步的需求验证和正确性检查等，待产品功能基本完备后提交需求人员进行试用和验收。文档人员根据交付软件功能编写使用手册等。开发过程中发现实现出现偏差或者需求发生变化，则由相关人员提交对应测试文档、需求变更文档、设计修改文档等，重新交由上游人员按照流程处理。

以上生产过程在生产每一个功能点时都涉及到多处信息传递，而且都需要人的参与，人将信息编写为文档，再由另外的人理解文档，反向抽取信息再加工成机器可理解的信息（代码）。整个生产是一个相当复杂的过程，从需求人员提出需求到他可以直观的看到系统运行结果，一般至少需要一周以上的时间。

编程是我们非常熟悉的生产范式，无论是敏捷开发还是更传统的瀑布式开发，它所依赖的都是人与人之间的协调，而它的瓶颈也就在于人。人的不精确性和复杂性也会渗入到生产过程中，增加生产的困难。例如，一般情况下，软件需求文档、设计文档、使用文档和具体系统实现之间会逐渐出现偏离，最终可能完全相互脱离，文档失去参考价值。

NOP是一种非编程的生产范式，它强调的是开发人员、需求人员和机器三者之间协同工作，信息采用中立形式表达不再需要人工传递和转换。从编程到NOP需要经历所谓的范式转移过程，这意味着软件整体开发思想、开发架构、开发工具等都要经过彻底的改造，在新的技术思想指导下重构所有相关概念。

根据可逆计算理论，软件的构造可以被分解为两个相对独立的步骤：

    使用领域模型所构成的特征向量来描述业务需求 [公式] 领域模型经过生成器转换以及差量描述调整后，产生最终所需的软件产品 [公式] 

NOP不是编程，也不是不编程，它实际上是两种工作之间的一种新的相互配合方式。

用户所能直观理解的逻辑，也就是用户需要自己控制的业务需求，它们通过所谓的领域模型来表达，而领域模型可以通过可视化工具来进行自助式设计。需求人员是有足够的逻辑能力来表达自身需求的，他们只是不熟悉具体程序开发所需要的语言和工具而已。比如说，一般的需求人员都能熟练使用Excel、Visio等工具，并能够通过Excel公式、决策表、流程图等形式表达业务处理规则。

开发人员的工作可以看作是面向NOP编程（Nop Oriented Programming），他们所编写的不是对应具体需求的业务代码，而是对整个业务领域进行模型抽象，为业务用户提供可视化设计工具，并编写转换代码将领域模型映射为底层技术实现。对于部分很难进行直观展现的业务需求，开发人员能够通过差量编程的方式对已有模型进行补充和增强。

NOP的核心是具有可逆语义的领域模型空间。NOP以可逆计算为指导理论，它在各个层面上都强调可逆性。领域模型的可逆语义指的是机器在不需要人工参与的情况下，可以自动从领域模型中抽取信息（部分或全部），自动将其转换为所需形式，并自动应用到所需场景。

    人工参与的本质原因在于系统自身不具备可逆性，因此需要补充系统之外的信息，例如我们世界的背景知识，存在于其他文档中的全局设计信息，以及只存在于程序员头脑中的经验和设计思想等。一段通用语言编写的代码很可能无法通过工具自动分析得出其精确的设计意图，只有通过人这种最高级别的智能分析才可以实现逆向工程，反向抽取出其内在语义。但是如果采用精心设计的领域模型，则机器就可以很容易的理解模型语义，并在多种场景下以不同的方式使用同一信息。

在可逆语义假设下，我们很容易实现同一信息的多种展现形式，可视化设计仅仅是可逆语义的一个简单应用。

[公式]

领域模型采用领域特定语言（DSL）来描述，界面生成器可以理解DSL，从中抽取信息将其转换为可视化界面，同时界面生成器提供了对应的逆向信息提取机制，可以从生成的可视化界面中反向提取出DSL模型信息。所谓的可视化设计不过是模型的两种表现形式（representation）之间的可逆转换而已。

NOP要求每一个领域模型都能进行可视化设计，这表面上看起来是一个非常大的工作量，因为我们需要为每个领域模型都要提供相应的可视化设计工具。但是可逆计算理论指出可逆性可以复合，我们只需要构建一个通用的设计器的设计器，即所谓的元设计器，使用它就可以无限量的生成针对特定DSL的可逆的可视化设计器。

为了保证模型语义的可逆性，可视化设计器必须允许用户扩展，将用户特定的业务逻辑直接在DSL层面进行表达。否则，头脑简单的机器将无法直接理解复杂的用户逻辑。NOP中的设计器的设计器正是传统模型驱动架构（MDA）所缺失的部分。

NOP生产范式下的生产过程：

    需求人员与机器协作完成业务建模：需求人员不需与技术人员沟通，直接使用类似Office的可视化工具对业务逻辑进行描述。人工智能可以在这一过程中扮演辅助角色，例如分析多个数据样本与指定领域模型的匹配情况，从而自动建立初步的模型描述等。
    需求人员与机器协作完成业务验证：业务建模的结果是直接可以运行的系统，需求人员可以立刻从系统得到反馈，验证自己的业务设计。
    机器自动录制测试用例，执行测试用例，完成回归测试和压力测试：因为业务系统根据领域模型自动生成，所以机器掌握了系统内在的很多逻辑信息，它可以将用户的业务验证操作步骤直接录制为可以直观理解的测试脚本，作为回归测试用例和压力测试用例。机器也可以自动进行探索式测试，并将测试路径以用户可以直观理解的步骤形式展现出来。
    机器跟踪用户操作过程，结合用户录入的模型信息，推知用户意图，从而自动生成相应操作手册和文档等。并且可以录制用户操作过程，作为在线教程。系统运行出现异常时，也可以录制用户操作步骤，便于技术人员复查。
    机器根据领域模型，自动生成数据库设计、概要设计、详细设计等设计文档。
    程序员在业务模型基础上补充分布式部署架构等纯技术层面信息。
    程序员使用差量编程完成少部分特殊需求的代码实现。如果需求很常见，程序员使用元设计器（设计器的设计器）改进可视化工具，从而减少自己未来的工作量。
    机器根据领域模型，自动生成相应运维监控指标，并对关键性数据进行采集和记录。
    机器在系统运行过程中，利用大数据和人工智能对运行数据进行分析，自动进行局部程序优化，例如SQL执行计划、数据分布策略等。
    机器根据领域模型，自动发布对外服务接口，并根据转换模型自动实现集成数据格式转换等。

借助于具备可逆语义的领域模型空间，通过NOP方式生产的软件不再是一个封闭的黑箱，而是打破了信息载体的形式边界，使得信息可以在人和机器，以及机器与机器之间自由流动。

NOP将会带来新的工作分工方式，更多的非软件专业人员可以参与到业务逻辑的构建过程中来，扩大软件的应用领域，加快软件的演化速度。NOP极大简化了机器眼中的软件构造，使得人工智能和大数据更容易和具体应用相结合，可以快速推进AI技术落地。

NOP生产是从简单到复杂的一个连续进化过程，通过不断补充对领域模型的解释方式，细化领域模型的描述粒度，我们可以不断改进已有的软件。
四. NOP的本质

生产力决定生产关系，生产关系反作用于生产力。第四次工业革命意味着生产力新的飞越，伴随它的必然是生产关系的根本性变革。智能时代的本质是机器智能的崛起，机器不再是被动的工具，而是能力与日俱增，逐步成长为生产活动的主动参与者。同时，面对越来越复杂的应用场景，直接面对需求变化的相关人员也逐渐成熟起来，他们不再接受固定的软件功能，而是有着自己特定的利益诉求，希望能够主动参与到软件构造过程中，主导软件在应用过程中的调整和演化。

在这种背景下，NOP生产范式本质上所体现的正是生产关系的一种新的变化，它所强调的是开发人员、需求人员和机器三者之间的协同工作，或者说三者合作完成最终软件功能的实现和调整，每一方都有自己的价值和活动空间。

传统的软件生产其核心只有开发人员，所有最终的生产活动都是围绕开发人员组织实施的，这种单纯依靠编程（Programming）的生产模式将所有压力集中在程序员身上，导致程序员不堪重负(不996干得过来吗？)。


另一方面，人工智能的火热发展让人们浮想联翩，采用“人工智能写代码”看似是一条解决问题的捷径。但问题在于，目前的人工智能只是所谓的浅层智能，可以解决简单的判断、识别问题，无法进行更加复杂的逻辑组织，在可预见的未来，人工智能写代码还只是一个美好的设想，没有真正能够落地的技术方案。

实际上，目前计算机科学对于程序结构的理解过于简单，只有简单的函数、类、对象等概念，明显是无法支撑复杂逻辑的自动化构建的（对比物理学就可以知道，夸克、原子、分子、固体、液体、气体、凝聚态、等离子体...，我们掌握了多少物质形态和物理规律才创造了现代工业化生产体系）。

为了使得机器和非专业技术人员也能够平等的参与软件生产，我们必须要建立一种新的逻辑抽象方式，使得逻辑可以按照复杂性分级，简单的可以被直观理解的逻辑，以及简单的可以被机器自动识别处理的逻辑需要被明确分离出来。可逆计算理论为实现这种逻辑分离提供了一条可行的技术路线。特别是可逆概念的系统化应用将构建一个信息转化友好的逻辑世界，使得智能更容易产生和成长。

NOP是面向未来的软件生产范式，在强人工智能诞生之前，它代表了机器智能、专业开发知识以及其他领域的人类智能相互协作的一种典型方式。在追寻强人工智能的漫长旅途中，我们需要加深对软件所处的逻辑空间内在构造规律的认知，智能社会的实现不可能是一蹴而就的，NOP的发展将是人工智能不断扩大应用范围的必经之路。
五. NOP不是什么
（一）NOP不是可视化编程

可视化仅仅是NOP的一个副产品，并不是NOP的目标。NOP首先是采用创新的技术思想，基于领域模型和可逆性的概念极大降低了软件结构构造的复杂性。在NOP中，通过领域模型的抽象，我们对于软件结构的认知更加深刻了，表达同样的业务逻辑，相比于传统的编程方式，我们所需要传递的信息总量大大下降了。即使完全不使用可视化设计工具，我们的生产效率可以出现指数级的上升。

一般的可视化编程强调的是模型的可视化语义，导致程序语义只能通过可视化界面来理解。如果可视化设计器出错了，则我们没有任何其他途径可以越过可视化设计器来直接修改业务代码。如果我们对现有的可视化设计器不满意，没有任何技术手段可以对可视化设计器本身进行定制修改。当我们在多个业务场景中需要有不同形式的可视化设计器来设计同一底层模型时，也没有规范化的方案来保证多个设计器语义之间的一致性。

更为严重的问题是，一般的可视化编程为了降低自身实现难度，会要求业务代码的实现结构也针对可视化设计器做大量侵入性的修改。业务代码中能够使用的抽象手段受到极大限制，阻碍了业务模型的深度复用。同时，可视化设计器自身的升级修改也可能导致业务代码需要进行相应的调整。

在NOP中，强制要求所有领域模型都具有可逆语义，因此同一个模型很自然的可以具有多种展现形式，可视化设计仅仅是可逆语义的一个简单应用而已。在NOP中，不需要针对每一个领域模型单独编制其对应的可视化设计工具，元设计器可以利用模型的可逆语义自动的生成对应的设计器。
（二）NOP不是代码生成工具

NOP依赖于内置的代码生成器（Generator）来推导产生大量的衍生代码，但这种代码生成是一个抽象的概念，它类似于反复应用不同的数学定理来推导产生新的定理，具体实现中可以对应很多种不同的实现手段。

一般概念中的代码生成工具都是单向的、一次性的脚手架生成器。程序员设计好模型后，手工运行代码生成工具，根据模型生成脚手架代码，然后程序员再手工调整生成出来的代码，填充更多的细节等。如果模型发生变动，重新运行代码生成工具时将导致已生成的代码被覆盖，手工调整的部分将会丢失。在这种开发模式中，代码是第一位的，而模型是相对次要的、仅起参考作用的。当代码和模型冲突时，胜出的永远是代码。

NOP中，模型是第一位的，代码必须永远与模型保持一致。因此，NOP中的代码生成机制应该采用类似C++模板元编程（Template Metaprogramming）的编译期模板展开技术来实现。当模型发生变化时，由编译器自动重新生成代码，无需程序员手工操作。同时，基于可逆计算理论，NOP是支持增量模型变化的，当模型变动时不会覆盖程序员手工编写的代码，而只会传播模型的增量变化部分，同时自动实现模型代码和程序员手工编写代码之间的差量合并。
（三）NOP不是零代码开发

零代码（zero-code/no-code）开发平台的目标用户不是专业程序员，而是具有一定技术理解力的业务人员，它强调的是普通人经过简单培训即可独立实现业务软件模块的快速开发。为了尽量减少对业务人员的技术储备要求，同时尽量降低业务人员在操作过程中出错的可能性，零代码开发平台唯一的选择就是尽可能多的替用户做决定，呈现给用户尽量少的技术选项。因此，零代码开发平台如果好用、易用，就必然是用途非常狭窄的、功能固化的。它一般只针对小型系统，很少考虑架构层面的可扩展性，也很少考虑性能、安全性等非功能性需求。

为了克服零代码开发的弊端，最近几年还出现了一种所谓的低代码开发（Low-code Development）模式，它通过可视化设计结合少量编码的方式极大扩充了自身适用的应用范围。

NOP面向的群体是专业程序员以及业务人员，它能够支持从简单的小型应用（如普通的OA和MIS系统）到复杂的大型关键性应用（如银行核心系统）之间的连续演化，可以有效的实现专业程序员和业务人员之间的分工协作。专业程序员的核心价值在于建立领域抽象，将业务领域中常见的逻辑组织模式通过领域特定语言（DSL）和业务组件的方式固化下来。业务人员在已经确定的技术范围之内，就可以使用可视化设计工具创建和修改领域模型（使用DSL来表示），从而实现业务功能模块的开发。

NOP不仅仅不是零代码开发，它也不是低代码开发。零代码开发是完全没有扩展能力，低代码开发是允许开发人员编写第三方组件和插件，在一定程度上扩展可视化开发工具的能力。但是低代码开发平台的扩展能力仍然是非常受限的，这典型的就表现为low code开发平台本身并不是使用low code开发技术开发出来的，而且low code开发平台一般会给扩展代码增加大量限制性要求，这对于开发人员而言，意味着他所能动用的技术武器库是有着明显倒退的。

而NOP与low code的不同之处在于，NOP的理论基础是可逆计算理论而不是模型驱动架构（MDA）和组件/构件理论，它从本质上摆脱了现有主流技术体制对软件构造过程的基本限制。在NOP中，所有的领域模型设计器都是基于可逆计算原则利用元设计器逐步构建出来的。
（四）NOP不是更强大、更高级的程序语言

从汇编到Fortran，到C/C++语言，再到Java/C#语言，一路走来，程序语言的抽象层次在不断提高，越来越多的通用逻辑结构被内置到语言中，语言变得越来越强大。一些现代高级语言不断追求代码形式的表现力，如号称综合了面向对象和函数式编程等多种编程范式的Scala语言，往往一句话可以顶传统编程语言的n句。所谓第四代程序语言（4GL）更是内置了数据库管理、界面布局等大量针对特定领域的语言结构，使得开发专项应用时如鱼得水。

NOP的核心并不是一个单一的、与现有编程语言相比更加强大的高级程序语言，它强调的是由大量不同的领域特定语言（DSL）所共同构建的领域模型空间，以及领域模型空间中所需要满足的可逆性原则。如果仔细回顾一下历史，我们会发现，传统的编程语言都是图灵完备的通用程序语言。通过不断引入强大的通用语言结构，我们在所有业务领域都免费获得了新的更高层次的抽象能力，每一代的程序语言都相当于是更好的、更强大的图灵机。

但是正如摩尔定律终将走到尽头，通用程序语言的这种免费的抽象提升也逐渐陷入停滞，这表现为主流程序语言内置的语言特性开始出现加速趋同的倾向。不同的语言具有类似的语言特性，它们在某种意义上是完全等价的，差别仅仅是语法形式上的，或者说是文化习惯上的。

可逆计算理论指出可以定义一个新的通用语言结构：可逆的差量运算，从而再一次为所有领域免费提供了抽象提升的机会。但这一概念真正的重要性在于，它打开了一条与此前完全不同的抽象上升通道。可逆计算将领域特定语言（DSL）推到了应用前台，而DSL相比于通用语言不是更强大，只是更有用。

在可逆计算理论中，DSL需要超越通用语言提供针对特定领域的更有效的逻辑表达形式，同时在结构层面需要满足某种可逆性要求，DSL为了将某一方面推进到极致就必须放弃很多其他方面的能力，导致它往往不是图灵完备的！

NOP中，大量图灵不完备的、只针对特定领域的DSL构成一个语言森林，我们不再依赖单一的、固定的语法结构，而是直面世界的复杂性，开始构建细腻丰富的结构层次。同时，NOP中需要根据领域模型推导生成衍生代码，这在DSL层之下开辟了一个新的战场：编译器所在的元模型空间。传统上，程序语言的语法规则是固定的，即使是内置领域相关结构的第四代程序语言（4GL），也是不允许程序员定制和选择编译规则的。NOP中，代码生成规则也只是普通的代码，程序员可以自由的定制和扩充，整个编译规则空间是图灵完备的。NOP打破了旧世界对程序员创造力的桎梏，就像一句口号所鼓吹的，未来“只有想不到，没有做不到”。
（五）NOP不是人工智能

NOP虽然致力于解决智能时代的软件生产力瓶颈问题，但是它并不依赖于人工智能的概念和技术，它与人工智能是一种相辅相成的关系。

人工智能可以作为庞大的充满不确定性的世界和确定性的小型模型空间之间的一个桥梁。

[公式]

或者作为更加人性化的输入输出接口

[公式]

NOP通过可逆的领域模型简化了人工智能所需要处理的逻辑结构，并可以利用人工智能来与人类世界以及大数据世界交互。人工智能负责解决的问题往往是局部性的非常困难的技术问题，它要发挥最大作用还需要和周边系统和人员发生协同作用，而NOP所提供的正是一种整体解决方案。

以下为闲聊时间

TL;DR

不知诸位看官有没有发现，业内与差量（Delta）相关的概念正如同雨后春笋一样纷纷冒头。前段时间Databricks公司发布新产品，干脆直接叫作Delta Lake。搞神经网络的家伙们也沿着ResNet越走越远，最近流行的概念已经是differential programming。这反映了整个业界正在经历从全量思维向差量思维的转变，差量革命一触即发。

很多人已经敏锐的意识到了技术发展到了一个转折点，一种新的技术可能性已经出现。现在这种情形其实非常类似多年以前Ajax和Agile概念诞生的前夕，有很多独立的实践，有各种聪明的实现，但是还缺乏一个有灵魂的概念，能够把它们统摄在一个具有普遍意义的命题之下。

我的观点是差量不仅仅是简单的差别、增量、变化，可逆才是它的灵魂！可逆计算理论可以为下一代软件构造提供一个合适的理论框架，突破简单的组件式、积木式构建思想的束缚，为前端的、后端的、应用层的、系统层的等等诸多表面上形式不同的逻辑构造方案找到统一的理论解释，并推动它们的协同演化。当从细部到整体，从内部组成到外部环境，各个层面都满足可逆性要求时，软件的构造将出现真正本质性的变化。
canonical：可逆计算：下一代软件构造理论131 赞同 · 41 评论文章

智能时代的软件需求必然催生新的软件生产模式。国外逐渐开始出现所谓的Low Code开发模式，而国内也是一众的免编程、No Code的某某云。但是这些概念在感觉上总是差点意思。

No Code基本上就是No Brain，注定无法生产足够复杂的商业逻辑。而Low Code听着也有点"low"(谁让它的名字里就带个low字呢)，而且Code的概念是程序员圈子里的“黑话”，投资人不一定懂，万一说你这是码农思维，那还怎么从他身上扎钱呢？

其实，免编程也好，快速开发也好，直接作为生产力工具在中国的大环境里不一定有着很大的实际优势。我们有着奋斗者的精神，有996/007的福报，税务上再找点"优惠"，整体利润瓶颈不一定在人工上。再说，很多系统的建设目的本来就不是为了用的，toB市场的水，深不见底。

NOP是我们团队所提出的一个新的概念。它的核心不是简单的降低生产成本，而是可以促成新的分工方式，从而促进软件形态的变革，创造新的商业模式。另外，关键的关键，是它的名字起得好啊！

    NP ?= P 是计算机科学的核心问题之一。 NP中间加上一个元音o之后，发音朗朗上口。 NOP是Nop is nOt Programming和Nop Oriented Programming的递归缩写，这符合黑客社区的传统。 nop在计算机领域也有空操作的意思，这符合可逆计算“正+负=空”的思想。

总之，NOP即有理论支撑，又有文化渊源，高端大气上档次有木有？总而言之，这么闪亮的概念，你值得拥有。我们的口号是You can Nop it!

码这么多字，目的就是为了传播可逆计算和NOP的思想。希望更多的架构师能够从单纯的业务系统构建过程暂停一下，喘喘气，将思考的方向从如何构建好用/高效的系统转向如何将更多的逻辑分离，如何通过差量的方式表达逻辑。它的目的不一定是提高生产力，而首先是为了加深我们对世界基本构造规律的认识。

前段时间，和 @徐飞 、 @侯振宇 等人也作了简短沟通，交流了一下业界情况和相关技术方案，发现很多队伍已经上路了，看起来还都兵强马壮的样子。欢迎有兴趣的同仁和我联系（canonical_entropy@163.com），共同探讨未来软件的架构模式。

支付宝现在跑得很快，一些做法可以纳入到NOP的范畴中考察。侯振宇对此作了很好的总结，很值得参考一下。
侯振宇：长夜未央——企业级研发提效的下一阶段170 赞同 · 11 评论文章
侯振宇：十倍效能提升——Web 基础研发体系的建立647 赞同 · 30 评论文章


听风看雨，无问西东。

生死看淡，不服就干！
编辑于 2022-04-24 22:16

]]
[[
https://zhuanlan.zhihu.com/p/64004026

canonical
千山万水
可逆计算：下一代软件构造理论
25 天前 · 来自专栏 可逆计算

    谨以此文庆祝清华建校108周年，及5字班本科毕业20周年

作者： Canonical

众所周知，计算机科学得以存在的基石是两个基本理论：图灵于1936年提出的图灵机理论和丘奇同年早期发表的Lambda演算理论。这两个理论奠定了所谓通用计算（Universal Computation）的概念基础，描绘了具有相同计算能力（图灵完备），但形式上却南辕北辙、大相径庭的两条技术路线。如果把这两种理论看作是上帝所展示的世界本源面貌的两个极端，那么是否存在一条更加中庸灵活的到达通用计算彼岸的中间路径?

自1936年以来，软件作为计算机科学的核心应用，一直处在不间断的概念变革过程中，各类程序语言/系统架构/设计模式/方法论层出不穷，但是究其软件构造的基本原理，仍然没有脱出两个基本理论最初所设定的范围。如果定义一种新的软件构造理论，它所引入的新概念本质上能有什么特异之处？能够解决什么棘手的问题？

本文中笔者提出在图灵机和lambda演算的基础上可以很自然的引入一个新的核心概念--可逆性，从而形成一个新的软件构造理论--可逆计算（Reversible Computation）。可逆计算提供了区别于目前业内主流方法的更高层次的抽象手段，可以大幅降低软件内在的复杂性，为粗粒度软件复用扫除了理论障碍。

可逆计算的思想来源不是计算机科学本身，而是理论物理学，它将软件看作是处于不断演化过程中的抽象实体， 在不同的复杂性层次上由不同的运算规则所描述，它所关注的是演化过程中产生的微小差量如何在系统内有序的传播并发生相互作用。

本文第一节将介绍可逆计算理论的基本原理与核心公式，第二节分析可逆计算理论与组件和模型驱动等传统软件构造理论的区别和联系，并介绍可逆计算理论在软件复用领域的应用，第三节从可逆计算角度解构Docker、React等创新技术实践。
一. 可逆计算的基本原理

可逆计算可以看作是在真实的信息有限的世界中，应用图灵计算和lambda演算对世界建模的一种必然结果，我们可以通过以下简单的物理图像来理解这一点。

首先，图灵机是一种结构固化的机器，它具有可枚举的有限的状态集合，只能执行有限的几条操作指令，但是可以从无限长的纸带上读取和保存数据。例如我们日常使用的电脑，它在出厂的时候硬件功能就已经确定了，但是通过安装不同的软件，传入不同的数据文件，最终它可以自动产生任意复杂的目标输出。图灵机的计算过程在形式上可以写成

[公式]

与图灵机相反的是，lambda演算的核心概念是函数，一个函数就是一台小型的计算机器，函数的复合仍然是函数，也就是说可以通过机器和机器的递归组合来产生更加复杂的机器。lambda演算的计算能力与图灵机等价，这意味着如果允许我们不断创建更加复杂的机器，即使输入一个常数0，我们也可以得到任意复杂的目标输出。lambda演算的计算过程在形式上可以写成

[公式]

可以看出，以上两种计算过程都可以被表达为Y=F(X) 这样一种抽象的形式。如果我们把Y=F(X)理解为一种建模过程，即我们试图理解输入的结构以及输入和输出之间的映射关系，采用最经济的方式重建输出，则我们会发现图灵机和lambda演算都假定了现实世界中无法满足的条件。在真实的物理世界中，人类的认知总是有限的，所有的量都需要区分已知的部分和未知的部分，因此我们需要进行如下分解：

[公式]

重新整理一下符号，我们就得到了一个适应范围更加广泛的计算模式

[公式]

除了函数运算F(X)之外，这里出现了一个新的结构运算符⊕，它表示两个元素之间的合成运算，并不是普通数值意义上的加法，同时引出了一个新的概念：差量△。△的特异之处在于，它必然包含某种负元素，F(X)与△合并在一起之后的结果并不一定是“增加”了输出，而完全可能是“减少”。

在物理学中，差量△存在的必然性以及△包含逆元这一事实完全是不言而喻的，因为物理学的建模必须要考虑到两个基本事实：

    世界是“测不准”的，噪声永远存在 模型的复杂度要和问题内在的复杂度相匹配，它捕获的是问题内核中稳定不变的趋势及规律。

例如，对以下的数据 ​ ​

我们所建立的模型只能是类似图(a)中的简单曲线，图(b)中的模型试图精确拟合每一个数据点在数学上称之为过拟合，它难以描述新的数据，而图(c)中限制差量只能为正值则会极大的限制模型的描述精度。

以上是对Y=F(X)⊕△这一抽象计算模式的一个启发式说明，下面我们将介绍在软件构造领域落实这一计算模式的一种具体技术实现方案，笔者将其命名为可逆计算。 所谓可逆计算，是指系统化的应用如下公式指导软件构造的一种技术路线

[公式]

    App : 所需要构建的目标应用程序
    DSL: 领域特定语言（Domain Specific Language），针对特定业务领域定制的业务逻辑描述语言，也是所谓领域模型的文本表示形式
    Generator : 根据领域模型提供的信息，反复应用生成规则可以推导产生大量的衍生代码。实现方式包括独立的代码生成工具，以及基于元编程（Metaprogramming）的编译期模板展开
    Biz : 根据已知模型推导生成的逻辑与目标应用程序逻辑之间的差异被识别出来，并收集在一起，构成独立的差量描述
    aop_extends: 差量描述与模型生成部分通过类似面向切面编程（Aspect Oriented Programming）的技术结合在一起，这其中涉及到对模型生成部分的增加、修改、替换、删除等一系列操作 

DSL是对关键性领域信息的一种高密度的表达，它直接指导Generator生成代码，这一点类似于图灵计算通过输入数据驱动机器执行内置指令。而如果把Generator看作是文本符号的替换生成，则它的执行和复合规则完全就是lambda演算的翻版。差量合并在某种意义上是一种很新奇的操作，因为它要求我们具有一种细致入微、无所不达的变化收集能力，能够把散布系统各处的同阶小量分离出来并合并在一起，这样差量才具有独立存在的意义和价值。同时，系统中必须明确建立逆元和逆运算的概念，在这样的概念体系下差量作为“存在”与“不存在”的混合体才可能得到表达。

现有的软件基础架构如果不经过彻底的改造，是无法有效的实施可逆计算的。正如图灵机模型孕育了C语言，Lambda演算促生了Lisp语言一样，为了有效支持可逆计算，笔者提出了一种新的程序语言X语言，它内置了差量定义、生成、合并、拆分等关键特性，可以快速建立领域模型，并在领域模型的基础上实现可逆计算。

为了实施可逆计算，我们必须要建立差量的概念。变化产生差量，差量有正有负，而且应该满足下面三条要求：

    差量独立存在差量相互作用差量具有结构

在第三节中笔者将会以Docker为实例说明这三条要求的重要性。

可逆计算的核心是“可逆”，这一概念与物理学中熵的概念息息相关，它的重要性其实远远超出了程序构造本身，在可逆计算的方法论来源一文中，笔者会对它有更详细的阐述。

正如复数的出现扩充了代数方程的求解空间，可逆计算为现有的软件构造技术体系补充了“可逆的差量合并”这一关键性技术手段，从而极大扩充了软件复用的可行范围，使得系统级的粗粒度软件复用成为可能。同时在新的视角下，很多原先难以解决的模型抽象问题可以找到更加简单的解决方案，从而大幅降低了软件构造的内在复杂性。在第二节中笔者将会对此进行详细阐述。

软件开发虽然号称是知识密集性的工作，但到目前为止，众多一线程序员的日常中仍然包含着大量代码拷贝/粘贴/修改的机械化手工操作内容，而在可逆计算理论中，代码结构的修改被抽象为可自动执行的差量合并规则，因此通过可逆计算，我们可以为软件自身的自动化生产创造基础条件。笔者在可逆计算理论的基础上，提出了一个新的软件工业化生产模式NOP（Nop is nOt Programming），以非编程的方式批量生产软件。NOP不是编程，但也不是不编程，它强调的是将业务人员可以直观理解的逻辑与纯技术实现层面的逻辑相分离，分别使用合适的语言和工具去设计，然后再把它们无缝的粘接在一起。笔者将在另一篇文章中对NOP进行详细介绍。

可逆计算与可逆计算机有着同样的物理学思想来源，虽然具体的技术内涵并不一致，但它们目标却是统一的。正如云计算试图实现计算的云化一样，可逆计算和可逆计算机试图实现的都是计算的可逆化。
二. 可逆计算对传统理论的继承和发展
（一）组件（Component）

软件的诞生源于数学家研究希尔伯特第十问题时的副产品，早期软件的主要用途也是数学物理计算，那时软件中的概念无疑是抽象的、数学化的。随着软件的普及，越来越多应用软件的研发催生了面向对象和组件化的方法论，它试图弱化抽象思维，转而贴近人类的常识，从人们的日常经验中汲取知识，把业务领域中人们可以直观感知的概念映射为软件中的对象，仿照物质世界的生产制造过程从无到有、从小到大，逐步拼接组装实现最终软件产品的构造。

像框架、组件、设计模式、架构视图等软件开发领域中耳熟能详的概念，均直接来自于建筑业的生产经验。组件理论继承了面向对象思想的精华，借助可复用的预制构件这一概念，创造了庞大的第三方组件市场，获得了空前的技术和商业成功，即使到今天仍然是最主流的软件开发指导思想。但是，组件理论内部存在着一个本质性的缺陷，阻碍了它把自己的成功继续推进到一个新的高度。

我们知道，所谓复用就是对已有的制成品的重复使用。为了实现组件复用，我们需要找到两个软件中的公共部分，把它分离出来并按照组件规范整理成标准形式。但是，A和B的公共部分的粒度是比A和B都要小的，大量软件的公共部分是比它们中任何一个的粒度都要小得多的。这一限制直接导致越大粒度的软件功能模块越难以被直接复用，组件复用存在理论上的极限。可以通过组件组装复用60%-70%的工作量，但是很少有人能超过80%，更不用说实现复用度90%以上的系统级整体复用了。

为了克服组件理论的局限，我们需要重新认识软件的抽象本质。软件是在抽象的逻辑世界中存在的一种信息产品，信息并不是物质。抽象世界的构造和生产规律与物质世界是有着本质不同的。物质产品的生产总是有成本的，而复制软件的边际成本却可以是0。将桌子从房间中移走在物质世界中必须要经过门或窗，但在抽象的信息空间中却只需要将桌子的坐标从x改为-x而已。抽象元素之间的运算关系并不受众多物理约束的限制，因此信息空间中最有效的生产方式不是组装，而是掌握和制定运算规则。

如果从数学的角度重新去解读面向对象和组件技术，我们会发现可逆计算可以被看作是组件理论的一个自然扩展。

    面向对象 : 不等式 A > B 组件 : 加法 A = B + C 可逆计算 : 差量 Y = X + △Y 

面向对象中的一个核心概念是继承：派生类从基类继承，自动具有基类的一切功能。例如老虎是动物的一种派生类，在数学上，我们可以说老虎(A)这个概念所包含的内容比动物(B)这个概念更多，老虎>动物（即A>B）。据此我们可以知道，动物这个概念所满足的命题，老虎自然满足， 例如动物会奔跑，老虎必然也会奔跑（ P(B) -> P(A) ）。程序中所有用到动物这一概念的地方都可以被替换为老虎（Liscov代换原则）。这样通过继承就将自动推理关系引入到软件领域中来，在数学上这对应于不等式，也就是一种偏序关系。

面向对象的理论困境在于不等式的表达能力有限。对于不等式A > B，我们知道A比B多，但是具体多什么，我们并没有办法明确的表达出来。而对于 A > B， D > E这样的情况，即使多出来的部分一模一样，我们也无法实现这部分内容的重用。组件技术明确指出"组合优于继承"，这相当于引入了加法

[公式]

这样就可以抽象出组件C进行重用。

沿着上述方向推演下去，我们很容易确定下一步的发展是引入“减法”，这样才可以把 A = B + C看作是一个真正的方程，通过方程左右移项求解出

[公式]

通过减法引入的“负组件”是一个全新的概念，它为软件复用打开了一扇新的大门。

假设我们已经构建好了系统 X = D + E + F， 现在需要构建 Y = D + E + G。如果遵循组件的解决方案，则需要将X拆解为多个组件，然后更换组件F为G后重新组装。而如果遵循可逆计算的技术路线，通过引入逆元 -F， 我们立刻得到

[公式]

在不拆解X的情况下，通过直接追加一个差量△Y，即可将系统X转化为系统Y。

组件的复用条件是“相同方可复用”，但在存在逆元的情况下，具有最大颗粒度的完整系统X在完全不改的情况下直接就可以被复用，软件复用的范围被拓展为“相关即可复用”，软件复用的粒度不再有任何限制。组件之间的关系也发生了深刻的变化，不再是单调的构成关系，而成为更加丰富多变的转化关系。

Y = X + △Y 这一物理图像对于复杂软件产品的研发具有非常现实的意义。X可以是我们所研发的软件产品的基础版本或者说主版本，在不同的客户处部署实施时，大量的定制化需求被隔离到独立的差量△Y中，这些定制的差量描述单独存放，通过编译技术与主版本代码再合并到一起。主版本的架构设计和代码实现只需要考虑业务领域内稳定的核心需求，不会受到特定客户处偶然性需求的冲击，从而有效的避免架构腐化。主版本研发和多个项目的实施可以并行进行，不同的实施版本对应不同的△Y，互不影响，同时主版本的代码与所有定制代码相互独立，能够随时进行整体升级。
（二）模型驱动架构（Model Driven Architecture)

模型驱动架构（MDA）是由对象管理组织（Object Management Group，OMG）在2001年提出的软件架构设计和开发方法，它被看作是软件开发模式从以代码为中心向以模型为中心转变的里程碑，目前大部分所谓软件开发平台的理论基础都与MDA有关。

MDA试图提升软件开发的抽象层次，直接使用建模语言（例如Executable UML）作为编程语言，然后通过使用类似编译器的技术将高层模型翻译为底层的可执行代码。在MDA中，明确区分应用架构和系统架构，并分别用平台无关模型PIM（Platform Independent Model）和平台相关模型PSM（Platform Specific Model）来描述它们。PIM反映了应用系统的功能模型，它独立于具体的实现技术和运行框架，而PSM则关注于使用特定技术（例如J2EE或者dotNet）实现PIM所描述的功能，为PIM提供运行环境。

使用MDA的理想场景是，开发人员使用可视化工具设计PIM，然后选择目标运行平台，由工具自动执行针对特定平台和实现语言的映射规则，将PIM转换为对应的PSM，并最终生成可执行的应用程序代码。基于MDA的程序构造可以表述为如下公式

[公式]

MDA的愿景是像C语言取代汇编那样最终彻底消灭传统编程语言。但经历了这么多年发展之后，它仍未能够在广泛的应用领域中展现出相对于传统编程压倒性的竞争优势。

事实上，目前基于MDA的开发工具在面对多变的业务领域时，总是难掩其内在的不适应性。根据本文第一节的分析，我们知道建模必须要考虑差量。而在MDA的构造公式中，左侧的App代表了各种未知需求，而右侧的Transformer和PIM的设计器实际上都主要由开发工具厂商提供，未知=已知这样一个方程是无法持久保持平衡的。

目前，工具厂商的主要做法是提供大而全的模型集合，试图事先预测用户所有可能的业务场景。但是，我们知道“天下没有免费的午餐”，模型的价值在于体现了业务领域中的本质性约束，没有任何一个模型是所有场景下都最优的。预测需求会导致出现一种悖论: 模型内置假定过少，则无法根据用户输入的少量信息自动生成大量有用的工作，也无法防止用户出现误操作，模型的价值不明显，而如果反之，模型假定很多，则它就会固化到某个特定业务场景，难以适应新的情况。

打开一个MDA工具的设计器，我们最经常的感受是大部分选项都不需要，也不知道是干什么用的，需要的选项却到处找也找不到。

可逆计算对MDA的扩展体现为两点：

    可逆计算中Generator和DSL都是鼓励用户扩充和调整的，这一点类似于面向语言编程（Language-oriented programming）。 存在一个额外的差量定制机会，可以对整体生成结果进行精确的局部修正。

在笔者提出的NOP生产模式中，必须要包含一个新的关键组件：设计器的设计器。普通的程序员可以利用设计器的设计器快速设计开发自己的领域特定语言（DSL）及其可视化设计器，同时可以通过设计器的设计器对系统中的任意设计器进行定制调整，自由的增加或者删除元素。
（三）面向切面编程（Aspect Oriented Programming)

面向切面（AOP）是与面向对象（OOP）互补的一种编程范式，它可以实现对那些横跨多个对象的所谓横切关注点（cross-cutting concern）的封装。例如，需求规格中可能规定所有的业务操作都要记录日志，所有的数据库修改操作都要开启事务。如果按照面向对象的传统实现方式，需求中的一句话将会导致众多对象类中陡然膨胀出现大量的冗余代码，而通过AOP， 这些公共的“修饰性”的操作就可以被剥离到独立的切面描述中。这就是所谓纵向分解和横向分解的正交性。

AOP本质上是两个能力的组合：

    在程序结构空间中定位到目标切点（Pointcut）对局部程序结构进行修改，将扩展逻辑（Advice)编织(Weave)到指定位置。

定位依赖于存在良好定义的整体结构坐标系（没有坐标怎么定位？），而修改依赖于存在良好定义的局部程序语义结构。目前主流的AOP技术的局限性在于，它们都是在面向对象的语境下表达的，而领域结构与对象实现结构并不总是一致的，或者说用对象体系的坐标去表达领域语义是不充分的。例如，申请人和审批人在领域模型中是需要明确区分的不同的概念，但是在对象层面却可能都对应于同样的Person类，使用AOP的很多时候并不能直接将领域描述转换为切点定义和Advice实现。这种限制反映到应用层面，结果就是除了日志、事务、延迟加载、缓存等少数与特定业务领域无关的“经典”应用之外，我们找不到AOP的用武之地。

可逆计算需要类似AOP的定位和结构修正能力，但是它是在领域模型空间中定义这些能力的，因而大大扩充了AOP的应用范围。特别是，可逆计算中领域模型自我演化产生的结构差量△能够以类似AOP切面的形式得到表达。

我们知道，组件可以标识出程序中反复出现的“相同性”，而可逆计算可以捕获程序结构的“相似性”。相同很罕见，需要敏锐的甄别，但是在任何系统中，有一种相似性都是唾手可得的，即动力学演化过程中系统与自身历史快照之间的相似性。这种相似性在此前的技术体系中并没有专门的技术表达形式。

通过纵向和横向分解，我们所建立的概念之网存在于一个设计平面当中，当设计平面沿着时间轴演化时，很自然的会产生一个“三维”映射关系：后一时刻的设计平面可以看作是从前一时刻的平面增加一个差量映射（定制）而得到，而差量是定义在平面的每一个点上的。这一图像类似于范畴论（Category Theory）中的函子（Functor）概念，可逆计算中的差量合并扮演了函子映射的角色。因此，可逆计算相当于扩展了原有的设计空间，为演化这一概念找到了具体的一种技术表现形式。
（四）软件产品线（Software Product Line）

软件产品线理论源于一个洞察，即在一个业务领域中，很少有软件系统是完全独特的，大量的软件产品之间存在着形式和功能的相似性，可以归结为一个产品家族，把一个产品家族中的所有产品（已存在的和尚未存在的）作为一个整体来研究、开发、演进，通过科学的方法提取它们的共性，结合有效的可变性管理，就有可能实现规模化、系统化的软件复用，进而实现软件产品的工业化生产。

软件产品线工程采用两阶段生命周期模型，区分领域工程和应用工程。所谓领域工程，是指分析业务领域内软件产品的共性，建立领域模型及公共的软件产品线架构，形成可复用的核心资产的过程，即面向复用的开发（development for reuse）。而应用工程，其实质是使用复用来开发（ development with reuse），也就是利用已经存在的体系架构、需求、测试、文档等核心资产来制造具体应用产品的生产活动。

卡耐基梅隆大学软件工程研究所（CMU-SEI）的研究人员在2008年的报告中宣称软件产品线可以带来如下好处：

    提升10倍以上生产率 提升10倍以上产品质量 缩减60%以上成本 缩减87%以上人力需求 缩减98%以上产品上市时间 进入新市场的时间以月计，而不是年

软件产品线描绘的理想非常美好：复用度90%以上的产品级复用、随需而变的敏捷定制、无视技术变迁影响的领域架构、优异可观的经济效益等等。它所存在的唯一问题就是如何才能做到？尽管软件产品线工程试图通过综合利用所有管理的和技术的手段，在组织级别策略性的复用一切技术资产（包括文档、代码、规范、工具等等），但在目前主流的技术体制下，发展成功的软件产品线仍然面临着重重困难。

可逆计算的理念与软件产品线理论高度契合，它的技术方案为软件产品线的核心技术困难---可变性管理带来了新的解决思路。在软件产品线工程中，传统的可变性管理主要是适配、替换和扩展这三种方式：

这三种方式都可以看作是向核心架构补充功能。但是可复用性的障碍不仅仅是来自于无法追加新的功能，很多时候也在于无法屏蔽原先已经存在的功能。传统的适配技术等要求接口一致匹配，是一种刚性的对接要求，一旦失配必将导致不断向上传导应力，最终只能通过整体更换组件来解决问题。可逆计算通过差量合并为可变性管理补充了“消除”这一关键性机制，可以按需在领域模型空间中构建出柔性适配接口，从而有效的控制变化点影响范围。

可逆计算中的差量虽然也可以被解释为对基础模型的一种扩展，但是它与插件扩展技术之间还是存在着明显的区别。在平台-插件这样的结构中，平台是最核心的主体，插件依附于平台而存在，更像是一种补丁机制，在概念层面上是相对次要的部分。而在可逆计算中，通过一些形式上的变换，我们可以得到一个对称性更高的公式：

[公式]

如果把G看作是一种相对不变的背景知识，则形式上我们可以把它隐藏起来，定义一个更加高级的“括号”运算符，它类似于数学中的“内积”。在这种形式下，B和D是对偶的，B是对D的补充，而D也是对B的补充。同时，我们注意到G(D)是模型驱动架构的体现，模型驱动之所以有价值就在于模型D中发生的微小变化，可以被G放大为系统各处大量衍生的变化，因此G(D)是一种非线性变换，而B是系统中去除D所对应的非线性因素之后剩余的部分。当所有复杂的非线性影响因素都被剥离出去之后，最后剩下的部分B就有可能是简单的，甚至能够形成一种新的可独立理解的领域模型结构(可以类比声波与空气的关系，声波是空气的扰动，但是不用研究空气本体，我们就可以直接用正弦波模型来描述声波)。

A = (B,D)的形式可以直接推广到存在更多领域模型的情况

[公式]

因为B、D、E等概念都是某种DSL所描述的领域模型，因此它们可以被解释为A投影到特定领域模型子空间所产生的分量，也就是说，应用A可以被表示为一个“特征向量”（Feature Vector）， 例如

[公式]

与软件产品线中常用的面向特征编程（Feature Oriented Programming）相比，可逆计算的特征分解方案强调领域特定描述，特征边界更加明确，特征合成时产生的概念冲突更容易处理。

特征向量本身构成更高维度的领域模型，它可以被进一步分解下去，从而形成一个模型级列，例如定义

[公式]

, 并且假设D'可以继续分解

[公式]

，则可以得到

[公式]

最终我们可以通过领域特征向量U'来描述D’，然后再通过领域特征向量D‘来描述原有的模型A。

可逆计算的这一构造策略类似于深度神经网络，它不再局限于具有极多可调参数的单一模型，而是建立抽象层级不同、复杂性层级不同的一系列模型，通过逐步求精的方式构造出最终的应用。

在可逆计算的视角下，应用工程的工作内容变成了使用特征向量来描述软件需求，而领域工程则负责根据特征向量描述来生成最终的软件。
三. 初露端倪的差量革命
（一）Docker

Docker是2013年由创业公司dotCloud开源的应用容器引擎，它可以将任何应用及其依赖的环境打包成一个轻量级、可移植、自包含的容器（Container），并据此以容器为标准化单元创造了一种新型的软件开发、部署和交付形式。

Docker一出世就秒杀了Google的亲儿子lmctfy （Let Me Contain That For You）容器技术，同时也把Google的另一个亲儿子Go语言迅速捧成了网红，之后Docker的发展 更是一发而不可收拾。2014年开始一场Docker风暴席卷全球，以前所未有的力度推动了操作系统内核的变革，在众多巨头的跟风造势下瞬间引爆容器云市场，真正从根本上改变了企业应用从开发、构建到部署、运行整个生命周期的技术形态。

Docker技术的成功源于它对软件运行时复杂性的本质性降低，而它的技术方案可以看作是可逆计算理论的一种特例。Docker的核心技术模式可以用如下公式进行概括

[公式]

Dockerfile是构建容器镜像的一种领域特定语言，例如

FROM ubuntu:16.04
RUN useradd --user-group --create-home --shell /bin/bash work
RUN apt-get update -y && apt-get install -y python3-dev
COPY . /app
RUN make /app

ENV PYTHONPATH /FrameworkBenchmarks
CMD python /app/app.py

EXPOSE 8088

通过Dockerfile可以快速准确的描述容器所依赖的基础镜像，具体的构建步骤，运行时环境变量和系统配置等信息。

Docker应用程序扮演了可逆计算中Generator的角色，负责解释Dockerfile，执行对应的指令来生成容器镜像。

创造性的使用联合文件系统（Union FS），是Docker的一个特别的创新之处。这种文件系统采用分层的构造方式，每一层构建完毕后就不会再发生改变，在后一层上进行的任何修改都只会记录在自己这一层。例如，修改前一层的文件时会通过Copy-On-Write的方式复制一份到当前层，而删除前一层的文件并不会真的执行删除操作，而是仅在当前层标记该文件已删除。Docker利用联合文件系统来实现将多个容器镜像合成为一个完整的应用，这一技术的本质正是可逆计算中的aop_extends操作。

Docker的英文是码头搬运工人的意思，它所搬运的容器也经常被人拿来和集装箱做对比：标准的容器和集装箱类似，使得我们可以自由的对它们进行传输/组合，而不用考虑容器中的具体内容。但是这种比较是肤浅的，甚至是误导性的。集装箱是静态的、简单的、没有对外接口的，而容器则是动态的、复杂的、和外部存在着大量信息交互的。这种动态的复杂结构想和普通的静态物件一样封装成所谓标准容器，其难度不可同日而语。如果没有引入支持差量的文件系统，是无法构建出一种柔性边界，实现逻辑分离的。

Docker所做的标准封装其实虚拟机也能做到，甚至差量存储机制在虚拟机中也早早的被用于实现增量备份，Docker与虚拟机的本质性不同到底在什么地方？回顾第一节中可逆计算对差量三个基本要求，我们可以清晰的发现Docker的独特之处。

    差量独立存在：Docker最重要的价值就在于通过容器封装，抛弃了作为背景存在（必不可少，但一般情况下不需要了解），占据了99%的体积和复杂度的操作系统层。应用容器成为了可以独立存储、独立操作的第一性的实体。轻装上阵的容器在性能、资源占用、可管理性等方面完全超越了虚胖的虚拟机。差量相互作用：Docker容器之间通过精确受控的方式发生相互作用，可通过操作系统的namespace机制选择性的实现资源隔离或者共享。而虚拟机的差量切片之间是没有任何隔离机制的。差量具有结构：虚拟机虽然支持增量备份，但是人们却没有合适的手段去主动构造一个指定的差量切片出来。归根结底，是因为虚拟机的差量定义在二进制字节空间中，而这个空间非常贫瘠，几乎没有什么用户可以控制的构造模式。而Docker的差量是定义在差量文件系统空间中，这个空间继承了Linux社区最丰富的历史资源。每一条shell指令的执行结果最终反映到文件系统中都是增加/删除/修改了某些文件，所以每一条shell指令都可以被看作是某个差量的定义。差量构成了一个异常丰富的结构空间，差量既是这个空间中的变换算符（shell指令），又是变换算符的运算结果。差量与差量相遇产生新的差量，这种生生不息才是Docker的生命力所在。

（二）React

2013年，也就是Docker发布的同一年，Facebook公司开源了一个革命性的Web前端框架React。React的技术思想非常独特，它以函数式编程思想为基础，结合一个看似异想天开的虚拟DOM（Virtual DOM)概念，引入了一整套新的设计模式，开启了前端开发的新大航海时代。

class HelloMessage extends React.Component {
  constructor(props) {
    super(props);
    this.state = { count: 0 };
    this.action = this.action.bind(this);
  }

  action(){
    this.setState(state => ({
      count: state.count + 1
    }));
  },

  render() {
    return (
      <button onClick={this.action}>
        Hello {this.props.name}:{this.state.count}
      </button>
    );
  }
}

ReactDOM.render(
  <HelloMessage name="Taylor" />,
  mountNode
);

React组件的核心是render函数，它的设计参考了后端常见的模板渲染技术，主要区别在于后端模板输出的是HTML文本，而React组件的Render函数使用类似XML模板的JSX语法，通过编译转换在运行时输出的是虚拟DOM节点对象。例如上面HelloMessage组件的render函数被翻译后的结果类似于

render(){
   return new VNode("button", {onClick: this.action, 
          content: "Hello "+ this.props.name + ":" + this.state.count });
}

可以用以下公式来描述React组件：

[公式]

当状态发生变化以后，只要重新执行render函数就会生成新的虚拟DOM节点，虚拟DOM节点可以被翻译成真实的HTML DOM对象，从而实现界面更新。这种根据状态重新生成完整视图的渲染策略极大简化了前端界面开发。例如对于一个列表界面，传统编程需要编写新增行/更新行/删除行等多个不同的DOM操作函数，而在React中只要更改state后重新执行唯一的render函数即可。

每次重新生成DOM视图的唯一问题是性能很低，特别是当前端交互操作众多、状态变化频繁的时候。React的神来之笔是提出了基于虚拟DOM的diff算法，可以自动的计算两个虚拟DOM树之间的差量，状态变化时只要执行虚拟Dom差量对应的DOM修改操作即可（更新真实DOM时会触发样式计算和布局计算，导致性能很低，而在JavaScript中操作虚拟DOM 的速度是非常快的）。整体策略可以表示为如下公式

[公式]

显然，这一策略也是可逆计算的一种特例。

只要稍微留意一下就会发现，最近几年merge/diff/residual/delta等表达差量运算的概念越来越多的出现在软件设计领域中。比如大数据领域的流计算引擎中，流与表之间的关系可以表示为

[公式]

对表的增删改查操作可以被编码为事件流，而将表示数据变化的事件累积到一起就形成了数据表。

现代科学发端于微积分的发明，而微分的本质就是自动计算无穷小差量，而积分则是微分的逆运算，自动对无穷小量进行汇总合并。19世纪70年代，经济学经历了一场边际革命，将微积分的思想引入经济分析，在边际这一概念之上重建了整个经济学大厦。软件构造理论发展到今天，已经进入一个瓶颈，也到了应该重新认识差量的时候。
四. 结语

笔者的专业背景是理论物理学，可逆计算源于笔者将物理学和数学的思想引入软件领域的一种尝试，它最早由笔者在2007年左右提出。一直以来，软件领域对于自然规律的应用一般情况下都只限于"模拟"范畴，例如流体动力学模拟软件，虽然它内置了人类所认知的最深刻的一些世界规律，但这些规律并没有被用于指导和定义软件世界自身的构造和演化，它们的指向范围是软件世界之外，而不是软件世界自身。在笔者看来，在软件世界中，我们完全可以站在“上帝的视角”，规划和定义一系列的结构构造规律，辅助我们完成软件世界的构建。而为了完成这一点，我们首先需要建立程序世界中的“微积分”。

类似于微积分，可逆计算理论的核心是将“差量”提升为第一性的概念，将全量看作是差量的一种特例（全量=单位元+全量）。传统的程序世界中我们所表达的都只是“有”，而且是“所有”，差量只能通过全量之间的运算间接得到，它的表述和操纵都需要特殊处理，而基于可逆计算理论，我们首先应该定义所有差量概念的表达形式，然后再围绕这些概念去建立整个领域概念体系。为了保证差量所在数学空间的完备性（差量之间的运算结果仍然需要是合法的差量），差量所表达的不能仅仅是“有”，而必须是“有”和“没有”的一种混合体。也就是说差量必须是“可逆的”。可逆性具有非常深刻的物理学内涵，在基本的概念体系中内置这一概念可以解决很多非常棘手的软件构造问题。

为了处理分布式问题，现代软件开发体系已经接受了不可变数据的概念，而为了解决大粒度软件复用问题，我们还需要接受不可变逻辑的概念（复用可以看作是保持原有逻辑不变，然后增加差量描述）。目前，业内已经逐步出现了一些富有创造性的主动应用差量概念的实践，它们都可以在可逆计算的理论框架下得到统一的诠释。笔者提出了一种新的程序语言X语言，它可以极大简化可逆计算的技术实现。目前笔者已经基于X语言设计并实现了一系列软件框架和生产工具，并基于它们提出了一种新的软件生产范式（NOP）。
canonical：NOP --- 下一代软件生产范式35 赞同 · 9 评论文章

编辑于 2022-04-24 22:16

]]
[[
https://zhuanlan.zhihu.com/p/85492497

canonical
canonical
千山万水
从可逆计算看声明式编程
25 天前 · 来自专栏 可逆计算

可逆计算是笔者提出的下一代软件构造理论，它的核心思想可以表示为一个通用的软件构造公式

[公式]

在这一公式中，所谓的领域特定语言（DSL）占有核心位置，而可逆计算在实践中的主要策略就是将业务逻辑分解为多个业务切面，针对每个业务切面设计一种DSL来描述。DSL是声明式编程的一种典型范例，因此可逆计算可以被看作是声明式编程的一种实现途径。透过可逆计算的概念，我们可以获得对声明式编程的一些新的理解。
canonical：可逆计算：下一代软件构造理论131 赞同 · 41 评论文章
一. 虚拟化

DSL是声明式的，因为它所表达的内容不像是可以直接交由某个物理机器执行的，而必须通过某种interpreter/compiler进行翻译。不过如果换一个角度去考虑，这个interpreter一样可以被看作是某种虚拟机，只不过它不一定是冯.诺伊曼体系结构的。这里核心的要点在于，底层的interpreter只要支持少数固定的针对某个特定领域的原语，即可执行DSL所编写的程序，从而实现不同的业务逻辑。在一般的程序结构中，业务逻辑是一次性表达的，而在基于DSL概念的程序中，逻辑是分两阶段表达的。底层是与具体业务无关的，只与领域结构有关的相对通用的逻辑，而上层才是多变的，与特定业务场景绑定的逻辑。

在比较现代的大型软件结构设计中，多多少少都会体现出构造某种内部虚拟机的努力。以Slate富文本编辑器框架为例，它号称是一个“完全可定制的”框架，核心是一个所谓的“Schema-less core"。也就是说，Slate的内核并不直接知道它所编辑的数据的具体结构，这些结构是通过schema告诉内核的。schema定义了允许哪些节点，节点有哪些属性，属性需要满足什么样的格式。

const schema = {
  document: {
    nodes: [
      {
        match: [{ type: 'paragraph' }, { type: 'image' }],
      },
    ],
  },
  blocks: {
    paragraph: {
      nodes: [
        {
          match: { object: 'text' },
        },
      ],
    },
    image: {
      isVoid: true,
      data: {
        src: v => v && isUrl(v),
      },
    },
  },
}
​
<Editor
  schema={schema}
  value={this.state.value}
  ...
/>

自定义的render函数类似于解释器

function renderNode(props, editor, next) {
  const { node, attributes, children } = props
​
  switch (node.type) {
    case 'paragraph':
      return <p {...attributes}>{children}</p>
    case 'quote':
      return <blockquote {...attributes}>{children}</blockquote>
    case 'image': {
      const src = node.data.get('src')
      return <img {...attributes} src={src} />
    }
    default:
      return next()
  }
}

传统的富文本编辑器，在内核中需要明确知道bold/italic这样的概念，而在Slate的内核中，关键的关键就在于不需要知道具体的业务含义就可以操纵对应的技术元素，这就类似于硬件指令不需要知道软件层面的业务信息。通过使用同一个内核，我们可以通过类似配置的方式实现Markdown编辑器，Html编辑器等多种不同用途的设计器。
二. 语法制导

实现虚拟化，最简单的方式是采用一一对应的映射机制，即将一组动作直接附加到DSL的每条语法规则上，处理到DSL的某个语法节点时，就执行对应的动作，这叫作语法制导（Syntax Directed）。

基于XML或者类XML语法的模板技术，例如Ant脚本，FreeMarker模板都可以看作是语法制导翻译的范例。以Vue的模板语法为例，

<template>
    <BaseButton @click="search">
      <BaseIcon name="search"/>
    </BaseButton>
  </template>

template相当于是将抽象语法树（AST）直接以XML格式展现，处理到组件节点时，将会直接根据标签名称定位到对应组件的定义，然后递归进行处理。整个映射过程是上下文无关的，即映射过程并不依赖于节点所处的上下文环境，同样的标签名总是映射到同样的组件。

同样的套路构成了Facebook的GraphQL技术的核心，它通过语法制导将待执行的数据访问请求发送到一个延迟处理队列，通过合并请求实现批量加载优化。 例如，为处理如下gql请求

query {
      allUsers {
        id
        name
        followingUsers {
          id
          name
        }
      }
    }

后台只需要针对数据类型指定对应dataLoader

const typeDefs = gql`
  type Query {
    testString: String
    user(name: String!): User
    allUsers: [User]
  }

  type User {
    id: Int
    name: String
    bestFriend: User
    followingUsers: [User]
  }
`;

const resolvers = {
  Query: {
    allUsers(root, args, context) {
      return ...
    }
  },
  User: {
     // allUsers调用返回的每个User对象，其中只有followingUserIds属性，它需要被转换为完整的User对象
    async followingUsers(user, args, { dataloaders }) {
      return dataloaders.users.loadMany(user.followingUserIds)
    }
  }
};

为了方便实现语法制导这一模式，现代程序语言已经有了默认的解决方案，那就是基于注解（Annotation）的元编程技术。例如，python中的函数注解

def logged(level, name=None, message=None):
    """
    Add logging to a function. level is the logging
    level, name is the logger name, and message is the
    log message. If name and message aren't specified,
    they default to the function's module and name.
    """
    def decorate(func):
        logname = name if name else func.__module__
        log = logging.getLogger(logname)
        logmsg = message if message else func.__name__

        @wraps(func)
        def wrapper(*args, **kwargs):
            log.log(level, logmsg)
            return func(*args, **kwargs)
        return wrapper
    return decorate

 # Example use
 @logged(logging.DEBUG)
 def add(x, y):
    return x + y

将注解看作是函数名，这一观念非常简单直观，TypeScript也采纳了同样的观点。相比之下，Java的APT（Annotation Processing Tool）技术显得迂回冗长，这也导致很少有人使用APT去实现自定义的注解处理器，不过它的作用是在编译期，拿到的是AST抽象语法树，因此可以做一些更加深刻的转化。Rust语言中的过程宏（procedural macros）则展现了一种更加优雅的编译期实现方案。

#[proc_macro_derive(Hello)]
    pub fn hello_macro_derive(input: TokenStream) -> TokenStream {
        // 从token流构建AST语法树
        let ast = syn::parse(input).unwrap();

        // 采用类似模板生成的方式构造返回的语法树
        let name = &ast.ident;
        let gen = quote! {
        impl Hello for #name {
            fn hello_macro() {
                println!("Hello, Macro! My name is {}", stringify!(#name));
            }
        }
        };
        gen.into()
    }

    pub trait Hello {
        fn hello_macro();
    }

    // 使用宏为Pancakes结构体增加Hello这个trait的实现
    #[derive(Hello)]
    struct Pancakes;

三. 多重诠释

传统上一段代码只有一种设定的运行语义，一旦信息从人的头脑中流出经由程序员的手固化为代码，它的形式和内涵就固定了。但是可逆计算指出，逻辑表达应该是双向可逆的，我们可以逆转信息的流向，将以代码形式表达的信息反向提取出来，这使得“一次表达，多重诠释”成为实现声明式编程，分离表达与运行的常规手段。例如，下面一段过滤条件

<and>
  <eq name="status" value="1" />
  <gt name="amount" value="3" />
</and>

展现在前台，对应于一个查询表单，应用到后台，对应于Predicate接口的实现，发送到数据库中，转化为SQL过滤条件的一部分。而这一切，并不需要人工编码，它们只是同一信息的多重诠释而已。

随着编译技术的广泛传播，传统上的命令式编程经过再诠释，现在也具有了声明式的意味。比如，Intel的OpenMP（Open Multi-Processing）技术

int sum = 0;
   int i = 0;

   #pragma omp parallel for shared(sum, i)
   for(i = 0; i < COUNT;i++){
      sum = sum + i;
    }

只要在传统的命令式语句中增加一些标记，即可把串行执行的代码转化为并行程序。

而在深度学习领域，编译转换技术更是被推进到了新的深度。PyTorch和Tensorflow这样的框架均可将形式上的python函数编译转换为GPU上运行的指令。而TVM这样的大杀器，甚至可以直接编译得到FPGA代码。

多重诠释的可能性，使得一段代码的语义永远处于开放状态，一切都是虚拟化的。
四. 差量修订

可逆计算将差量作为第一性的概念，将全量看作是差量的特例。按照可逆计算的设计，DSL必须要定义差量表示，允许增量改进，同时，DSL展开后的处理逻辑也应该支持增量扩展。

以Antlr4为例，它引入了import语法和visitor机制，从而第一次实现了模型的差量修订。

在Antlr4中，import语法类似面向对象编程语言中的继承概念。它是一种智能的include，当前的grammar会继承导入的grammar的所有规则，tokens specifications，names actions等，并可以重写规则来覆盖继承的规则。

在上面的例子中，MyElang通过继承ELang得到若干规则，同时也重写了expr规则并增加了INT规则。终于，我们不再需要每次扩展语法都要拷贝粘贴了。

在Antlr4，不再推荐将处理动作直接嵌入在语法定义文件中，而是使用Listener或者Visitor模式，这样就可以通过面向对象语言内置的继承机制来实现对处理过程的增量修订。

// Simple.g4
grammar Simple; 

expr  : left=expr op=('*'|'/') right=expr #opExpr
      | left=expr op=('+'|'-') right=expr #opExpr
      | '(' expr ')'                      #parenExpr
      | atom=INT                          #atomExpr
      ;

INT : [0-9]+ ;

// Generated Visitor
public class SimpleBaseVisitor<T> extends AbstractParseTreeVisitor<T> implements SimpleVisitor<T> {
    @Override public T visitOpExpr(SimpleParser.OpExprContext ctx) { return visitChildren(ctx); }
    @Override public T visitAtomExpr(SimpleParser.AtomExprContext ctx) { return visitChildren(ctx); }
    @Override public T visitParenExpr(SimpleParser.ParenExprContext ctx) { return visitChildren(ctx); }
}

class MyVisitor<Double> extends SimpleBaseVisitor<Double>{
  ...
}

五. 自动微分

如果说声明式编程的理想是人们只需要描述问题，由机器自动找出解决方案，那么我们从哪里去找一类足够通用，而且又能够自动求解的问题呢？幸而自牛顿以降，科学昌明，我们还是积攒了几个这样的祖传问题的，其中一个就是自动微分。

只要指定几个基础函数的微分表达式，我们就可以自动计算大量复合函数的微分，这一能力是目前所有深度学习框架的必备技能。可逆计算理论指出，自动计算差量这一概念可以被扩展到数学或者算法领域之外，成为一种有效的软件结构构造机制。

以k8s为例，这一容器编排引擎的核心思想是通过声明式的API来指定系统的“理想”状态，然后通过监控测量不断发现当前状态与理想状态的偏差，自动执行相应的动作来“纠正”这些偏差。它的核心逻辑可以总结为如下公式：

[公式]

k8s所采用的这种设计原理可以称为是状态驱动（State Driven），它关注的重点是系统的状态以及状态之间的差异，而不再是传统的基于动作概念的API调用和事件监听。从动作（Action）到状态（State）的这种思维转换其实类似于物理学中从力的观点过渡到以势能函数（Potential）为基础的场（Field）的观点。

从状态A迁移到状态B，无论经过什么路径，最终得到的结果都是一样的，因此势的概念是路径无关的。摆脱了路径依赖极大简化了我们对系统的认知。而所谓的力，随时可以通过对势函数求导，从势函数的梯度得到。

[公式]

同样，在k8s中，对于任意的状态偏差，引擎都可以自动推导得到相应需要执行的动作。

从状态A迁移到状态B有多条可行的路径，在这些路径中按照成本或者收益原则选择其一，这就是所谓的优化。

从动作到状态的转换是整体思维模式的一种变革，它要求我们用新的世界观去思考问题，并不断调整相应的技术实现去适应这种世界观。这一变革趋势正在逐渐加强，也在越来越多的应用领域促生着新的框架和技术。

势的观念要求我们对状态空间有着全面的认知，每一个可达的状态都有着合法的定义。有的时候，对于特定应用而言，这种要求可能过于严苛，例如，我们可能只需要找到从特定状态A到特定状态B的某一条可行的道路即可，没必要去研究所有状态构成的状态空间自身，此时传统的命令式的做法就足够了。
六. 同构转化

太阳底下没有新鲜事。在日常编程中，真正需要人们去创造的新的逻辑是很少的，绝大多数情况下我们所做的只是某种逻辑关系的映射而已。比如说，日志收集这件事情，为了采集日志文件内容进行分析，一般需要使用类似logstash这样的工具解析日志文本到json格式，然后投递到ElasticSearch服务。

但是，如果在打印日志的时候，我们就保留对象格式，那么实际上可以不需要中间logstash的解析过程。如果需要对属性过滤或者进行再加工，也可以直接对接一个通用的对象映射服务（可以通过可视化界面进行映射规则配置），而不需要为日志处理领域单独编写一套实现。

// 保持对象格式输出日志
   LOG.info(日志码，{参数名：参数值});

很多时候，我们之所以需要程序员去编写代码，原因在于跨越边界时出现了信息丢失。例如，以文本行形式打印日志时，我们丢失了对象结构信息，从文本反向恢复出结构的工作很难自动完成，它必须借助程序员的头脑，才能消除解析过程中可能出现的各种歧义情况。

程序员头脑中的信息包括我们所处的这个世界的背景知识，各种习惯约定，以及整体架构设计思想等。因此，很多看似逻辑上等价的事情往往无法通过代码自动完成，而必须通过增加人这个变量来实现配平。

[公式]

现代数学是建立在同构概念基础之上的，在数学上我们说A就是B，潜台词说的是A等价于B。等价归并大幅削减了我们所需要研究的对象，加深了我们对系统本质结构的认识。

    为什么 3/8 = 6/16, 因为这就是分数的定义！（3/8，6/16，9/24...）这一系列表示被定义为一个等价类，它的代表元素就是3/8（参见 彭罗斯《通向实在之路--宇宙法则的完全指南》一书的前言）。

可逆计算强调逻辑结构的可逆转化，从而试图在软件构造领域建立起类似数学的抽象表达能力，而这只有当上下游软件各个部分都满足可逆原则时才能够实现效用的最大化。

例如，当细粒度组件和处理过程均可逆时，可视化设计器可以根据DSL直接生成，而不需要进行特殊编码

[公式]

在现实开发过程中实现可逆性的一个障碍在于，目前软件开发的目的性都是很强的，因此与当前场景无关的信息往往无处安放。为了解决这个问题，必须在系统底层增加允许自定义扩展的元数据空间。

[公式]

对应于A'部分的信息在当前的系统A中不一定会使用，但是为了适应系统B的应用逻辑，我们必须找到一个地方把这些信息存储下来。这是一种整体性的协同处理过程。

你注意到没有，所有能称得上现代的程序语言都经历了戴帽子工程改造，都支持某种形式的自定义注解（Annotation）机制，一些扩展的描述信息会存在帽子里随身携带。换句话说，(data, metadata)配对才是信息的完整表达，这和消息对象总是包含(body, headers)是一个道理。

世界如此复杂，目的为何唯一？在声明式的世界中，我们有必要持有一种更加开放的态度。戴帽子不为了挡风挡雨，也不为了遮阳防晒，我就为了好看不行吗？metadata是声明式的，一般我们说它是描述数据的数据，但实际上它就算当前不描述任何东西可以有自己存在的理由，不是说有一种用叫“无用之用”吗。
编辑于 2022-04-24 22:17

]]
[[
https://zhuanlan.zhihu.com/p/85491177
什么是声明式编程

canonical
千山万水
什么是声明式编程
25 天前 · 来自专栏 可逆计算

一. 声明式 vs. 命令式。

什么是声明式编程？一般来说我们对于声明式的理解都是相对于命令式（imperative）而言的。图灵教会了我们imperative的真谛，并赋予了它数学意义上的精确定义：一台有状态的机器，根据明确的指令（instruction）一步步的执行。而所谓的声明式，它可以看作是命令式的反面。曾有人言：一切非imperative，皆是declarative。从这个意义上说，越是偏离图灵机的图像越远的，就越是声明式的。

所以，函数式编程（Functional Programming）是声明式的，因为它不使用可变状态，也不需要指定任何的执行顺序关系（可以假定所有的函数都是同时执行的，因为存在引用透明性，所谓的参数和变量都只是一堆符号的别名而已）。逻辑式编程（Logical Programming）也是声明式的，因为我们只需要通过facts和rules描述我们所需要解决的问题，具体的求解路径由编译器和程序运行时自动决定。

如果说命令式对应于由具体的物理机器可执行的步骤，那么声明式就可以看作是对应于更高级别的抽象的表达。由此引申出一种令人浮想联翩的理解：命令式是关于“how to do”的，而声明式是关于“what to do”的。在这种理解下，SQL语言作为一种领域特定语言（DSL）是声明式的。SQL语言描述了我们希望得到的逻辑上的数据加工结果，由执行引擎将SQL语言翻译为物理执行计划。

参考Kowalski曾提出的公式：algorithm = logic + control，逻辑（解决问题时所需要用到的知识）可以独立于具体执行时的控制流（具体使用知识的解题策略）得到表达。在DSL中，重要的是表达所有需要表达的信息，表达时的先后顺序往往是不重要的，并且与具体执行时的处理顺序也没有什么必然的关系。比如SQL语句表连接的先后顺序，以及过滤条件的先后顺序原则上是不影响执行结果的。

select *
   from a,b,c
   where a.x = b.x and c.x = a.x

在逻辑上等价于

select *
   from c,b,a
   where c.x = a.x and a.x = b.x

注意到select写在from部分的前面并不意味着select部分先执行，实际上这里的顺序仅仅是习惯上的。在C#的LINQ语法中，我们会这样写

from x in array
  where x % 2 == 1
  orderby x descending
  select x * x;

二. 声明式编程：表达与运行分离

如果将命令式编程看作是一种“忠实的”表达（表达了就要执行，而且所表达的正是要执行的内容），那么声明式编程就是相当不老实的表达。
表达了可以不执行，甚至没法执行

比如说

list = range(0, Infinity); // 得到一个从0到无穷大的所有整数构成的数组
   list.take(5)            // 取数组的前5条记录

声明式编程中延迟计算是一个常见的特性，它极大增加了逻辑组织结构的灵活性。比如在WebMVC架构中

// action中
   entity = dao.getEntity(id)

   // view中
   entity.mainTable
   entity.subItems

基于ORM的延迟加载特性可以同时兼顾表达的便捷性和按需访问的高性能。在action层可以直接表达获取相关数据，但并不真正把所有数据都读取到内存中。当实际使用时，才通过延迟加载机制进行数据读取。
不仅表达当下，还表达未来

现代编程语言中标配的Promise对象，它表示了未来可以获得的一个值，当我们还未真正得到这个值的时候，就可以把它作为返回值返回，并在程序中作为参数传来传去。

而在传统的命令式编程概念中，函数的返回就表示执行完毕，如果是异步执行，则只能通过回调函数获取通知，在概念层面上我们并无法直接定义和使用“未来的值”。

async function asyncValue(){
    return new Promise((resolve, reject) => {
        setTimeout(() => resolve('a'), 1000)
     });
  }

  var result = asyncValue();
  doSomething(result);

  async function doSomething(input){
     console.log('begin');
     var result = await input;
     console.log('1 second later: result='+result);
  }

不仅表达自己有的，还表达自己没有的

未来的值虽然现在未来，但毕竟未来可期。但如果根本不知道未来是否会来，那能否给它分配一个表达形式呢？

在groovy语言中，提供了类似Ruby的methodMissing机制

class Foo {

    def methodMissing(String name, def args) {
        println "Missing method name is $name"
    }

    static def $static_methodMissing(String name, Object args) {
        println "Missing static method name is $name"
    }
    static def $static_propertyMissing(String name) {
        println "Missing static property name is $name"
    }

    def propertyMissing(String name) { println "Missing property name is $name" }
}

foo = new Foo();
fo.x;
foo.f();

三. 声明式 & 命令式

传统上主流编程语言都是偏向命令式的，因为我们的硬件运行环境都是图灵机的升级版本，软件的功能就是指导硬件执行预设的动作。甚至有一种说法，程序开发工作的本质就是命令式的，毕竟为老板的小目标（what）找到具体的技术实现方案（how）才是我们的本职工作。但是，如果仔细观察一下现代编程的日常，就会发现，绝大多数的编程工作是建立在声明式API的基础之上的。

比如说，要显示界面，我们通过字符串操作拼接出HTML问本，为了调用服务，我们拼接出URL和JSON文本，为了访问数据库，我们拼接出SQL请求。很少有人清楚，如何使用命令式的指令一步步的构造出完整的应用程序。即使是最简单的前台拖拽动作，我们所会的多半也只是调用一个Draggable组件，监听（声明）一下拖拽结束时的触发动作。在这个意义上说，我们所掌握的编程技能只是从一种声明式视图映射到另一种声明式视图之间的转换策略而已。

整个软件开发生态环境正在不断向着声明式和命令式水乳交融的方向发展。以前，为了突出声明式的部分，我们会选择模板语言，即在描述性内容中嵌入少量的命令式控制逻辑。而在今天，出现了JSX这种直接将描述性内容嵌入到命令式上下文中的技术。更进一步，类似SwiftUI这种基于通用程序语言直接实现声明式表达的技术正快步向我们走来

List(landmarks) { landmark in
       HStack {
          Image(landmark.thumbnail)
          Text(landmark.name)
          Spacer()

          if landmark.isFavorite {
         Image(systemName: "star.fill")
            .foregroundColor(.yellow)
          }
       }
    }

四. 可逆计算视角下的声明式编程

我们如何才能进一步推进声明式编程？如果套用What & How的比喻，方向就在于如何通过系统化的方案来定义What, 并自动推导得到How。可逆计算提供了实现DSL的一整套完整技术路线，同时也为实现声明式编程带来一些新的启发。

这里空白太小，我写不下了，且听下回分解。
canonical：从可逆计算看声明式编程19 赞同 · 8 评论文章

编辑于 2022-04-24 22:17

]]
[[
https://baike.baidu.com/item/%E5%A3%B0%E6%98%8E%E5%BC%8F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/22700944

目录
声明式编程语言

    科普中国 | 本词条由“科普中国”科学百科词条编写与应用工作项目审核
    审阅专家王慧维

在计算机科学中，声明式编程是一种编程范式，即构建计算机程序的结构和元素的一种风格，它表达了计算的逻辑而没有描述其控制流程。

许多应用这种风格的语言试图通过描述程序在问题领域必须完成的事情来最小化或消除副作用，而不是描述如何将它作为一系列编程语言原语来实现（如何离开直至语言的实现）。这与命令式编程相反，命令式编程以明确的步骤实现算法。

声明性编程通常将程序视为形式逻辑的理论，并将计算视为逻辑空间中的推论。声明式编程可能会极大地简化编写并行程序。

常用的声明性语言包括数据库查询语言（例如SQL，XQuery），正则表达式，逻辑编程，函数式编程和配置管理系统。

    中文名
    声明式编程语言
    外文名
    Declarative programming language

快速
导航

    编程

定义
声明式编程通常被定义为任何不是必须的编程风格。还有其他一些常见的定义，试图给这个术语一个定义，而不是简单地将它与命令式编程对比。例如：
a.一个描述计算应该执行的高级程序。
b.任何缺乏副作用的编程语言（或者更具体地说，都是引用透明的）
c.与数学逻辑对应的语言。
这些定义基本上重叠。声明式编程与命令式和程序式编程形成对比。声明式编程是一种非必要的编程风格，其中程序在不明确列出必须执行的命令或步骤的情况下描述其预期结果。功能和逻辑编程语言的特点是声明式编程风格。在逻辑编程语言中，程序由逻辑语句组成，程序通过搜索语句的证明来执行。
在纯粹的函数式语言中，比如Haskell，所有的函数都没有副作用，而状态变化只是表现为转换状态的函数，状态被明确表示为程序中的第一类对象。尽管纯粹的功能语言不是必需的，但它们通常提供一种功能描述作为一系列步骤的功能。其他函数式语言，如Lisp，OCaml和Erlang支持程序和函数式编程的混合。
一些逻辑编程语言（如Prolog）和数据库查询语言（如SQL）虽然原则上是声明性的，但也支持程序式编程风格。
编程
声明性编程是一个总括性术语，包括许多更为人熟知的编程范例[1] 。
约束编程
约束编程以指定目标解决方案属性的约束形式表示变量之间的关系。通过给每个变量赋予一个值来解决这组约束，以便解决方案与约束的最大数目一致。约束规划经常补充其他范式：功能性，逻辑性甚至是命令式编程。
特定于域的语言
众所周知的声明性域特定语言（DSL）的示例包括yacc解析器生成器输入语言，QML，Make构建规范语言，Puppet的配置管理语言，正则表达式和SQL的子集（例如，SELECT查询）。 DSL具有非常有用的优点，但不一定需要Turing-complete，这使得语言更容易纯粹是声明性的。
许多标记语言(如HTML，MXML，XAML，XSLT或其他用户界面标记语言)通常都是声明式的。例如，HTML仅描述网页上应显示的内容 - 它既不指定呈现页面的控制流，也不指定页面与用户可能的交互。
截至2013年，一些软件系统将传统的用户界面标记语言（例如HTML）与声明性标记相结合，声明性标记定义了后端服务器系统应该做什么（但不是如何）以支持声明的接口。这种系统通常使用特定于域的XML名称空间，可能包括SQL数据库语法的抽象或使用表示状态传输（REST）和SOAP对Web服务的参数化调用。
混合语言
例如，Makefiles以声明方式指定了依赖关系，但也包括一个必要的行动列表。同样，yacc声明式地指定了一个上下文无关语法，但是包含来自宿主语言的代码片断，这通常是必要的（比如C）。
逻辑编程
逻辑编程语言，如Prolog状态和查询关系。回答这些查询的具体细节取决于实现及其定理证明，但通常采取某种形式的统一。像函数式编程一样，许多逻辑编程语言都允许有副作用，因此不是严格声明式的。
建模
物理系统的模型或数学表示可以在声明性的计算机代码中实现。该代码包含许多描述（“声明”）行为关系的等式，而不是强制性的任务。当一个模型用这种形式表达时，计算机能够执行代数操作来最好地制定解决方案算法。数学因果关系通常强加于物理系统的边界，而系统本身的行为描述则是声明性的或非因果性的。声明式建模语言和环境包括Analytica，Modelica和Simile。
参考资料

    [1]  NEMO:一种声明式网络编程与业务定制语言．万方 [引用日期2018-06-30]

词条目录

        百科名片
        定义
        编程
        约束编程
        混合语言
        逻辑编程
        建模
        TA说
]]
[[
https://baike.baidu.com/item/%E5%A3%B0%E6%98%8E%E5%BC%8F%E7%BC%96%E7%A8%8B/9939512

目录
声明式编程

    科普中国 | 本词条由“科普中国”科学百科词条编写与应用工作项目审核
    审阅专家吴晨涛

声明式编程（英语：Declarative programming）是一种编程范式，与命令式编程相对立。它描述目标的性质，让计算机明白目标，而非流程。声明式编程不用告诉计算机问题领域，从而避免随之而来的副作用。而命令式编程则需要用算法来明确的指出每一步该怎么做。

声明式编程通常被看做是形式逻辑的理论，把计算看做推导。声明式编程因大幅简化了并行计算的编写难度，自2009年起备受关注。

声明式语言包包括数据库查询语言（SQL，XQuery），正则表达式，逻辑编程，函数式编程和组态管理系统。

声明式编程透过函数、推论规则或项重写（term-rewriting）规则，来描述变量之间的关系。它的语言运行器（编译器或解释器）采用了一个固定的算法，以从这些关系产生结果。

声明式编程语言通常用作解决人工智能和约束满足问题。

    中文名
    声明式编程
    外文名
    Declarative programming
    类别
    编程形式
    作用
    解决人工智能和约束满足问题

快速
导航

    子编程范式
    参见

定义
声明式编程通常被定义为除命令式以外的编程范式。同时存在一些其他的定义，这些定义不是简单的将声明式编程和命令式编程做对比，例如：

    声明式编程是告诉计算机需要计算“什么”而不是“如何”去计算
    任何没有副作用的编程语言，或者更确切一点，任何引用透明的编程语言
    任何有严格计算逻辑的编程语言

这些定义有一些是重合的。
子编程范式
声明式编程是一个大的概念，其下包含一些有名的子编程范式。
约束式编程
在约束式编程中，变量之间的关系是在约束中说明的，定义了问题的解的范围。这些约束然后被应用程序来求解，以使得每个变量获得一个值，并让最多的约束得到满足。
约束式编程经常被用作函数式编程、逻辑编程甚至命令式编程的补充。
领域专属语言
一些著名的声明式领域专属语言（DSLs）包括yacc语法分析器，编译说明语言Make，Puppet管理配置语言，正则表达式和SQL的一些子集（例如Select queries等）。DSLs有时非常有用，并且不需要是图灵完全的，这往往让其很容易以一种纯声明式的方式来表达。
很多文本标记语言例如HTML、MXML、XAML和XSLT往往是声明式的[1] 。
函数式编程
函数式编程，特别是纯函数式编程，尝试最小化状态带来的副作用，因此被认为是声明式的。大多数函数式编程语言，例如Scheme、Clojure、Haskell、OCaml、Standard ML和Unlambda，允许副作用的存在。
逻辑式编程
逻辑式编程语言如Prolog声明关系并且对关系进行提问。同函数式编程一样，许多逻辑编程语言允许副作用的存在。
参见

    （对立的）命令式编程
    函数式编程和逻辑编程

参考资料

    [1]  李凤凯, 张亚丽, 夏寅贲. NEMO:一种声明式网络编程与业务定制语言[J]. 信息通信技术, 2016(4):65-74.

词条目录

        百科名片
        定义
        子编程范式
        约束式编程
        领域专属语言
        函数式编程
        逻辑式编程
        参见
        TA说
]]
[[
https://baike.baidu.com/item/Puppet

目录
puppet

puppet是一种Linux、Unix、windows平台的集中配置管理系统，使用自有的puppet描述语言，可管理配置文件、用户、cron任务、软件包、系统服务等。puppet把这些系统实体称之为资源，puppet的设计目标是简化对这些资源的管理以及妥善处理资源间的依赖关系。

puppet采用C/S星状的结构，所有的客户端和一个或几个服务器交互。每个客户端周期的（默认半个小时）向服务器发送请求，获得其最新的配置信息，保证和该配置信息同步。每个puppet客户端每半小时(可以设置)连接一次服务器端, 下载最新的配置文件,并且严格按照配置文件来配置客户端. 配置完成以后,puppet客户端可以反馈给服务器端一个消息. 如果出错,也会给服务器端反馈一个消息.

    外文名
    puppet
    性质
    集中配置管理系统
    特点
    使用自有的puppet描述语言
    设计目标
    简化对这些资源的管理

快速
导航

    使用的稳定性
    细节和原理
    Facter变量
    工作方式流程
    修改系统配置
    资源之间关系
    语言资源
    版本

开发原因
系统管理员都喜欢自己写点小工具来让自己的工作完成的更快或者更好, 不管是在大企业管理大量的服务器还是只管理两三台机器. 但是很少人会把他们的工具发布出来. 也就是是说极少有工具能被重用,或者说很多工具就只能在所在的组织内部有用.拷贝给别的组织,他们也用不上. 也就是说,每个系统管理员,在一个新的公司,都会另起炉灶开发一套基于ssh,for循环的"系统"来帮助自己完成系统管理任务.
开发puppet是为了让系统管理员可以相互交流和共享成熟的工具,避免重复的劳动.通过以下两个特性来实现这一目标:
提供一个简洁的但是强大的框架来完成系统管理任务
系统管理任务可以描述成puppet语言,因此可以相互分享代码,就像分享其他语言的代码一样,比如python, c等
因此,作为系统管理员的你可以更快的完成工作,因为你可以用puppet来处理所有的管理细节. 甚至你还可以下载其他管理员的puppet代码来让你的工作完成的更快.
使用的稳定性
puppet与其他手工操作工具有一个最大的区别就是 puppet的配置具有稳定性,因此你可以多次执行puppet, 一旦你更新了你的配置文件,puppet就会根据配置文件来更改你的机器配置,通常每30分钟检查一次. puppet会让你的系统状态同配置文件所要求的状态保持一致. 比如你配置文件里面要求ssh服务必须开启. 假如不小心ssh服务被关闭了,那么下一次执行puppet的时候,puppet会发现这个异常,然后会开启 ssh 服务. 以使系统状态和配置文件保持一致.puppet就象一个魔术师,会让你的混乱的系统收敛到puppet配置文件所想要的状态.
可以使用puppet管理服务器的整个生命周期,从初始化到退役.不同于传统的例如sun的Jumpstart或者redhat的Kickstart, puppet可以长年让服务器保持最新状态.只要一开始就正确的配置他们,然后再也不用去管他们.通常puppet用户只需要给机器安装好puppet并让他们运行,然后剩余的工作都由puppet来完成.
细节和原理
puppet的目的是让你只集中于你要管理的目标,而忽略实现的细节,例如命令名,参数或者文件格式. puppet把系统里面的用户,软件包,服务 看作是"资源", puppet的作用就是管理这些资源以及资源之间的相互联系.
底层支撑工具 Providers,puppet有很多的资源类型,例如文件,用户,软件包,服务, 不同的操作系统上对资源的管理命令是不一样的,例如debian下面用apt-get安装软件,redhat下面用yum安装软件. 因此puppet 对同一资源的管理可以有多个实现,配置资源的时候,可以明确的指定用什么provider. 例如在redhat上配置一个package资源的时候,可以指定provider是yum.
Facter变量
在puppet客户端分析代码的时候,会把从facter传送过来的对应的值赋值给变量. 你可以单独手工执行facter这个命令,这个命令会打印出它所收集到的关于主机的信息,例如ip地址等等. facter把收集到值发送给puppet服务器端,服务器端就可以根据不同的条件来对不同的节点机器生成不同的puppet配置文件. 最重要的一个就是服务器的主机名.
工作方式流程
puppet既可以在单机上使用,也可以以c/s结构使用.在大规模使用puppet的情况下,通常使用c/s结构.在这种结构中puppet客户端只是指运行puppet的客户端,puppet服务器端是只运行puppetmaster的服务器.
puppet客户端首先会连接到puppet服务器端,并且通过facter工具把客户端的基本配置信息发送给服务器端. 服务器端通过分析客户端的主机名,通过node 定义,找到该主机的配置代码,然后编译配置代码,把编译好的配置代码发回客户端,客户端执行代码完成配置.并且把代码执行情况反馈给puppet服务器端.
修改系统配置
puppet 通过管理资源的方式来管理系统, 例如管理某个软件是否要安装,是安装最新的还是安装了就行. 管理某个服务是否开启, 管理某个文件的属性,内容等等. 所有的资源都有对应的几个属性可以设置. 通过设置属性的方式来管理资源. 有一种特殊的属性可以用在所有的资源上面,这种属性叫做 metaparams ( 元参数或者元属性).
资源之间关系
支持资源之间的关系配置是puppet的关键特性之一. 一个资源的变更可以对另一个资源产生一个动作.例如 /etc/apache.conf这个资源有改动,可以让/etc/init.d/apache 这个资源 reload一下.假如一个资源依赖另一个资源,那么puppet会优先配置被依赖的资源,因此如果你的配置文件没有准备好,对应的服务是不会先启动的.
语言资源
puppet的全部就是管理资源,因此puppet语言的焦点就是处理这些资源,下面是一个基本的管理单个资源的例子.
file {"/etc/hosts": owner = root, group = root, mode = 644}
上面的例子给出了定义一个资源所需要的所有组件,类型,名字和属性. 定义了一个 file 资源, 资源的title(标题)是 "/etc/hosts", 资源的属性里面设置了该文件属于哪个用户和组,以及文件的权限.
也可以在一个大括号里面定义多个资源,通过分号来区分.
避免重复配置
puppet的编译器会避免在不同的代码段里面管理同一个资源, 如果在不同的代码段对同一个资源进行配置,执行puppet的时候你会得到一个语法错误.puppet探测这种冲突的情况是通过判断资源类型和资源的title(标题); 如果两个资源有相同的资源类型和title; 那么就认为这两个资源是表示同一个资源.
类
你可以把多个相关的资源定义在一起,组成一个类.可以在其他的代码段include这个类.puppet还支持有限制的类的继承,作用就是在子类里面的属性可以覆盖父类里面的属性.
字符串
几乎所有的东西和符号在puppet里面都被看作是字符串,包括数字和布尔值. 但是如果你用引号把true和false引起来,他们会被当做字符串,例如你想赋值给某个资性"yes"的 字符串.
变量
puppet除facter变量外，也可以自定义变量，但不允许你在同一个类里面对一个变量进行两次赋值.
$myvar = value123
条件语句
Puppet支持常见的条件语句，使得你能根据不同的条件导入不同的资源定义。如if、case、另外puppet从版本0.24.6开始支持比较运算符。
数组
puppet 非常有限的支持数组这种类型,你可以创建数组,并且给他们赋值,但是你不能删除它们.数组用的最多的情况就是上面ssh例子里面,资源依赖哪种情况. 或者是一次管理多个相同类型的资源.例如:user { [bin, adm]: ensure => present }
函数
puppet提供一些有用的函数,例如template利用erb模板来生成文件内容,这样就可以根据不同主机的情况,生成不同的配置文件.例如配置squid的内存缓存大小,可以利用facter返回的内存值做一个简单的数学计算,然后写入到squid的配置文件,就是通过template来完成的. 另外一个函数include 可以读入另外的puppet配置文件或者类.这样可以把puppet的文件分割的更有规律.
节点
最后一个关于puppet语言的语法是节点定义"node", 节点定义很象类定义,也支持继承特性. 当一个节点(puppet客户端)连接到puppet服务器端,puppet解析器会查找这个节点的node代码片断,然后利用这个代码片断来生成该客户端的配置代码. puppet里面主机名来标明一个主机,因此主机名在puppet里面相当重要. 如果puppet找不到匹配该主机名的node定义,就会用默认的节点定义来配置该主机. 在node里面使用主机名,需要用单引号把主机名括起来.
node 'server1' { include nginx }
在上面的代码中,如果server1这个主机连接到puppet服务器,puppet服务器就会按照nginx的代码来配置这台服务器.
自定义资源
puppet里面有一个非常有用的语法结构,叫做define, 通过define可以把多个资源包装成一个资源,或者把一个资源包装成一个模型,便于使用.例如,在debian里面管理一个apache虚拟机非常简单,把一个虚拟主机的配置文件放到/etc/sites-available/里面,然后做一个符号链接到/etc/sites-enabled目录. 你可以为你每个虚拟主机复制同样的配置代码.
版本
puppet 有企业版和社区版，版本是2.6。
社区版是免费的，有些常用的功能。
企业版是收费的，支持vmware虚拟机的部署和审计功能。但如果10个节点以下是免费的。
2013年1月13日。

词条目录

        百科名片
        开发原因
        使用的稳定性
        细节和原理
        Facter变量
        工作方式流程
        修改系统配置
        资源之间关系
        语言资源
        类
        字符串
        变量
        条件语句
        数组
        函数
        节点
        自定义资源
        版本
        TA说
]]
[[
]]
[[


Digital Guide
IONOS

    24.02.20Web development

Declarative programming: When “what” is more important than “how”

Whether programming an app, IoT software or a computer game – developers have to make a fundamental decision before they write their first line of code: What programming language do they want to use? A variety of languages is available, but all of them can be assigned to two fundamental programming paradigms: declarative programming and imperative programming.
Contents

    What is declarative programming?
    Imperative vs declarative programming
    Declarative programming example
    Advantages and disadvantages of declarative programming languages

What is declarative programming?

There is no one specific definition of the paradigm, but all definitions agree on one thing: A characteristic feature of declarative programming languages is that they always describe the desired end result rather than outlining all the intermediate work steps. In declarative programming, the solution path to reach the goal is determined automatically. This works well, provided the specifications of the final state are clearly defined and an appropriate implementation procedure exists. If both of these conditions are met, declarative programming is very efficient.

Since declarative programming does not specifically describe the “how” but works at a very high level of abstraction, the programming paradigm also leaves room for optimization. If a better implementation procedure is developed, the integrated algorithm can identify and use it. This makes the paradigm futureproof. The procedure for how the result is to be achieved does not have to be set in stone when writing the code.

The best-known declarative programming languages are:

    Prolog
    Lisp
    Haskell
    Miranda
    Erlang
    SQL (in the broadest sense)

The different declarative programming languages can, in turn, be divided into two paradigms: functional programming languages and logic programming languages.

However, in practice, the boundaries are frequently blurred and elements of both imperative programming – with its sub-types procedural, modular, and structured programming – and declarative programming are used to solve problems.
Overview of the systematization of imperative and declarative programmingProgramming languages can be assigned to two fundamental programming paradigms, which in turn have their own programming styles.
Imperative vs declarative programming

The imperative programming paradigm (command-based paradigm) is the older of the two basic paradigms. Unlike in declarative programming, in this case, the developer specifies in the source code precisely what the computer should do, step by step, to achieve the result. The focus is on the “how” of the solution path. For example, this approach can be found in Java, Pascal, and C. By contrast, in declarative programming the “what” of the solution is described directly.

As an example, let’s apply the idea to furniture assembly: While imperative programming provides instructions for assembly, declarative programming provides a picture of the finished piece of furniture as a template.

Instead of leaving the “how” of implementation open with functions, in imperative programming there are variables, which are changed at runtime. This makes the code longer but also more understandable than the truncated and very abstract form of the declarative style.
Declarative programming example

One of the strengths of declarative programming is its ability to describe problems more briefly and succinctly than imperative languages.

If we want to output a list of first names, in PHP this can be described with just one line of code using declarative programming – as the example shows – while the imperative method requires five lines.

Imperative programming

$participantlist = [1 => 'Peter', 2 => 'Henry', 3 => 'Sarah'];
$firstnames= [];
foreach ($participantlist as $id => $name) {
    $firstnames[] = $name;
}

Declarative programming

$firstnames = array_values($participantlist);

Advantages and disadvantages of declarative programming languages

These days, the declarative programming style is used in a variety of cases, even if not in its purest form. However, the method is not suitable for all uses.

Declarative code is characterized by a high level of abstraction. This enables developers to represent complex programs in a compressed form. But the more sophisticated the application, the greater the danger that the code becomes so convoluted that it can only be read by the developer who originally wrote it. For companies that want to be able to maintain and develop applications without having to rely on a single person’s knowledge, this presents a challenge. External developers have to carefully read and work out the declarative code until they understand the structure and have solved any problems.

However, the level of abstraction in declarative programming also offers advantages. Because implementation is clearly delineated from the system using an algorithm, maintenance can be performed independently of application development. Interruptions of day-to-day operations are reduced to a minimum. At the same time, optimization is easier because the algorithm used allows new methods to be integrated. One disadvantage of algorithm use is that this kind of formulaic solution is often insufficiently equipped to deal with specific characteristics of individual applications.

Not so much a disadvantage as a challenge is the conceptual model of declarative programming. Thinking in terms of solution states contradicts natural human thought processes. People tend to think in terms of processes moving towards a goal rather than starting from a goal and working backward. This requires developers to rethink and accustom themselves to the concept, which can initially slow down problem-solving. However, once the new mindset has been learned, the declarative approach can capitalize on its strengths.

Another advantage of development starting from the description of the problem is that teams can outline solution models rapidly. Ultimately, specific programming of the implementation can take place later. The declarative style is thus well suited for prototyping in agile software development.
Advantages 	Disadvantages
Short, efficient code 	Sometimes hard to understand for external people
Can be implemented using methods not yet known at the time of programming 	Based on an unfamiliar conceptual model for people (solution state)
Easy optimization as implementation is controlled by an algorithm 	Hard to take characteristics of individual applications into account during programming
Maintenance possible independent of application development 	 

In practice, mixed forms of the paradigms are often used these days, with declarative programming languages being supplemented with imperative methods. However, this increases susceptibility to errors and can impair the legibility of the code.

    24.02.20Web development

]]
[[
https://www.benfrederickson.com/python-as-a-declarative-programming-language/


Ben Frederickson
Python as a Declarative Programming Language

If you look at the programming languages benchmarks game, Python is one of the slowest commonly used programming languages out there. Typical programs written in pure Python average around 40 times slower than the equivalent program written in C or C++.

Despite the performance penalty, Python is still probably the most popular language choice out there for doing Data Analysis and Machine Learning. Most of the recent Deep Learning frameworks target Python for development: TensorFlow, Theano, and Keras all use Python. Torch originally was written for Lua, which is substantially faster than Python when using LuaJIT - but Torch failed to gain traction until switching to Python with the release of PyTorch.

The reason for this is that the performance penalty in writing programs in Python isn’t as large as the programming language benchmarks game would suggest: Most of the best Python Data libraries have their core routines written as native extensions.

This all means that to get the most out of these libraries, you need to treat Python as a Declarative Language - and push as much control flow as possible down to a native layer, and just let the Python program describe what needs done.
Declarative Programming Languages

Declarative Programming Languages focus on on describing what should be computed - and avoid mentioning how that computation should be performed. In practice this means avoiding expressions of control flow: loops and conditional statements are removed and replaced with higher level constructs that describe the logic of what needs to be computed.

The usual example of a declarative programming language is SQL. It lets you define what data you want computed - and translates that efficiently onto the database schema. This lets you avoid having to specify details of how to execute the query, and instead lets the query optimizer figure out the best index and query plan on a case by case basis.

Python isn’t a pure Declarative Language - but the same flexibility that contributes to its sluggish speed can be be leveraged to create Domain Specific API’s that use the same principles. I thought it would be kind of interesting to look at a couple specific examples of how this plays out.
NumPy

The design of NumPy has a couple neat declarative programming features, that lead to code that is not only cleaner and easier to understand - but also substantially faster.

A simple example of this might be to apply TF-IDF weighting to a sparse matrix. I originally needed to do this in order to add some basic nearest neighbour recommendation code as a baseline for my implicit recommendation library, and I thought it would provide a good example of what I’m talking about here.

In an imperative style, TF-IDF weighting on a sparse matrix can be written like:

def tfidf_imperative(m):
    # count up unique occurrences of each column of the sparse matrix
    X = coo_matrix(m)
    df = bincount(X.col)

    # calculate inverse-document-frequency = log(N/df) 
    N = float(X.shape[0])    
    idf = zeros(X.shape[1])
    for i in range(X.shape[1]):
        idf[i] = log(N / (1.0 + df[i]))

    # adjust data by TF-IDF weighting
    X.data = X.data.copy()
    for i in range(X.nnz):
        X.data[i] = sqrt(X.data[i]) * idf[X.col[i]]
   
    return X

There are 2 different for loops in that code - and each of which can be replaced by different NumPy language constructs.

The first for loop calculates the IDF itself. Numpy lets you do almost all operations on arrays of values as well as on single values and its much faster to use the vectorized form: idf = log(N / (1.0 + bincount(X.col))).

This tells NumPy to loop over the array returned from the bincount(X.col) function, and create a new array with the IDF value transformed appropriately. In effect we’re telling NumPy what result we want and letting it figure out how to calculate it best itself.

The final TF-IDF weighting can be done in a similar fashion using NumPy’s array indexing feature. This feature lets you use one array as an index into another array. Going idf[X.col] looks up each column value from X in IDF and returns an array with the IDF weight for that column.

Putting it all together leads to code like:

def tfidf_declarative(m):
    X = coo_matrix(m)

    # calculate IDF
    N = float(X.shape[0])
    idf = log(N / (1 + bincount(X.col)))

    # apply TF-IDF adjustment
    X.data = sqrt(X.data) * idf[X.col]
    return X

Not only is the declarative version shorter and more readable, its also substantially faster. By removing the for loops, the iteration can happen in vectorized C calls and makes this code run 75 times faster than the imperative version on my laptop. By avoiding writing any loops, we’ve declared the operations that need to happen and let the NumPy translate that to control flow.
TensorFlow

One frequently asked question is why Deep Learning frameworks like TensorFlow are written for Python instead of a faster language like C++.

The answer is that for the most part these frameworks are written in a language like C++, but provide a Python API to make it convenient to call. The Python code only describes the computations that need to be performed, all the real work happens in the library in either C++ or CUDA calls on the GPU.

Take a look at this simple function that uses TensorFlow to do Linear Regression:

def linear_regression(train_X, train_Y, learn_rate=0.005):
    # define placeholders for input data
    X, Y = tf.placeholder("float"), tf.placeholder("float")

    # define the variables we're learning
    slope, intercept = tf.Variable(0.0), tf.Variable(0.0)

    # learn the slope/intercept on a ordinary least squares loss function
    loss_function = (Y - (X * slope + intercept)) ** 2

    # find the parameters slope/intercept using a basic GD optimizer
    train = tf.train.GradientDescentOptimizer(learn_rate).minimize(loss_function)

    with tf.Session() as sess:
        tf.global_variables_initializer().run()

        # Train the model
        for x in range(100):
            sess.run(train, feed_dict={X: train_X, Y: train_Y})

        return sess.run(slope), sess.run(intercept)

In terms of line count, most of the function is in defining the variables to optimize, the linear model that we’re trying to learn and the loss function and optimization method to learn that function. None of these calls do any work though - all they do is declare a computation graph of what should be done.

Basically everything here happens in the sess.run call on the training function. This call takes the computation graph defined in the train variable binds the placeholder variables X and Y to the training data and runs the graph to learn the regression coefficients.
Python as Super Glue

Python is sort of like glue - it works well for binding different libraries together, but if you try to build a large fast program out of it you end up with a sticky mess that’s difficult to quickly move through.

The reason it has been so successful with Data Processing and Machine Learning tasks is that many of the libraries have adopted API’s where you declare the operations you want to perform, and the library executes those declarations in an efficient manner in a lower level language. This leads to the best of both worlds, code that’s easy to write in Python that runs as fast as code written in C++.

Using an imperative style means that you spend too much time wading through the glue, but declaring what operations you want leads to code that’s efficient and clean.

The side effect of this is that in order to be a great Python programmer, you have to learn to program in a lower level language too. All of the most popular Python data libraries have native extensions: TensorFlow, scikit-learn, NumPy, Pandas, SciPy, spaCY etc all have significant portions of their code written in a native language. If you are comfortable just using these libraries its enough to be just a good Python programmer; however, if you want to be the type of programmer that can produce libraries like these you really should be learning something like C++ or Cython too.

Published on 28 February 2017
]]
]]]
]]]]
