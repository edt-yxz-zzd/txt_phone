
e others/数学/编程/差量编程-可逆计算-声明式语言.txt

[[[
范畴论 教科书
可计算性
e others/book/category-theory.txt
e others/book/computability.txt
  view /mnt/m_external_sd/000edt/0my_files/book/math/category\ theory/
  view /mnt/m_external_sd/000edt/0my_files/book/math/computability/

[[
ls /mnt/m_external_sd/000edt/0my_files/book/math/category\ theory/
'Abstract and concrete categories--the joy of cats(1990ed+2004update-web)(Adamek).pdf'
'Axiomatic Method and Category Theory (2014)(Andrei Rodin).pdf'
'Basic Category Theory (2014)(Leinster).pdf'
'Categorical Logic and Type Theory (1999)(Bart Jacobs).djvu'
'Categories for the Working Mathematician (2ed)(1998)(Mac Lane).pdf'
'Category Theory (2ed)(2010)(Steve Awodey).pdf'
'Category Theory for Computing Science (1995-rev20200423)(Michael Barr).pdf'
'Category Theory for Programmers (20181021)(v1.0.0-0-g41e0fc3)(Milewski).pdf'
'Category Theory for Programmers (20190812)(v1.3.0-0-g6bb0bc0)(Milewski).pdf'
'Category Theory for Scientists (dynamic-20130514).pdf'
'Category Theory for Scientists (static-20130205).pdf'
'Category Theory in Context (2014)(Emily).pdf'
'Conceptual Mathematics--A First Introduction to Categories (2ed)(2009)(Lawvere).pdf'
'Introduction to CATEGORY THEORY and CATEGORICAL LOGIC (Thomas Streicher).pdf'
'Introduction to Categories and Categorical Logic (Samson Abramsky)(2006-2011).pdf'
'Introduction to Categories and Categorical Logic (Samson Abramsky).pdf'
'Topoi--The Categorial Analysis of Logic (1983)(Robert Goldblatt).pdf'
'范畴论(2006)(贺伟)(书签+去水印).pdf'
]]
[[
ls /mnt/m_external_sd/000edt/0my_files/book/math/computability/
'Higher-Order Computability (2015)(Longley).pdf'
'Hilbert Tenth Problem--Intro to Logic,Number Theory,Computability (2019)(Murty).pdf'
'The Foundations of Computability Theory (2ed)(2020)(Borut).pdf'
'The Incomputable--Journeys Beyond the Turing Barrier (2017)(Cooper).pdf'
]]
]]]
[[[[
e others/数学/编程/差量编程-可逆计算-声明式语言.txt
[[
类型/接口 是 公开的稳定的部分
数值/实现 是 细节的特定于平台的特定于版本的多变的不可用作跨模块推导的部分(但可用于 推导/匹配 声明的类型约束)

对称卷积?:
  输入输出的近期历史/完整历史？:
    y[n] = f(y[n-1]..y[n-p],x[n-1]..x[n-q]; x[n])
    可逆:x[n] = g(y[n-1]..y[n-p],x[n-1]..x[n-q]; y[n])

流-树
  码流->码流
    编码/解码:bytes<->str
    语境无关-词法分析:str->[token]
    宏展开
    ==
    基础有限状态码 byte/char 单值 #可对 整值 归类，也可直接将值当成 种类
    复合结构状态码 token = 种类+属性表
    ==
    地址，多层次地址
  码流->{(中途状态,半切树/构造中途的不完整的树)}
    语境无关-句法分析
  树->树
    ==
    节点路径
    面向切面编程，切入点 需要收集 所有信息
      而调用函数本身功能并不需要太多信息
      ==>>应用层不可拆包的信息封装传递##穿透性环境感知+封装隔离保证
        应用:i->o
        切入点:
          (g, g->IO())
          (g, g->i->IO())
          (g, g->i->o->IO())
          (g, g->i->mid->o->IO())
          g=全局整体状态+当前节点路径
      单子Monad！
        既封装 运算，也封装 语境context!!!
          StateMonad
          来自 https://zhuanlan.zhihu.com/p/65449477 写给小白的Monad指北
  树->码流 #序列化/扁平化

]]
[[

可逆:
  * 原子性可逆
  * 组合 <-> 拆分
    文本拼凑 <-> 正则表达式 不越界
    组合 时：冗余信息 校验，缺失信息 推导
    元素次序？
    元素多路变换，可逆性识别
  ##
  高层操作 映射到 底层操作，语义丢失
    高层：删除 过滤器 指定的行
      动机/原由 驱动
    底层：删除 第几行
      直接地址驱动
    高层操作不变，当目标表格改变时，底层操作发生改变，即 底层操作序列 依赖于输入，不具可分离性
      补丁 完全 锚定 唯一输入
      可移植差量:
        d=A'-A=B'-B
        B'=B+(A'-A)
  ===
  绝对差量vs相对差量vs幂等差量
  绝对差量
    (+=1)
  相对差量
    (*=1.5)
  幂等差量
    (+=1 until >=4)#允许的变换序列+终态判定条件
  ===
  f(x)=y
  f(x+dx)=y+dy
  Df(x,dx)=dy
  可移植差量？
  ===
  中间节点-节省算力
    人为？自动化搜索等同别名(引用透明-反向整合)？
    存储用紧凑表达形式(抽象概念，强调等同)vs动态修改快速访问用带冗余展开表达形式(具象构造树，强调等价)
  ===
  输入相容与否
    输出与输入相容与否:检查 输入相容性 乃至 算法正确性
  ===
  输入分量-正交vs相互约束带冗余-覆盖vs狭义抽取
    狭义视图 #不可逆 用作 构造器
  ===
  同畴映射？畴内映射？endofunction
  同象映射？象内映射？endofunction
    允许哪些变换作用于输入？==>>解空间
      棋盘状态行棋规则
      命题推导证明
      term rewrite
    单个输出满足哪些约束？==>>可行解
      枚举/搜索
      离散枚举、正交随机构造、连续梯度
    输出在所有可行解中是什么地位？==>>稳定性
      最小化某个特征
    ===同畴？整体状态分解为多个子分量，单一同畴映射分解为多个多中间状态分量到单中间状态分量的触发动作函数，wanted/wanting消息洪流自动填充
    =畴domain #类/种类
  ===
  [i->(o1,o2)] <==> [i->o1][i->o2]
  [(i1|i2)->o] <==> [i1->o][i2->o]
  但[(i1,i2)->(o1|o2)]无法拆分
  ===
  外延 内涵
  当将对象进行编码，通常是对内涵的编码
    很难判断函数是否外延等价，更别说针对外延编码
  高阶函数:将 某些输入数据 解码 用作 函数
    编码~内涵
  ===
]]

[[[
声明式语言
  定义实体/命名  +  关系描述
    事实+规则？fact+rule
  关系描述 = 谓词-连词 + 名词?
    但考虑一下cmake，输入相同，也可以有很多选项
      额外参数/带外信息/注解
        一份数据 如果带有 额外信息，则意味着 有多种用途
        多用途/多切面 数据
          标注 参数/选项 的 目的/用途/应用
  关系描述 = 谓词-连词 + 修饰谓词的副词 + 名词 + 修饰名词的形容词
  ===
  直接描述 结果状态/输出
[[
]]
[[
]]
[[
]]
[[
xxxxxx
]]
[[[
[[
https://zhuanlan.zhihu.com/p/19908708
尹璋琦
科研等 2 个话题下的优秀答主
从可逆经典计算到量子计算
7 年前 · 来自专栏 量子世界

最近在从新读有关可逆经典计算的文献，学到一些有趣的结果，在这里记录一下。

我们知道经典逻辑门很多都是不可逆的，比如说与门，或门。后来Toffoli和Fredkin等人发现，实际上经典物理也允许可逆的逻辑门存在。比方说，Toffoli定义了一个可逆的Toffoli逻辑门，包含三个输入，三个输出。如果我们只用到其中的某个输出，那么可以构造出逻辑上不可逆的与非门，用这个逻辑门完全可以构造出任意的经典逻辑电路出来。换句话说，用Toffoli门就可以构造出可逆的经典计算电路。再完成计算之后，再把逻辑门按照逆序操作一次，我们会发现整个计算过程并没有消耗能量。

量子计算兴起之后，我们发现量子系统演化的幺正性天然保证了计算的可逆性。人们也在寻找什么是通用的量子逻辑门。最早确认的一组是两比特的控制非门和两个正交的单比特逻辑门。有没有可能找到更少的通用量子逻辑门呢？后来Yaoyun Shi发现只用Toffoli门加上单比特的Hadamard 门就可以构造出任意的量子电路。

这个结论有可以用下面这句话概括：量子计算超越经典计算的地方就在于多了单比特的Hadamard门，或者说所有的量子计算算法不过就是经典计算机加上Hadamard门。
编辑于 2015-03-18 17:24

]]
[[
https://zhuanlan.zhihu.com/p/23811020
使用Paxos前的八大问题
杨东东
OTS，更好的分布式NoSQL！终局视野，长期主义！
使用Paxos前的八大问题
5 年前

相信不少做存储或者数据库的人已经被Paxos轰炸过过一轮，我也不能免俗，最近也尽可能的翻了一些Paxos的文章，看了这些文章后，我个人感觉最好的理解方式是将Paxos要解决的问题具体化，细节化，然后，我想任何一个有着丰富经验的同学都能不依赖Paxos的任何资料很好的回答这些问题，这些答案的形式化综合起来就应该是网络上的各种Paxos解释。我相信问题导向逐步推导的方式比冲上去学习Paxos文章里面的流程有趣一些，同时，没准还可以发现一个更适合自己业务的改进。

问题一：Paxos[2]解决什么问题？

在保证一致性的前提下，提高系统的可用性。系统中破坏可用性的场景包括，机器down机（硬盘等各种硬件损坏类比），机器间网络丢包、高延时。解决这些问题的根本思路是多副本，这样一个机器down其他副本还可以使用。多副本早已被大家广泛使用，之前最主要的思路是主备机制，又叫做primary-second，或者master-slave，核心思路是主承担所有的操作，并定期异步将主上面数据的变化同步到备。在主备系统运行过程中，如果备出问题，服务不受影响；如果主出问题，就切换到备，因为主总是比备多一点数据，所以这个过程中可能丢数据。丢多少数据呢？这取决于主隔多少时间能将最新的信息同步到备，如果主每隔1小时就能保证1小时前的数据完全到备，那么最多丢一个小时。那么，丢数据的量能缩短吗？5分钟？1秒钟？

对于一个繁忙的数据库系统，1秒钟的数据丢失可能也是灾难，那么最小粒度是什么？就是per request，即主上面每一个变化备都能同步感受到，那么主down掉的时候，备能无损的接管服务，这就是MySQL 主备强同步的思路。但是，如果每个request都要备参与，就意味着这个系统如果备挂了就不可服务了，这也是线上恐怕很少有人选择MySQL主备强同步的理由，怎么办？多加几个备来降低备不可用对系统的影响。

多加几个备之后，就带了两个问题，

1. 这些主备之间数据一致性怎么解决？Paxos是一种思路，即多数派同意的就是正确的

2. 那如果主挂了呢，这里有两种选择，一种是任何人在任何时候都可以是主，这时候就没有主备之分了，这是basic paxos[2]的思路；另一种思路是，主挂了就让某一个备成为主，系统可以继续服务，这是viewstamped replication[3]、Raft[4]、Zab[5]（广义上可以算Paxos）的思路，在multi-paxos[6]里面也提到了使用leader减少prepare message，leader切换条件更灵活，也可以归类为这个序列。

上面两个问题就是Paxos要解决的核心问题，即Safety（数据是一致的）和Liveness（系统总是能继续前进）。

问题二：状态机(Replication State Machine, RSM)和一致性有何关系

状态机有一个很好的特性：任何初始状态一样的状态机，如果执行的命令序列一样，则最终达到的状态也一样。而存在多个参与者的系统的一致性可以理解为，系统多数成员就某一系列决议得到了相同的判断结果，使用状态机来描述就是，如果在某一个时刻系统不再接受外部输入，则系统中存在多个参与者具有完全相同的状态机。上面两点结合在一起，就得到系统参与者保持一致的关键是，起始状态完全一致，执行命令序列完全一致，那么系统的行为就是可以重复的。这跟单机数据库系统可以类比，数据库重做日志就等于命令序列，数据库数据存储就等于状态机，唯一不同的是单机数据库日志序列化lock一下就可以做，那么多个参与者之间如何让日志序列化呢？这就是Paxos等一致性协议致力解决的具体问题，即如果状态机状态的改变是由命令1...N组成的，那么Paxos需要保证对任何一个1<=k<=N，命令序列的内容被系统中绝大部分的参与者同意。这个k可以称之为log position，log index，不同文章叫法不同。这里我们对上面问题一的一致性问题进行了具体化，只要保证了大部分参与者执行的命令序列是一样的，系统就是一致的。再具体化一步，保证命令序列中每个序号对应的命令是一样的，就能保证命令序列是一样的。Paxos的责任就是保证：在一个命令序列中，同一个序号下面对应的命令内容是一样的。[7]的描述还是比较清晰的。

问题三：Paxos如何保证多参与者同一个序号对应同样的命令内容

这是各类Paxos算法的核心，不过我认为在准备动手写代码前这是最不重要的一部分，因为除了最开始的paxos文章说的比较模糊，后面出来的都把这一块描述的异常清晰，甚至各种优化都帮着想好了。这里面理解下面几点就行，

    目标：让第k个命令序号执行x命令（x比如是inc）

    动作：给所有人发请求，<no, k, x>，no每次都要涨，这个好理解，否则一个网络上漂了半天的包被服务器收到怎么办？

    结果：如果大部分参与者都同意，就确定了<k, add>的对应关系；否则，每个Paxos算法都有一系列的规则来让系统一定能达成一个共同的决议，具体参考每个算法；


问题四：leader选还是不选

网上见到有人争论basic paxos不用选leader，对运维更友好，对网络抖动容忍度高等等，这个更像是一个工程实现问题，而不是理论问题。在一个多参与者的系统里面，如果每个人都提议，那么显然冲突的概率是很大的，冲突了就要重新开始新一轮提议，这会导致很低效，就好像高速路上8车道变成了1车道，这时候谁先走就是一个问题，如果没有警察叔叔，必定乱成一锅粥，在一个高压力的系统中问题类似。选了一个leader之后，leader知道没人跟自己抢，就可以省不少事，事情省了，系统也简单了，这就是Raft的思路。同时，如果有了leader，批量确认命令序列也成了可能（否则同一个paxos group冲突肯定高的吓人，有了警察叔叔每个车道可以一次放行20辆，没有警察叔叔一次放20辆可能很快就会因为事故全部堵死），这就是multi-paxos，即一次确认多个命令。选leader不是没有弊端，如果leader挂了，这时候系统是不能服务的，必须等新的leader选出来，这个一般几百毫秒搞定。那么，leader挂的时候如何降低对服务的影响？就是将paxos group做的精细一点，一个leader挂了，只影响这个paxos group，其余正常服务。如果碰到leader节点网络抖动，也可以迅速切换，减小影响。整体来看，选leader是较好的做法，人类社会不也需要leader嘛。

问题五：机器down掉后，新加入的机器是否能立刻服务

这点取决于状态机如何维护，是整个系统作为一个状态机还是每个参与者都是一个独立的状态机。如果整个系统被当做一个独立的状态机，那么任何机器加入进来都可以立刻服务，因为系统的状态是完整的，这也是basic paxos能达到的效果。如果系统中每个参与者都被当做一个独立的状态机，那么任何新机器加入进来必须先从其他机器获得一个过去的状态（snapshot），类似数据库备份里面的数据文件，然后执行这个状态之后的命令，类似执行数据库重做日志，等到状态已经追赶上系统中的多数参与者，就可以提供服务，这是Raft的效果。从描述看，Raft似乎弱了点，但是本质上两个是类似的，因为basic paxos将整个系统视为状态机增加了复杂性，且在参与者连续down的场景中，一样不能很好的解决，也需要尽快让新机器追状态，以达到每个命令都有多replica。

问题六：paxos group如何随着新节点加入而改变

这个问题被称为view change，就是说参与者变多了，比如1 2 3变成1 2 3 4 5，或者参与者要换一批，比如 1 2 3换成4 5 6，这个问题Raft处理的最好，简洁明了，说简单点就是在新旧config交叠的时候，leader必须得到新旧两个group的认可，这就避免了多leader脑裂的问题。viewstamped replication第一版在变配的时候要停机，revised解决了这个问题；paxos make simple里面的N+alpha方案不太好懂，按照文中的描述，在极端情况下有正确性问题（练习题[10]里面最后的题目，当然，工程实现上可以绕，这本来就是一个低频动作）

问题七：不同方案哪个资源会首先成为瓶颈

在leader方案中，最容易成为瓶颈的是网络，因为从方案设计上使用的就不均衡，leader接受请求后转给其他参与者，出口带宽会承压，这时候可以选择chain forward，让其余参与者也承担网络流量。磁盘方面还好，毕竟都上paxos了，PCIe接口NVME SSD盘应该少不了，秒几十万写不是事，还有像Oceanbase[11]讲的，log落盘就返回的话磁盘更不是事。现在CPU也越来越强大，配合上各类专用处理器，牛的不行。

问题八：读的时候怎么保证一致性

这个问题在各个Paxos文章里面叙述的不太明显，其实是一个很难的工程问题。basic paxos里面没有专门提，我揣摩意思就是读跟写一样，走完整的多参与者决策流程，这个肯定能读到一致的数据，但是性能恐怕不会好。在leader选举的方案里面，也不是件简单的事情。直接读leader的话，因为leader可能是过期的，那么可能导致读到的数据是过期的，这时候又要给leader加上lease机制，而这个机制更进一步限制了leader挂时候的可用性恢复。这里或许提供两类接口是一个明智的选择，比如

1. 非一致读：可能读到过期数据，这时候读任何一个参与者都行，不过也不能太随便，client可以提要求，该参与者与leader的距离不能超过一个阈值或者已经apply到RSM的序列号至少得大于client曾经写过的命令序列号。

2. 一致读：只能读leader，或者为了负载均衡，leader选一个状态一致的参与者也行。

以上是近来研究paxos的一点记录，算是一个总结，欢迎交流微信teaworldvc20。

    封面图片来自：http://www.cs.rutgers.edu/~pxk/rutgers/notes/clocks/images/clocks-lamport.png

    http://research.microsoft.com/en-us/um/people/lamport/pubs/lamport-paxos.pdf

    http://101.96.10.62/www.pmg.csail.mit.edu/papers/vr-revisited.pdf

    https://zh.scribd.com/document/323523128/raft-pdf

    http://www.tcs.hut.fi/Studies/T-79.5001/reports/2012-deSouzaMedeiros.pdf

    http://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf

    https://ramcloud.stanford.edu/~ongaro/userstudy/paxos.pdf

    https://ramcloud.stanford.edu/~ongaro/userstudy/raft.pdf

    https://ramcloud.stanford.edu/~ongaro/userstudy/paxossummary.pdf

    https://ramcloud.stanford.edu/~ongaro/userstudy/rubric.pdf

    https://www.zhihu.com/question/19841579/answer/131853733


发布于 2016-11-20 17:52

]]
[[
https://zhuanlan.zhihu.com/p/138132426
打个比方说 Paxos 的过程和正确性
欢歌
分布式存储、数据库
打个比方说 Paxos 的过程和正确性
2 年前

理解Paxos的关键不在于记住它的两个阶段，而在于理解它为啥是正确的。我在春节期间写过 Basic Paxos 的正确性推导过程：
欢歌：觉得Paxos是对的却不知为啥？探讨下Paxos背后的数学68 赞同 · 3 评论文章

但是推导过程中的大量公式对于大部分读者来说还是太枯燥了。五一假期陪小朋友们爬山时，偶然想到可以换个方式来描述，或许可以让更多人理解正确性的大致原理。但打比方更多是打开思路，它不是严格的推理。先说下本文的概要：

    用一个假想的江湖帮派(登山帮)在登台阶过程中审批内务的过程来类比 Paxos 的Phase1 和 Phase2

    用台阶层级比喻 Ballot Number间的优先级；
    投票者(长老)要给某级台阶上的请求投票，必须先站到那级台阶上；
    势利的长老们一旦站到在某个台阶上，就无视脚底下发生的事情，只看高处；
    长老会信守自己的有条件承诺；
    长老的爽约规则是公开透明的；
    只有在某一级台阶上获得三个以上长老的点赞，才算批准通过；

    用“学生们列队做操如何保证不冲突”的比方来类比 Paxos 的正确性推理

    假设每个学生都遵守规则；
    学生只要保证与站在自己前面且紧邻的学生的间距即可；
    学生无需保证与自己后面的学生的间距；
    学生无需保证与站在自己前面但是不相邻的学生的间距。

看了上面的比方，读者是不是觉得 paxos 的Acceptor 在vote 时只需要瞻前，不需要顾后了？而且还不需要瞻的特别前。因为站你眼跟前的那个学生，也在瞻他的前，你相信他不撒谎，就知道他前面的同学也不会跟自己冲突。
1. 打比方说说 Paxos 过程和规则

假设江湖上有个诡异的帮派叫做登山帮，为了保证大家不忘了祖上传下来的功夫，每天都举办一次在登山(有巨大的台阶)过程中投票批准弟子们的申请的活动。申请的内容可以多种多样，比如张三申请办结婚喜酒，李四想请假去泰国旅游等。注意登山帮每天最多只能批准一个申请，也可能一天下来一事无成(大家都登顶了，还是没有达成共识)。

具体来说，登山帮有5个长老，只有长老们拥有投票权，但是长老们年纪太大，自己不能爬台阶，而且相互之间不太沟通。登山帮规定如果一个申请想要被批准，必须在某一级台阶上被3个或以上长老的点赞(超过半数)。为了能让自己的申请被通过，登山帮弟子们练就了非凡本领，他们在爬到某一级台阶后，发出的每个请求都带着魔法，一个请求的魔法可以把一个长老从任意一个低级台阶拉到自己所在的台阶上(长老们都是势利的，一心向往高处走)。 由于每天只举行一次登山投票活动，而每天可能有很多帮派弟子都有申请需要提请批准，并且弟子和长老们都在运动中，且没有裁判，大家不会在某个时间点统一停下来判断是否已经批准了某个申请。为了防止出现多个申请都被批准的情况，登山帮制定了一套规则：只有在某一级台阶上成功完成邀约和点赞两个环节，才是被批准。
1.1 环境和规则

        登山的台阶很宽，并且像操场的跑道一样划了线，相当于每个人都有自己的登山道；大家通过传递消息(比如滚动纸条)通信，且消息只能在同级台阶上传递，不能跨台阶传递；消息可以是弟子们发的邀约、求赞请求，也可以是长老们的应邀/点赞消息；弟子们可以在任意一层台阶上停下来，发送邀约消息(不含待批准的申请)，只有在当前台阶上收到过半长老们的应邀消息，才算邀约成功；只有在当前台阶上的邀约成功后，才允许进入求赞阶段。求赞请求包含一个待批准的申请。如果一个求赞请求在某一级台阶上被过半的长老点赞，那么它里面的申请就被批准了(注意，批准的是申请，而不是求赞消息自身)。如果失败，弟子只有继续往上爬，再试。长老们看到某个更高级台阶上的邀约请求后，如果决定应邀，必须先借助邀约请求的魔法升到该级台阶上。但是他们不会考虑同级或者更低级台阶的邀约。长老们看到同级或者更高级台阶上的点赞请求后，必须先借助点赞请求的魔法到该级台阶上(或者已经是在同级台阶上)，然后才能点赞。但是他们不会考虑更低级台阶的点赞请求。消息可能丢失。

为了避免混淆，我们把名词先明确下。 与邀约请求对应的是应邀；与求赞请求对应的是点赞。

观察一些执行过程，我们能够发现一些规律：

    如果弟子张三在第 b 级台阶上邀约成功，那么一定有多数派个长老，被张三的邀约从某个低位置拉到了第b级台阶，然后才响应的。注意每个长老在响应时，都稳稳地站在第b级台阶上。如果张三在台阶b上求赞成功，那么一定有多数派个长老站在第b级台阶给他点赞。这些长老要么之前就在第 b 级台阶上(被某个邀约请求拉上来的)，要么被这个张三的求赞请求拉上了第 b 级台阶。每一级台阶上，最多只会出现一个求赞请求(OneValuePerBallot)；但是邀约请求则可以有多个（邀约请求并不带申请内容）。

1.2 FAQ

FAQ 1: 在邀约阶段，长老给张三发回的应邀消息包括什么内容？

应邀消息实际上包括两个方面，我们假设这个长老就是唐长老。

    有前提的点赞承诺(所以弟子们必须要有紧迫感):
        有条件的承诺：如果在收到你的求赞请求时，我还站在当前这级台阶上，那么我一定给你点赞。明示可能爽约：如果我遇到更高级别的任何请求，那么对不住啦，人往高处走。长老的最近一次点赞历史
        长老是否点赞过任何申请(Yes/No)；如果是Yes，需要给出最近一次点赞是在哪一级台阶，具体的申请内容(最近一次点赞史，可以用<b, v>表示)；如果唐长老点赞过多次，只需要发送他最近的一次点赞记录就可以(必然是点赞史中，台阶最高的那个)，无需保存所有历史。


FAQ 2: 如何决定一个求赞贴中到底包含哪个申请？
如果某个弟子(比如张三）在第b级台阶上邀约过程中，收到了三个长老(比如唐、宋、秦)的应邀消息，有两种情况：

    如果唐、宋、秦三个长老的点赞史都是空的，即都没有点赞过任何的申请，那么张三就把自己的申请作为投票请求的内容；如果部分长老曾经点赞过，比如是唐长老和宋长老。假设唐长老在 b1 级台阶点赞过申请 v1, 宋长老在 b2 级台阶点在过 v2，那么层级高的台阶胜。即：如果b1 > b2，那么就取 v1作为张三在求赞阶段的申请；否则就取v2。注意，不论取v1还是v2，这个申请都可能是别人的申请，而不是张三自己的。

FAQ 3: 长老们的行为听起来怪怪的，他们都是什么样的人？

长老们都是势利的，利用自己的投票权借魔法不断往上爬。

        长老们会响应更高级台阶的邀约，因为有利可图。长老们无视来自同级台阶的邀约，因为可能造成混乱且无利可图(所以在任意一级台阶上，最多只会有一个弟子邀约成功，后面的 OneValuePerBallot 即是这个含义)。长老们无视来自低级台阶的任何请求，因为无利可图。长老们会点赞来自更高级台阶的求赞请求，因为有利可图。长老们会点赞来自同级台阶的求赞请求，因为承诺过。

长老们同时是诚信、守承诺的，并且会把履约的前提说在明处。

        信守承诺：长老会给同级台阶的求赞消息点赞，这是因为之前做了带前提的点赞承诺，即使这个动作并不能帮自己往上爬。不会抵赖。他们会记住最近一次点赞是在在哪一级台阶做的，被点赞的申请的内容（否则就是抵赖了）。


FAQ 4 为什么章三在决定第b级台阶上的求赞请求中的申请时，不考虑更高级台阶在发生什么？

简单来说，那是高层台阶上操心的事。在任意一层，只需保证更低级台阶不跟自己冲突即可。
2. 打个比方说说正确性

基本执行规则讲完了，那么到底这个规则是不是正确的？

我们先说说正确性的含义。 正确就是: 一次登山过程最多只允许批准一个申请。细化下：

    大家忙了一天，啥也没批准，正确；只有一个申请 v，在某一级台阶(比如b)被批准了，正确；有一个申请 v，在多级台阶(比如在台阶b1, b2, b3)上，反复被批准了，正确。

对于长老们来说，一天下来啥也没批准并不要紧，如果在同一天让张三和李四的申请都被批准了，是不允许的。

2.1 正确性是怎么得来的？

    如何保证不同层级台阶上不会批准不同的申请？由于任意一级台阶上最多只会出现一个求赞消息，所以同一级台阶上不可能两个申请被点赞。如何保证不同层级台阶上不会批准不同的申请？ 一个可类比的思路：如果体育老师让班上小朋友们列一个纵队做广播体操，只要每个同学都保证自己与前面的同学之间的间距足够大(比如 1 臂距离)，是不是就可以保证所有同学们间都不会发生碰撞？而不需每个人回头看后面同学跟自己多远？类比小朋友们列队的保证，Paxos的做法是：任何一个弟子，在第b级台阶发送求赞消息<b, v>时，必须保证：长老们不可能在低于 b 的台阶上批准 v 以外的申请，但是不用保证更高级台阶上什么条件。这个实际上对应Paxos的形式化证明中的 SafeAt(b, v)。

SafeAt(b,v)的含义是：

    不可能在低于 b 的任何台阶上批准 v 以外的申请；承认和继承在低于 b 台阶上可能已经批准的申请：如果之前在某个 < b 的台阶上已经批准或者可能批准了某个申请 v1 ，那么 b 级台阶上的求赞请求中包含的申请一定是v1，即v1 和 v一定必须是同一个申请(回顾下点赞请求中申请的来源，可能来自点赞史，就是为了这点)。

注意，不可能在 < b 的台阶上批准其它申请，不代表禁止了所有的消息传递，也不禁止 < b的台阶上继续批准相同的申请 v。

SafeAt(b,v) 本质上是限制了一部分他人(更低级台阶)做产生冲突的事，并没有成就自己。它没有保证 v 一定能在台阶 b 上被批准，即不保证ChosenAt(b, v)。

SafeAt(b,v)是如何保证的？我们再次类比小朋友列队做广播体操：

    如果东东同学排在第5位，那么东东只要保证不跟第4位同学的间距就好了，不需要考虑自己会不会跟排在 1 至 3 位的同学的冲突。因为站在第4位的同学，已经保证了跟第 3 位的同学的间距；第 3 位同学保证了跟第 2 位同学的间距。依此类推，虽然东东只保证了不跟第4的同学冲突，但是实际上他不可能跟任何一个同学冲突。

    假设张三在b级台阶上收到了3个应邀消息，且消息中带的点赞史非空。假定所有点赞史中，台阶最高的是c (c < b)，对应的申请是v1，用<c, v1>表示。现在，我们把 b级以下的台阶分为三段来讨论： [0, c), c 和 [c+1, b-1]，说明这三段都不可能选定v1以外的值。[c+1, b-1]这段台阶，已经被三个长老刚刚越过了，三个长老在这段台阶都没有点赞，将来也不会。所以，这段台阶不会批准任何申请。[0, c) 这段台阶：由于<c, v1>这个点赞史的存在，那么相应的求赞贴在发出时，已经保证了SafeAt(c, v1)；这一点可以类比东东同学前面的排第4位的同学，他必须保证自己前面是安全的。虽然张三不能确定 v1是否在c级台阶已经被批准(ChosenAt(c, v1)是否为真)，张三会遵守这个可能已经被批准的申请v1，他发出的求赞请求是<b, v1>。


2.2 一个实际的例子


假设有唐、宋、赵、秦、齐五个长老。宋、赵、秦三位长老在第3级台阶点赞批准了张三的申请，然后在第5, 8, 10级台阶有求赞贴发出，其他级的台阶上邀约阶段失败，未进入求赞阶段。这个过程如何保证正确性？

    第5级台阶上的应邀应形成多数派，必然包含了宋、赵、秦三未长老中的一个，即一定包含了<3, 张三的申请>这个点赞历史，且3是最大的；按照规则，第5级台阶上的求赞帖只能是<5, 张三的申请>。我们假设<5, 张三的申请>这个求赞贴只有唐长老一个人点赞，未形成多数派。在第8级台阶的邀约阶段，唐长老没有应邀。但是赵、宋、秦三个长老应邀了，他们的点赞史分别是<3, 张三的申请>，<3, 张三的申请>和 NULL。按照规则，第8级台阶发送的求赞贴必须是<8, 张三的申请>。我们假设这个求赞贴完全丢了，无长老点赞。在第10级台阶上，某个弟子在邀约后，收到了唐、赵、齐三位长老的应邀消息，他们的点赞史分别是<5, 张三的申请>，<3, 张三的申请>，NULL。那么10级台阶求赞贴内容是<10, 张三的申请>。

可以看出，只要在第3级台阶批准了张三的申请，后续无论在哪一级更高的台阶上产生的求赞消息，其包含的申请一定是张三的那个。这里面的原理是任意多数派必有交集，大家可以自己思考下。


后记

打比方本身并不是严谨的，但是希望能帮大家打开思路。本文的想法源于小时候看的电视剧里的丐帮，之前曾想过是用丐帮长老的袋子个数来比喻Ballot Number，但是发现没法对应完整的过程。登山帮长老的行为更符合我们对人往高处走并且势利的认识，从而更容易理解爽约是如何发生的，这就好比在我国古代能拿出更多彩礼的人更容易娶到媳妇一样(现代中国女性已经是独立的)。另外，请求中带的魔法，是想表达诱惑，类似于彩礼吧。不过好在大家是诚信的，爽约规则也是公开透明的，有条件的承诺不算忽悠。

编辑于 2020-05-05 22:18
##补偿]]
]]
[[
https://zhuanlan.zhihu.com/p/191845544

NiLang - 可逆计算，微分万物
Leo
理论物理博士
NiLang - 可逆计算，微分万物
1 年前 · 来自专栏 Julia中文社区

人类产生的能源中有2.5%用于计算，其中越来越多的部分用于人工智能产业。1961年，Landauer 从热力学第二定律出发，证明了凡是涉及信息擦除的不可逆过程，都伴随能量的耗散。因此，要解决能耗问题，可逆计算被认为是一种不仅理论严谨，而且在实践层面也很实际的方案，尤其是绝热CMOS技术具有很强的实际可行性。但是，可逆计算在最近的15年逐渐被打入了冷宫，在软件层面有两个原因，

    可逆计算要求现在的软件生态从底层开始重新设计，需要可逆的指令集，可逆的语言，可逆的应用，可逆编程比起传统计算往往具有需要额外的内存或者计算时间的开销

本文将会告诉大家，在人工智能时代，可逆计算的强制计算可逆的缺点将会变成它的优点，它将会是实现程序语言级别自动微分的一个现实的方案。文中，我们使用Julia中的嵌入式编程语言（eDSL）NiLang作为我们的主要可逆编程工具，它是由GiggleLiu（鄙人）和thautwarm一起开发的开源工具。关于这个工具的Tutorial，除了官方文档外，还可以看B站视频
Julia中文社区2020夏季会议（Day3 可逆编程与高性能自动微分）_哔哩哔哩 (゜-゜)つロ 干杯~-bilibili​
www.bilibili.com/video/BV1m64y1c7fT/

以及和这个视频配套的Pluto notebook。在此非常感谢Julia中文社区的工作者们提供这个做Tutorial的机会并上传这个视频。看完Tutorial后，想看更加理论和技术的部分可以查阅参考文献arXiv: 2003.04617。
什么是全语言自动微分？

当我们接触机器学习的时候，一个很重要的过程就是理解后向传播技术，很多小伙伴们跟着吴恩达老师的视频从推导矩阵乘法的后向传播规则开始了解什么是自动微分。我们把矩阵操作和激活函数联结起来构成神经元网络，通过后向传播得到整体神经元网络的导数。人们把常见的可以微分的操作做成了一个集合（软件包），这个操作的集合越来越大，表达能力越来越强。如今人们开始用微分编程，或者是自动微分这些新概念来表现这些自动微分库在对代码微分时候的强大。但是我还是要提醒大家，仍然有很大部分的需要自动微分的代码并不能很好的表达成常见的张量操作，自动微分远没有想象的自动(见：Leo：微分编程（一）：传统自动微分的三宗罪)。比如，你是否思考过这样一个问题，我们可以把矩阵乘法本身看成一个巨型神经元网络，里面的基础操作是"+"和"*"，我们发现其实可以通过基础四则运算的链式法则对矩阵乘法进行求导。但不会有人真的用主流的机器学习库从基础指令开始微分代码，因为这样做内存和时间都是问题。这些库都是为机器学习这个特定领域设计的，适合在张量层面操作的自动微分，他们包括

    TensorFlowPyTorchJax

而我们今天要讨论的另一类是通用的，可以微分整个编程语言，包括自动推导上述的矩阵乘法的自动微分规则，如

    ZygoteTapenadeNiLang

全语言微分无疑是机器学习和科学计算中的一个圣杯一样的存在。结合作者的领域物理学，有了全语言自动微分，很多变分算法以及逆向工程都会变得巨简单。比如微分量子力学含时演化可以帮助人们做量子控制，微分配分函数计算过程可以得到能量密度和比热容以及微分变分平均场和变分蒙特卡洛中的ansatz计算求梯度，人们可以自由的设计各种ansatz而不用手推梯度。
为什么说全语言微分需要可逆编程？

主流的机器学习库没法做到全语言微分，本质是因为后向传播过程要求回溯计算的中间变量。变量回溯是一个非常困难的问题，尤其对于非张量操作，传统checkpointing技术会带来的额外内存和时间的开销巨大。
传统自动微分中的checkpointing技术

Checkpointing 是一种通过往全局堆栈缓存数据的方式回溯中间状态的方案。
蓝色和黄色的多边形分别代表计算和重计算过程

示意图中，每隔100步，就有一个中间状态（虚线处）被自动缓存。当我们 要获得一个没有被存储的状态（图中状态100），我们只需要找到离这个目标状态往前数最近的被缓存的状态（状态1），并重新计算想要的状态。 这里，缓存状态不是拷贝整个磁盘，而是记录发生变化的变量。这种方案的一些较为致命的弊端，比如我们要改变一个矩阵的一个元素的时候，我们必须完整的拷贝整个矩阵，否则之前缓存的数据可能会失效。因为处理可变张量内存开销巨大，PyTorch和TensorFlow中会直接禁止改变单个矩阵元素（除了一些特殊的计算图叶子节点）。同时频繁的操作全局堆栈会导致一些计算密集的for循环效率变低，这在微分类似BLAS函数中的循环中尤为重要。

那么怎么样才可以做到真正的全语言微分呢？那就得看接下来要介绍的反计算技术。
反计算技术
菱形都是可逆过程，蓝色和黄色的分别代表了运算与逆运算。(a) 中红色立方体代表可逆计算过程中为了保证可逆性产生的额外内存消耗。(b) 当可逆性不带来额外的内存。

反计算是可逆计算中回溯中间状态，同时也是释放内存的过程。如图 (a) 所示，因为可逆计算每个过程都是可以倒着执行，所以并不需要额外的堆栈来缓存数据。但是没有免费的午餐，为了保证可逆，可逆计算也会显式的引入一些辅助空间（红色方块）。有时候为了控制辅助空间不要增长太快，需要用户自己在正确的时间通过反计算主动释放内存（时间换空间）。通过反计算而不是checkpointing更加容易做到全语言微分有如下的优点

    内存分配是显式的，用户有足够的管理内存，以及权衡内存与计算时间的自由度。同时没有全局堆栈的特点也使得GPU代码和CPU代码之间更加兼容。支持可变数组可以利用可逆性节省内存，如图(b)所示让用户倾向于写出更适合回溯状态的可逆风格的代码，因此实际内存消耗会小很多

因此，在编程语言或者指令层面，一般用可逆计算更加省内存和时间。更加详细的探讨请参阅 Nextjournal 上的一篇博文
Reverse computing is not checkpointing​
nextjournal.com/giggle/reverse-checkpointing
现实生活中的应用和NiLang的性能

NiLang 以Julia语言为宿主，实现了基于可逆编程语言，并实现了指令级别的高性能微分。随着NiLang拥有越来越多的用户，我们看到了越来越多的有趣的应用。这边简单介绍下其中6个，并着重对第1个进行基准测试。

1. Bundle Adjustment

Bundle adjustment是计算机视觉中一个比较重要的应用，训练中很重要的一步是计算一个稀疏的Jacobian，微软的一个研究中人们曾经对一些自动微分软件做过基准测试
不同自动微分框架在Bundle Adjustment应用中的基准测试。

测试中, 除了手动微分之外，表现最好的Tapenade和手动微分的结果接近。Tapenade 是在自动微分圈内有名的基于 C/Fortran 的经过充分优化的全语言自动微分框架，同时也是一个商业闭源软件。于是我们作了NiLang和Tapenade的对比如下
NiLang，ForwardDiff和Tapenade在Bundle Adjustment应用中的基准测试。

这个图中，我们发现在单核CPU上，NiLang的自动微分甚至比Tapenade还要快一些。同时我们仅仅用了不到10行代码就用KernelAbstractions把它放到了GPU上执行，并成功的加速了200多倍。

设备

    CPU: Intel(R) Xeon(R) Gold 6230 CPU @ 2.10GHzGPU: Nvidia Titan V. 

参考资料

    Srajer, Filip, Zuzana Kukelova, and Andrew Fitzgibbon. "A benchmark of selected algorithmic differentiation tools on some problems in computer vision and machine learning." Optimization Methods and Software 33.4-6 (2018): 889-906.microsoft/ADBenchJuliaReverse/NiBundleAdjustment.jl

2. 微分Gaussian Mixture Model

3. 优化NICE神经元网络 (一种Normalizing flow模型)的内存开销，代码可以在NiLang的文档中找到。

4. 微分Tropical张量网络算法求取自旋玻璃基态

5. 微分一段量化金融的代码并获得相较于Zygote 600x的加速，这段代码的作者的博文猴子掷骰子中可以找到.

6. 加速变分平均场理论中的性能关键的部分并获得相较于Zygote 600倍的性能提升。
结语：可逆计算与未来

让我们再回到文章开头埋下的伏笔，之前人们觉得可逆计算的软件层面有一些缺点导致这种计算模式不是很实际，现在我们站在人工智能时代我们再审视这两个缺点。首先，第一个缺点是软件生态尚未建立。但我们发现我们可以在没有可逆指令集的情况下，从可逆编程语言开始解决微分编程这个特定的问题，并不需要完整的生态。第二个缺点是可逆计算存在额外的内存或时间的开销，但我们发现这部分额外开销带来的可逆性恰好是机器学习回溯中间状态最好的解决方案之一。它给予用户规划内存开销和计算时间的自由度，使得代码兼容GPU设备，支持可变数组，并且比起传统checkpointing能够很好的利用可逆性节省内存。

此外，可逆编程给予我们更多的未来编译到可逆硬件的可能性，超低能耗可逆的硬件的发展将会成为AI技术的大规模普及的基石。
编辑于 2020-08-22 08:07

]]
[[
https://zhuanlan.zhihu.com/p/434703462
叶凌远
-
计算系统的结构II——计算模型的数学框架
6 个月前 · 来自专栏 数理逻辑随笔
前言

在上一篇文章 计算系统的结构I——对可计算性概念的反思 中我们对可计算性的一般概念进行了一个反思，为今天的这篇文章提供了观念基础和动机。在这篇文章中，我们将用更加技术化的语言来更加深入地了解 Higher-Order Computability 这本书的理论框架，以及它对我们理解可计算性起到什么作用。全文共 8000 字左右。

在正式进入主题之前，我们先规定一些这篇文章讲要使用的符号。对于两个集合间的部分函数 [公式] 和任意 [公式] 中的元素 [公式] ，我们规定：

    [公式] 表示 [公式] 有定义， [公式] 表示 [公式] 无定义；[公式] 表示 [公式] 均有定义，且两者的值相等；[公式] 表示如果 [公式] 二者之中一个有定义，则另一个也有定义，且这种情况下二者的值相等。

计算模型

在上一篇文章中我们提到了，在数学和计算机领域中，计算这个概念不总是基于自然数的。因此我们需要一个能够处理多种数据类型之间的可计算函数的理论框架。很自然的，不同的数据结构可以看作是不同的类型 [type]；我们假设我们有一个集合 [公式] ，其是所有数据类型名称 [type names] 的集合。例如如果我们只想考虑自然数和真值上的计算函数，集合 [公式] 应就只包含两个元素 [公式] 。

我们将 [公式] 上的一个计算模型 [公式] 定义为包含如下信息的对象：

    其给出了以 [公式] 为索引的一系列集合 [公式] ，其中每一个集合 [公式] 都可以看作是类型 [公式] 下的数据集；对于任意两个类型 [公式] ，其给定一个集合 [公式] ，其中的每一个元素都是从 [公式] 到 [公式] 的一个部分函数 [partial function]；我们要求 [公式] 在部分函数的复合操作下构成一个范畴。

简单地说，一个 [公式] 上的计算模型 [公式] 便是一个对象集合同构于 [公式] 的 Setp 的子范畴 [subcategory]，其中 Setp 是集合和部分函数所构成的范畴。注意，对于我们所关心的大多数计算模型而言， [公式] 都不是 Setp 的一个满子范畴 [full subcategory]，因为一般而言不是所有从 [公式] 到 [公式] 部分函数都是可计算的。

这样的定义是符合我们对于可计算性的直观的。对于不同的数据类型，其必定对应着不同的数据集合作为它的值，这便是 [公式] 这些集合所代表的含义。当然，也有可能不同的类型对应着相同的（或同构的）数据集合；我们将在后面看到这一点。在不同的数据类型之间，显然一个从 [公式] 到 [公式] 的可计算函数应该至少为一个从 [公式] 到 [公式] 的部分函数。直观上来说，至少所有恒等映射应该是可计算的，且两个可计算函数的复合也应该是可计算的。因此，要求 [公式] 构成一个范畴看起来是其构成一个计算模型的必要条件。从这个定义出发，我们来看看常见的一些计算结构如何融入到我们所定义的框架中来。

例子1: 自然数的计算模型. 从现有的研究来看，自然数应该算得上是最基础的计算模型了。我们能很自然地将其纳入上面的框架当中。此时的类型名称集合 [公式] 只包含一个元素，且自然地我们有 [公式] 。而对于态射我们自然也有 [公式] 是所有从 [公式] 到 [公式] 地部分可计算函数所构成的集合。容易验证其构成一个范畴。

例子2: untyped [公式] -calculus. Church 最早对于可计算性地研究基于 [公式] -calculus，是一种语形（syntactical）的进路。假设我们固定了一个变元集合 [variable set] [公式] （通常其是可数无穷的），则我们可以如下递归定义所有 untyped [公式] -calculus 的项 [terms]:

[公式]

我们定义 [公式] 为所有的项构成的集合在模掉 [公式] -等价后所得到的集合（我们假设读者熟悉 [公式] -等价的概念，其表示的是对于限制变元 [bounded variable] 的重命名）。在 [公式] 上我们还可以进一步定义 [公式] -等价关系，即由下面的条件所生成的最小等价关系：

[公式]

其中 [公式] 表示将 [公式] 中的自由变元 [free variable] [公式] 替换为 [公式] 后所得到的项（为了避免 [公式] 中的自由变元在替换到 [公式] 后被限制我们可能需要先替换 [公式] 中限制变元，但这是良定义的，因为在 [公式] 中 [公式] -等价的项代表同一个元素）。我们用 [公式] 表示项 [公式] 在 [公式] -等价关系下所对应的等价类，将 [公式] 记为 [公式] 在这个等价关系下的商。则我们同样有一个只有一个类型 [公式] 的计算模型，其中 [公式] 。对于任意 [公式] ，其都对应着一个良定义的映射函数 [公式] ，其定义为 [公式] 。这样的映射称为 [公式] -可定义函数，在我们的计算模型中，我们也令 [公式] 为所有 [公式] -可定义函数所构成的集合。值得注意的是，所有这样的函数都是完全函数而不是部分函数。感兴趣的读者应自行验证 [公式] 构成一个范畴，即 [公式] 上的恒等映射是 [公式] -可定义的，且若两个映射均为 [公式] -可定义，则其复合映射同样为 [公式] -可定义。

在 Higher-Order Computability 一书中还给出了许许多多的可计算模型的例子，有基于图灵机的，有基于编程语言的，还有和传统递归论和可计算理论中所研究的计算模型更贴近的，限于篇幅我们就不一一介绍了。我们后面的理论介绍将都基于上面给出的这两个最基本的计算模型的例子。
计算模型上的弱笛卡尔闭 [Weakly Cartesian Closed] 结构

在上一篇文章 计算系统的结构I——对可计算性概念的反思 我们提到了，我们有许许多多地理由关心高阶的可计算性，但高阶可计算性的具体数学结构只有在今天介绍了详细的计算模型的定义后才能展开说明。对应到我们前面提到的计算模型的范畴结构，高阶计算性表示这个范畴是弱笛卡尔闭的。这一节我们便详细地谈谈这一点。

给定一个 [公式] 上的可计算模型 [公式] ，我们说 [公式] 上有一个弱笛卡尔结构 [weak Cartesian structure] 当满足条件：对于 [公式] 中的任意两个类型 [公式] 我们有一个对应的类型 [公式] 和两个投影映射 [projection map] [公式] ， [公式] ，使得对于任意 [公式] 和任意 [公式] ，存在一个函数 [公式] 使得对于任意 [公式] 我们有：

    [公式] 当且仅当 [公式] 且 [公式] ；在这种情况下， [公式] ， [公式] 。

值得注意的是，在上面的定义中我们仅仅要求函数 [公式] 的存在性而不要求其唯一性，这是我们说它构成一个“弱”笛卡尔结构的原因。同时一般地，我们并不一定有 [公式] ，因为可能对于某些 [公式] ， [公式] 但 [公式] ，因此根据定义我们必定有 [公式] ，这表示 [公式] 。当某个 [公式] 满足 [公式] ， [公式] 时，其中 [公式] ， [公式] ，我们称 [公式] 表示了 [公式] 这个有序对。对于一般计算模型上的弱笛卡尔机构，不一定任意 [公式] 中的有序对都由一个 [公式] 中的元素表示，但对于许多常见的计算模型，如我们下面会提到的两个例子，这是成立的。

完全类似的，我们可以定义什么是 [公式] 中的一个弱终对象 [weak terminal object]：它由一个类型 [公式] 和一个元素 [公式] 构成，使得对于任意的类型 [公式] ，将所有 [公式] 中的元素都映射到 [公式] 的常函数是 [公式] 中的一个可计算函数。

感兴趣的读者可以尝试思考，在什么意义下弱笛卡尔积结构和弱终对象是不依赖于我们具体选择的，即当对于两个类型 [公式] 我们有多个类型和多个投影映射都满足是 [公式] 的弱笛卡尔积时它们之间有什么关系；或者当我们有多个弱终对象时，它们之间是什么关系。这些问题的答案应该是与范畴论中在同构的意义上定义笛卡尔积和终对象类似。有了如上定义，我们可以来看看之前提到的两个计算模型的例子。事实上，它们上面都有弱笛卡尔结构以及弱终对象。

例子1: 自然数的计算模型. 在这个例子中我们的类型结合 [公式] 中只有一个类型 [公式] ，因此我们别无选择只能有 [公式] 和 [公式] 的弱笛卡尔积就是其本身！这样定义的确能够构成一个弱笛卡尔积结构是由于我们有许多从 [公式] 到 [公式] 的可计算函数构成它们之间的双射，比如下面定义的这个可计算函数 [公式] ：

[公式]

显然，当我们有了这个双射 [公式] ，在弱笛卡尔积结构中我们所需要的两个投影映射可以分别定义为

[公式]

容易验证，对于任意两个部分可计算函数 [公式] ，我们可令 [公式] 为 [公式] ，显然其满足我们上面陈述的两个条件。由此可见，对于我们第一个非常基础的自然数的计算模型，其有一个弱笛卡尔积结构。同时由于 [公式] 是一个双射且 [公式] ， [公式] 都为完全函数，对于任意自然数的有序对 [公式] 它都由某一个自然数表示。我们选取不同的 [公式] 和 [公式] 之间的双射能够得到不同的弱笛卡尔积结构。这个计算模型具有一个弱终对象是显然的，因为任意 [公式] 到 [公式] 的常映射都是可计算的。

例子2: untyped [公式] -calculus. 对于第二个 [公式] -calculus 所对应的计算模型的例子，熟悉一些基本的 untyped [公式] -calculus 理论的读者应该都应该能够猜想到其也必定具有弱笛卡尔积结构。和例子1完全类似，在这个计算模型中我们也只有一个类型，因此其笛卡尔积必定只能是其自身。我们同样需要找到一个 pairing 函数使得 [公式] 本身就能够表达 [公式] 的信息。由我们的定义可知，在此计算模型中所有的可计算函数都由一个项生成。特别地，我们如下可以定义 [公式] 中的一个项：

[公式]

其中 [公式] 是 [公式] 的缩写；还有如下的两个项：

[公式]

此时，对于任意两个 [公式] 中的可计算函数，即两个项 [公式] ，我们这个有序对所对应的可计算函数可以选为 [公式] （注意，在 [公式] -calculus 的语境下项都默认为是左侧结合的）。由于 [公式] 中全是完全函数，因此我们可以直接结算 [公式] 和这个函数的复合；在项的层面这就是将这两个项相作用：

[公式]

上面的计算完全遵从于 (2) 中提到的 [公式] -等价关系。完全类似地，大家可以计算 [公式] ，其结果也必定和 [公式] 相等。由此可见， [公式] -calculus 所对应的计算模型也具有弱笛卡尔积的结构，且同样地对于任意一个有序对都有一个表示项与其对应。和例子1类似，任意 [公式] 到其自身的常映射都是 [公式] -可定义的，因此其上也具有弱终对象。

由此可见，对于前面提到的两个基本的计算模型的例子，尽管它们都只有一个数据类型，但它们都具有弱笛卡尔积结构，其原因也符合我们的直观：利用它们本身的数据集合就能够编码它们自身成对的信息。

目前为止，我们还不涉及高阶计算的内容，因为弱笛卡尔积结构从直观上只是说明在我们的计算模型中能够表达成对的数据值。与高阶计算内容密切相关的是弱笛卡尔积闭的结构。换句话说，我们要求可计算函数本身作为数据也能够在我们的计算模型中进行表达。这也就是我们接下来要阐述的。

我们称一个 [公式] 上的具有弱笛卡尔积和弱终对象的可计算模型 [公式] 上具有一个弱笛卡尔积闭 [weakly Cartesian closed] 结构，当我们给出如下信息：

    对于任意两个类型 [公式] ，我们指定一个类型 [公式] ；一个部分函数 [公式] ；

使得对于任意 [公式] 和任意部分函数 [公式] ，下面两个条件是等价的：

    [公式] 存在一个 [公式] 中的部分函数 [公式] 为其表示，即对于任意 [公式] ，若其是 [公式] 的表示，则 [公式] ；在 [公式] 中有一个完全函数 [公式] 满足对于任意 [公式] ， [公式] ， [公式] 。

直观上来说，高阶计算性或者弱笛卡尔闭结构是想说明 [公式] 这样的部分函数可以由 [公式] 这个类型的值，即 [公式] 中的元素表示。这个定义和一般范畴论中的笛卡尔积闭结构最大的不同在于，对于任意的一个函数 [公式] 若其表示存在，我们并不要求其表示函数 [公式] 是唯一的。换句话说， [公式] 中的元素是内涵性物体 [intensional objects]，如一段程序或者是一个算法（对于可计算函数的内涵与外延的探讨参见上一篇文章 计算系统的结构I——对可计算性概念的反思），我们可以有多个内涵性物体对应着同一个可计算函数的外延。从如上的定义中我们也可以看出， [公式] 这个部分函数也必定由某个 [公式] 中的函数表示，因为在 [公式] 中我们有 [公式] 上的恒等映射；我们把这个函数记为 [公式] 。我们再次来看看前面提到的两个计算模型的例子上的高阶计算结构。

例子1: 自然数的计算模型. 和之前类似，由于我们只有一个类型 [公式] ，因此如果其上有高阶计算结构我们也必定有 [公式] 。在考虑高阶计算结构的时候我们需要对可计算函数的具体实现方式作出更多的说明，因为如前所述，高阶计算模型不仅要考虑可计算函数的外延，还要考虑其内涵。因此此时，可计算函数的具体实现方式变得相关了。假设我们采用了图灵机的表述（换用其他常见的可计算函数表述，如传统递归论的或是其他类型的也是可以的，只是我们得到的高阶模型会有些细微的差别），则高阶计算结构（把自然数本身看作是某个程序，因为我们此处有 [公式] 和 [公式] 是同一个类型）具体实现方式是通过对所有的图灵机进行编码。假设我们选取了一个合适的编码，并用 [公式] 表示第 [公式] 号图灵机（由于有不同的图灵机计算相同的可计算函数，这显示了当我们把自然数本身看作是可计算函数的编码时其所表示的是内涵的结构，而不单纯是可计算函数的外延）。可计算理论中一个很重要的结果便是存在一个通用图灵机 [公式] 使得当我们输入一个有序对 [公式] 时，我们有 [公式] 。显然，我们可以把 [公式] 对应的可计算函数作为我们的部分函数 [公式] 。在自然数的计算模型中由于我们的函数 [公式] 是一个双射，因此任意可计算的 [公式] 都有一个对应的函数 [公式] 为其表示，其可以自然地选为如下的函数：

[公式]

此时我们也有另一个完全可计算函数 [公式] 满足 [公式] 。这来自于基本递归论中的 Kleene s-m-n 定理：对于任意一个图灵机 [公式] ，存在另一个完全图灵机 [公式] 使得对于任意 [公式] ， [公式] 。由此可见，我们基于自然数的计算模型是一个完整地高阶计算模型；在计算理论的文献中，这个模型一般被称为第一 Kleene 模型 [Kleene's first model]，记为 [公式] 。

例子2: untyped [公式] -calculus. untyped [公式] -calculus 的高阶可计算性某种意义上要比自然数模型的高阶性要更自然也显然一些。显然同样的，在这个模型中我们也必定有 [公式] 。其上的函数 [公式] 非常自然的就是项之间的作用函数。假设我们有一个项 [公式] 表示了某个函数 [公式] ，使得对于任意两个项 [公式] 我们有 [公式] ，则此时我们可以令 [公式] 为表示 [公式] 的项。此时我们有，

[公式]

这同样说明了 untyped [公式] -calculus 的计算模型是弱笛卡尔积闭的，其上很自然的有高阶计算结构。
剩余的问题

在前面两节中我们表述了最基础的高阶计算模型的数学结构，并陈述了我们常见的两个计算模型，即基于图灵机的自然数上的可计算模型和基于 [公式] -calculus 的可计算模型，如何融入到我们所定义的数学框架中。但这仅仅是一个开始。在本篇文章的最后我们阐述一下在此基础之上我们还应该关心什么基本问题。这一节可以看作一个预告，里面提到的内容将会在下一篇文章中具体地阐述。
问题1: 计算模型之间的关系？

首先，范畴的基本思想仍然指导着我们，一旦当我们定义了某种数学对象（比如我们这里定义的高阶计算模型），我们应该立刻关心这些数学对象之间的关系，即什么应该是它们之间的态射。在计算模型的语境下，两个计算模型之间的态射 [公式] 直观上来说应该对应着某种用 [公式] 来模拟 [公式] 中的计算的方式。在理解态射之后，进一步我们便可以询问什么情况下两个计算模型之间是等价的？

我们可以从上面所提到的两个计算模型的例子入手。在基础的可计算性理论中一个非常重要的结果便是，在 untyped [公式] -calculus 中定义的可计算函数和用图灵机定义的可计算函数是完全相等的——在我们的话语体系中更准确地应说它们定义了相同的可计算函数的外延。更具体一些，我们在 untyped [公式] -calculus 中可以定义形如 [公式] 这样的闭项 [closed term] 作为数字 [numeral]，其中 [公式] 是 将 [公式] 作用在 [公式] 上 [公式] 次，即 [公式] 的简写。则在 untyped [公式] -calculus 模型中的可计算函数（即由某个项所表示的函数）和图灵可计算函数在外延上是完全一致的。

更进一步，从直观上来讲我们似乎也的确能够用其中一个模型来模拟另一个模型的计算。对于用自然数模型来模拟 [公式] -calculus 的模型，我们只需要使用我们非常常见的编码手段，将 untyped [公式] -calculus 的语形用自然数编码，便非常容易能够看出 [公式] -calculus 上语形的操作能够用自然数的操作来进行模拟。但反过来也同样，对于任意自然数上的操作我们可以用前面定义的 [公式] -calculus 中的数字和闭项来模拟。因此直观上讲，对于这两个模型而言我们能够在一个模型中模拟另一个模型的计算。

但再继续深入地问，这样的双向模拟表示这两个计算模型之间是等价的吗？事实上，由前面的论述我们可以看出这两个模型也有许多非常不同的地方。比如在 untyped [公式] -calculus 当中所有的可计算函数全是完全函数，但在自然数模型中显然不是。它们到底是否是等价的，我们留到在下一篇文章中详细探讨。
问题2: 我们有没有类似代数拓扑中的不变量来描述计算模型之间的等价性？

在拓扑的语境下，我们一个很基本的问题是判断两个空间是否是同胚的。我们能够写下的所有连续函数都不构成同胚这件事并不能说明这两个拓扑空间之间没有任何的连续函数使得它们同胚，这个问题使用传统的办法是非常难以回答的。为了解决这个问题，在拓扑的语境下我们发展了代数拓扑的工具使得对于一个拓扑空间我们能够赋予其一系列代数的不变量；通过比较这些不变量，我们能够在某种含义的等价下（如同伦、弱同伦等价）判断两个拓扑空间是否属于同一个等价类。

这样的想法其实是非常普世的。在我们之前的一篇文章 范畴逻辑 I——逻辑与数学结构的对应 中介绍了将一阶逻辑片段扩展到一般范畴上的语义学，并阐释了在范畴语义下一阶逻辑模型的表示和完全性定理。但同样，我们或许不希望在最为普遍范畴的意义上考虑一个逻辑系统的模型。比如，任意的完全格 [complete lattice] 都是一个笛卡尔范畴，但显然我们几乎不在任何意义上希望考虑格上的代数理论。比如任意格上的群都是 trivial 的，这是因为格 [公式] 上的终对象是最大元，而对于任意元素 [公式] ，若其是 [公式] 中的一个群我们要求有一个态射 [公式] ，换句话说即有 [公式] 。这表明 [公式] 。因此，考虑一般范畴上的某个逻辑系统的模型太普遍了，对我们没有太大的作用。一个更加好的范畴类别是拓扑斯 [topos]，这是一类具有和 Set 十分结构的范畴，每一个拓扑斯都可以看作是某种构造性的数学宇宙 [constructive universe]；因此，在所有拓扑斯中看待逻辑系统的模型看起来至少是更为合理的。而由此我们生成了一种新的逻辑系统的 Morita 等价观念，即我们称两个系统是 Morita 等价的当且仅当它们在所有的拓扑斯中具有相同的模型。在这种等价观念下，我们在之前文章中介绍的逻辑系统的分类拓扑斯 [classifying topos] 便可看作是这种等价观念下逻辑系统所对应的完全不变量，即两个逻辑系统是 Morita 等价的当且仅当它们的分类拓扑斯是等价的。

回到我们的可计算模型上来。若我们对之前问题1有了一个好的答案，即我们有了一个计算模型之间的等价概念，我们能否找到这种等价概念下所对应的不变量，使得我们能够更加直接地判断两个计算模型之间是否是等价的？对这个问题的我们也会在下一篇文章中进行解答；事实上，和分类拓扑斯的构造类似，对于每一个计算模型 [公式] 我们也能够构造一个代表其计算结构的范畴 [公式] ，称为 the category of assemblies of [公式] 。这个范畴和拓扑斯一样有着非常丰富的范畴结构，可以看作是对于计算模型的某种分类空间 [classifying space] 其能够解决很多我们关于计算模型的问题。
结语

在这篇文章中我们简单地介绍了高阶计算模型的基本数学定义，并用了两个常见的例子阐述了这个数学框架如何将这些例子囊括在内，希望大家能够从更细节的角度理解高阶计算模型的数学结构，以及对于为什么要这么定义有一个直观上的把握。在文章的最后我们提到了一些剩余的问题，这些问题将会在下一篇文章中进行介绍。在下一篇文章中我们也会简单地总结一下高阶计算模型的应用，请拭目以待。
编辑于 2021-11-18 13:05

]]
[[
https://zhuanlan.zhihu.com/p/432584254

叶凌远
-
计算系统的结构I——对可计算性概念的反思
6 个月前 · 来自专栏 数理逻辑随笔

前言

这次终于要换一个主题了，我们不再讲述与范畴逻辑相关的内容，转为开始介绍可计算性 [computability] 这个概念了——但如果你学过范畴论，你就会知道范畴的思想无处不在。对我而言，在大一学习和一阶逻辑以及不完备性定理时，可计算性这个概念就引起了我非常大的兴趣。但由于国内没有非常好的关于递归论和可计算理论的课程，我那时和后来关于可计算性的疑惑也无处解答。直到当我大四时看见一本 2015 年出版的书 Higher-Order Computability[1]，我才醍醐灌顶。这本书真正意义上解答了我心中关于对可计算性这个概念许许多多的疑惑，因此我想向大家简单介绍一下这本书的内容和想法（其实这本书大一的时候就躺在我的 iBook 中了，但那时对于范畴论一无所知的我完全无法理解这本书介绍的深刻思想）。我目前总共打算分两篇文章来介绍这本书的内容。今天这篇文章会主要从可计算性的概念反思入手，几乎不包含任何技术性的内容。下一篇则会更加详细地介绍基于这样的概念反思这本书对可计算性的研究所采用的数学框架。如果大家看完这一篇或这两篇觉得感兴趣，请一定去阅读这本书。这两位作者的写作非常清晰，并且有非常好的导论和对可计算性概念历史发展地阐释，在技术细节和概念解释上有非常好的平衡，具有很高的可读性！显然我两篇字数有限的文章完全无法传达整本书的内容，仅仅能起到一个非常简略的介绍作用。全文共 7200 字左右。
可计算性不总是基于自然数

我相信如果大家了解过一些递归论或者是可计算理论的内容，大多都会有一个模糊的印象，认为计算理论研究的是从 [公式] 到 [公式] 的一个函数什么时候是可计算的，或者与之类似的相关问题。这个印象不能说是错的，对于自然数上可计算函数的研究的确是可计算性理论刚兴起时非常重要的内容。但在我们日常生活中或者在面对许许多多的数据结构的时候，这真的是我们唯一的对可计算性这个概念的理解方式吗？

首先，我们似乎不仅仅关心 [公式] 上的可计算性问题。或许首先一个比较微不足道的观察是，在计算机理论中我们对 [公式] 有不同的表示方式，比如经常采用的是二进制数。因此严格来说，此时可计算性和可计算函数所基于的对象变成了 [公式] ，即 01-字符串构成的集合。当然，很多人会说这两者没有本质的区别，因此采用哪一个发展可计算性的理论没有关系；我们的经验也的确支持这种看法，因为它们二者是同构的。

但我们在日常生活中遇到的例子不是都像改变自然数的进制这样微不足道的。比如在编程中或者在理论计算机的研究中，我们经常遇见的情况是我们所想要考虑可计算性的数据集合上有更多的结构存在：比如在数据结构中我们经常使用树、图或者是表这样类型的数据结构，这些结构本质上和自然数的结构是不同的。如果采用递归类型 [inductive type] 或者是许多函数式编程 [functional programming] 语言中的表示方式，自然数 [公式] 可以看作是如下的递归类型：

inductive N : Type :=
| zero : N
| succ : N -> N

换句话说， [公式] 的结构是由 0 和后继函数 [successor function] 递归生成的自由结构。我们同样可以类似地定义二元树的数据类型：

inductive Btr : Type :=
| leaf : Btr
| node : Btr -> Btr -> Btr

可以看见的是，二元树的递归生成方式是和 [公式] 不同的。自然数生成的方式是给定一个自然数，生成一个其后继；而二元树是给定两个二元树，可以通过一个点将二者连起来形成一个新的二元树。我们还有许多其他的递归数据类型，其上的结构也自然和二元树与自然数都是不同的。但几乎在任何一个高级编程语言中，我们都可以编写输入为自然数 [公式] 输出为二元树类型的程序；根据 Church-Turing Thesis, 所有由这样定义的函数都应是可计算的。因此，尽管 [公式] 和二元树的数据结构不同，我们仍然可以谈论什么是不同数据结构之间的可计算函数，并且对此具有一定的直观。

在一般的可计算理论分析中，我们解决上面这个问题的方式是考虑从一个结构到另一个结构的编码 [coding]。比如对于上面 [公式] 和二元树的数据结构，我们很容易看出来的是我们可以用二元树编码自然数。比如我们可以令满的二元树代表自然数，其层高对应着自然数的值；原则上，自然数的任意操作都可以在这套编码下采用二元树的操作来表达。但在实际的理论研究中我们更加熟悉的是用自然数来编码二元树。自然数这个集合是非常丰富的，其上的操作可以编码我们遇到许多数据结构。从某种程度上，这也是我们在可计算理论中主要考虑自然数上的可计算函数的原因之一。大家脑海中或多或少都会认为，由于这些编码函数的存在，我们只需要有了自然数这个结构上的可计算理论，其他的可计算函数均可以通过各种不同的编码来实现。

但这样对待可计算性理论的方式是有些不自然的。首先，采用编码的方式其实严格意义上并不能完全地解决我们的问题。如果我们使用自然数来编码二元树，通常的编码方式是找到一个从二元树到自然数的单射（或双射）Btr -> N。通过这个编码函数，我们便可以将自然数上的可计算性概念迁移到二元树这个结构上。但为了使这个方法成立，我们必须要求这个编码函数本身是可计算的！如果我们选取了一个本身不可计算的编码函数，那么一个根据 Church-Turing Thesis 不可计算的二元树上的函数 Btr -> Btr，根据这个编码转换成自然数上的函数后其也可能变成是可计算的。因此，为了选取一个合理的编码，从概念上我们还是无法逃脱需要首先知道什么是从二元树到自然数的可计算函数。

当然，在实际的可计算理论中，我们之所以可以不用发展更为一般的从二元树到自然数的可计算理论的原因是我们能找到许多直观上可计算的编码函数；一旦我们确定了这样一个编码，似乎我们就可以绕过上面这个问题了。但是，如果我们回到可计算性观念的层面，这样任意选取的编码函数对于我们理解可计算性这个概念的作用是微乎其微的。从更大的层面上来讲，可计算性这个概念没有任何先验的理由是特殊针对自然数 [公式] 的；对非常广泛的一类数学结构我们都能够非常直观地谈论它上面的可计算性，特别是在默认了 Church-Turing Thesis 成立的条件下。

另外从技术的角度，许多现代对于计算这个概念的发展和研究所基于的数学对象和结构并不全都能够用自然数来进行编码了。例如在最近十多年发展得越来越多的基于余代数 [coalgebra] 或者自动机 [automata] 来模拟的无穷计算 [infinite computation]，其考虑的就是诸如 [公式] 这一类集合上的可计算性。再或者我们想要模拟物理世界的可计算性，我们需要考虑的是在无穷时间的延伸下可能发生的各个物理事件之间的集合上的可计算性。和之前的二元树或其他的递归定义的数据结构不同的是，这些集合都不再是可数的了，因此用自然数编码来研究这些集合结构上的可计算性是根本行不通的了。这些无穷计算不仅仅是有理论研究价值的，目前一些函数式编程语言早已支持对这些无穷的数据进行编程操作了（如 Haskell 中非常重要的 lazy 特性就能够支持这一点）；另外，如果我们考虑人和计算机之间的交互，我们在一连串时间中不断按下的键盘和点击的鼠标也可以被模拟成在连续时间上的无穷事件。这些应用也都侧面地印证了，考虑这些不可数集合上的计算结构同样是重要的。

回到观念的层面上来看，我们所需要的是一个更加广泛与抽象的框架来研究与描述一般对象上的可计算性概念，而不仅仅是聚焦在自然数这单单一个集合上。此处可以跟我们对一般空间的研究做一个类比。我们对几何的研究有非常深的历史，早在古希腊我们对平面几何和立体几何就有了非常多的知识。但所有的这些知识都是对某几个空间中的某几类几何结构作出的描述，因此它们都可以看作是我们对某一些常见的数学对象所收集的知识。但我们对空间——或者以范畴论的视角来看，连续性——这个抽象概念的一般认识是要到在数学中发明了一般拓扑空间的这个抽象概念之后才真正有了质的突破。正因如此，拓扑这个概念在现代数学中的重要性怎样强调似乎也不为过。事实上，可计算性和连续性这两个概念有着千丝万缕异常紧密的联系，这个联系也是我们介绍的这本书中的一大主题。但限于篇幅，在这篇文章中或许我们没有机会提到了，只能如此非常粗略地告诉大家这个结论而已。与几何的发展完全类似的是，在可计算性领域许多顶尖的数学家以及逻辑学家，包括 Turing、Church、Kleene 等的工作之后，我们收集了许许多多的对于某些具体的计算模型的知识，并对于它们之间的关系有了很多初步的结果。但我们目前缺乏的是如同拓扑的概念一样谈论一般可计算性概念的抽象框架。基于拓扑的概念，我们能够谈论一般空间之间的连续函数；同样的，我们或许也需要有一个对可计算性的一般框架来考虑一般不同数据结构之间的可计算函数，同时比较不同计算模型之间的关系。

从某种意义上来说，我们介绍的这本书初步地解决了上面的这个问题。在书中给出了一般抽象意义上的计算模型的定义，并据此研究了一般可计算函数的性质。根据上一段的描述，书中自然地采取了范畴的框架。在这篇文章中我们并不会介绍书中给出的计算模型的具体数学定义；这将会是下一篇文章的内容。接下来我则会继续探讨一下对于可计算性这个概念其他方面的反思。
可计算性是一个高阶的概念

我们这次介绍的这本书的名字叫 Higher-Order Computability，即高阶可计算性。高阶可计算性的含义是，如果对于两种不同的数学结构 [公式] 我们有了什么是从 [公式] 到 [公式] 的可计算函数的概念，则我们同样需要考虑的是某种函数空间 [公式] （目前可以粗略地看作所有从 [公式] 到 [公式] 的可计算函数集合）上的可计算性。比如，我们希望知道以什么方式选择一系列从 [公式] 到 [公式] 的可计算函数其本身是可计算的；采用更加数学化的语言，即我们同样想要了解什么是 [公式] 到 [公式] 的可计算函数。当然完全类似的，我们还可以考虑相应更高阶的可计算性，如集合 [公式] 上的可计算性。

为了说明高阶可计算性的概念与直观，我们这里将其和拓扑进行一个类比。很多人或许会认为拓扑是在研究空间的性质，但基于范畴的观点更加自然地描述或许是拓扑空间是在描述连续函数的性质。完全类似的，计算理论实际上是在研究可计算函数的性质。在拓扑空间的语境下，我们需要考虑什么是两个空间之间的连续函数；但更进一步，我们还需要知道如何连续地选择两个拓扑空间上的连续函数。因此自然地，连续性也本质上是一个高阶的概念，而连续的高阶性在现代拓扑中起着非常重要的作用。如果采用范畴的语言，无论是可计算性还是连续性，高阶的含义实质上是要求我们所考虑的某个范畴是 Cartesian closed 的（在可计算性中由于我们要考虑部分函数 [partial function] 因此所有的范畴结构我们都只考虑弱版本的，即泛性质 [universal property] 只考虑存在性而不考虑唯一性）。对于所有的拓扑空间我们没有一个很好的解决方案，因为 Top 这个范畴并不是 Cartesian closed 的；但如果局限在紧致的 Hausdorff 空间下我们可以拓扑化两个拓扑空间之间连续函数所构成的空间，这个构造对高阶的连续性作出了一个很好的解答。在可计算性的语境下，我们也需要类似的 Cartesian closed 的结构来模拟高阶的可计算性。

为什么考虑可计算性时我们一定需要考虑高阶的可计算结构呢？其原因是多样的。在这里我们仅仅讨论两个和数理逻辑以及可计算理论最相关的原因。

首先，让我们对可计算函数的外延和内涵做一个区分。如果我们简单地采用程序语言的叙述方式，在某种意义上我们可以说任何一段输入输出均是自然数的程序都定义了一个部分可计算函数 [partial computable function]。但从直观上来讲，这一段程序比这一个单独的部分可计算函数包含了更多的信息，因为一段程序不仅仅能够给出正确的结果，它还包含了如何具体计算这个函数的步骤与方式。从另一个角度来讲，我们可以有另一段完全不一样的程序使用了另一种计算方式，但它们计算的是同一个部分可计算函数。换句话来说，尽管我们经常把程序和可计算的函数等价起来，在观念的层面它们是不一样的：一段程序是有内涵的 [intensional]，其对应的那个部分可计算函数仅仅表征了这一段程序的外延 [extension] 而已。因此，如果只单纯地考虑从 [公式] 到 [公式] 的可计算函数这个集合，我们是仅仅在外延的层面考察可计算性，而忽略了其内涵。

对于大多数的编程语言，特别是许多现代的函数式编程语言比如 Lisp, Haskell 或者是 Lean，它们都支持将它们本身的一段程序作为数据而对它们进行编程和各种操作；直观地来说，它们都在它们的语言中包含了一份自身 [contains a copy of themselves]。在这些语言中，输入输出为 [公式] 的程序本身也能够成为输入和输出来考虑其上的可计算性。因此对这些编程语言而言，仅仅考虑可计算函数的外延是不够的。计算函数的内涵性往往是通过高阶可计算性来刻画和表达的。换句话说，在我们的高阶计算模型中，前面提到的 [公式] 这个集合并不是所有从 [公式] 到 [公式] 的可计算函数的外延构成的集合，而是它们的内涵构成的集合。因此，如果我们想要刻画这一类编程语言的抽象结构，考虑高阶计算性是不可或缺的。高阶可计算模型的研究也的确有很大一部分是为了解决和许多程序语言的计算语义相关的问题。

高阶可计算性以及对可计算函数内涵和外延的区分，更是直接地与直觉主义逻辑的构造性或可计算性阐释息息相关，因此它对数理逻辑的研究也非常的重要。从高阶可计算性研究的历史来讲，的确也有很大一部分贡献和发展来自于对数理逻辑中直觉主义逻辑相关的研究。直观上来讲，我们常常声称直觉主义逻辑有某种构造性阐释，即某个命题在直觉主义逻辑下可证明当且仅当我们能够给出某种构造来直接地验证或说明它是正确的。在现代数学的语境下，构造数学 [constructive mathematics] 和直觉主义数学 [intuitionistic mathematics] 在很多时候是作为同义词被大多数数学家使用的。例如，在直觉主义的构造性阐释下，对于推出连接词 [公式] 的证明或构造指的是一个把 [公式] 的证明或构造转化成 [公式] 的证明或构造的一个程序。但在这种解释下，如果没有对高阶可计算性的刻画我们是无法理解有嵌套的推出连接词，如 [公式] 等公式的构造性解释的：套用前面的说法，对 [公式] 的一个证明是一个把将 [公式] 的证明转化到 [公式] 的证明的程序转化为 [公式] 的证明的程序（这句话用自然语言写出来非常难读，正是因为其涉及可计算性的高阶嵌套）。对于涉及到多个存在量词嵌套时直觉主义逻辑公式的构造性解释也完全类似。为了能够给这些嵌套的直觉主义逻辑公式一个严格地构造性阐释，有一个准确的语言来描述高阶的可计算性是必要的。
比较不同计算模型之间的关系

本文的最后一节我们来探讨一下不同计算模型之间的关系。在上世纪三十年代，Turing、Church、Kleene 等人的工作让我们非常惊讶地发现，许许多多完全不同的定义 [公式] 上可计算函数的方式所给出的是完全一样的同一族函数。Church 对于可计算函数的刻画是基于 [公式] -calculus 的，其中对数字和可计算函数的表示都是基于 [公式] -calculus 中的项 [terms]，是一个完全从语言和语形出发给出的构造。Turing 定义的图灵机则有完全不同的直观，它是基于某种特殊的物理可实现的机器，这些机器也被称为图灵机 [Turing machine]。而 Kleene 创立的递归论则是一个从复合 [compositionality] 和递归 [recursion] 结构出发的进路。事实上我们还有许许多多的计算模型，比如和现代计算机更加接近的基于暂存器 [register machine] 的计算结构，或者从纯逻辑的证明角度出发基于一阶算数系统的计算结构。所有关于这些计算模型的讨论可以参见[2]。令人震惊的是，这些看似完全不同——有着完全不同直观且基于完全不同的出发点——的计算模型所最终定义的可计算函数是完全一样的！这个事实也可以看作是可计算性能够作为一个数学中值得研究的抽象概念存在的最有力证据。

但值得注意的是，这里我们所谓的这些不同的计算模型给出完全一样的可计算函数指的是在外延的层面上。换句话说，从 [公式] 到 [公式] 的部分可计算函数这个外延集合具有非常高的鲁棒性。但这些不同的计算模型给出相同的可计算函数外延是否真的表明这系计算模型是等价的？这个问题从我刚开始接触可计算理论就一直困惑着我；直到我看到这本书，才感到有一个足够普遍的数学理论框架能够真正意义上对这个问题进行一个回答。

首先，现代数学或者说范畴论的经验告诉我们，要回答关于等价的问题，事实上是要回答态射的问题（顺嘴一提，这一点也说明有等价这个概念的地方就有范畴论的身影，如果再推广到无穷范畴则是有若等价这个概念的地方就有无穷范畴的身影；这从侧面解释了为何范畴和无穷范畴能够作为现代数学的语言而存在）。在可计算性的语境下，我们要考虑的态射则应该是某种模拟 [simulation]，即在一个计算模型中能够作出的计算能否平行的用另一个计算模型来进行模拟。

给定两个计算模型我们是可能有多种模拟方式的。比如给定一个有有限字母表的图灵机，我们可以有非常多种不同的方式来表达自然数；假设我们想要把基于递归论的可计算性用图灵机的方式进行模拟，则任意一种不同的表示自然数的方式应该都对应着不同的模拟方式（当然，表达自然数的方式只是一个计算模拟中很小的一个方面，由于在此处我们没有介绍其严格数学定义，我们仅以此为例；在下一篇文章中我们会更加严格地阐述计算模型和模拟的数学定义）。在这些不同的模拟方式下，有些模拟方式之间是能够可计算转换地（再一次，对于可计算转换地直观我们可以参考在拓扑的语境下连续转换的直观）。对于熟悉范畴论的读者，上面的描述很自然地构成了一个 2-阶范畴 [2-category]。在 2-阶范畴的语境下，我们有非常一般的有关等价 [equivalence] 的定义，而我们对于计算模型的等价也就定义为这个 2-阶范畴中的等价了。

也许大家读到这里已经有些云里雾里了；没有关系，在下一篇中我们更加仔细地介绍上面用自然语言阐述的思想背后的具体数学内容。在这里我们仅仅给出一个结论：上面提到的众多可计算模型在我们更加精细的等价定义下并不全是等价的！尽管它们都给出了外延相等的一族可计算函数，但当我们考虑高阶可计算性或者是其他可计算模拟之间的转换时，不同的计算模型之间有着更为细微的差别。如果我们再考虑更为广泛的计算模型，比如前面提到的许多无穷计算模型，则它们之间的差别会更为巨大。对笔者个人而言，这样的结论是符合我的直观的；并且它们的不等价性反应在了更多数学性质的不同上，这也间接地证明这样的考虑是有必要的。再说最后一次，这些内容的讨论详见下一篇文章！
结语

在这篇文章中我们对可计算性和计算模型进行了一个概念反思。对笔者个人而言，这样的思维过程是重要的，因为最终和空间以及连续性的概念一样，我们是想要对什么是空间这样一个抽象的概念进行理解与研究，而不仅仅是局限在研究三维欧式空间中的几何。尽管不能说拓扑的概念是我们对空间这个概念所作出的最终答案，但这的确是第一个抽象的框架使得我们能够阐述有关连续函数的一般性质。完全类似的，关于可计算性这个概念我们也需要这样的一套框架使得我们能够对一般的可计算性进行研究。我相信这样的思维方式一定会极大地扩展可计算性相关研究的视野及内容，对我们更加深入地理解数学的本质一定是有很大的帮助的。希望感兴趣的同学能够开始思考相关的问题。
参考

    1. ^Longley, J., & Normann, D. (2015). Higher-order computability (Vol. 100). Heidelberg: Springer.
    2. ^Cooper, S. B. (2017). Computability theory. Chapman and Hall/CRC.

编辑于 2021-11-12 17:28

]]
]]]
xxxxxx
[[[[
[[
https://www.zhihu.com/column/reversible-computation
可逆计算
云计算实现计算的云化，可逆计算实现计算的可逆化
canonical
canonical
 · 
18 
篇内容
置顶内容
https://zhuanlan.zhihu.com/p/64004026
可逆计算：下一代软件构造理论
谨以此文庆祝清华建校108周年，及5字班本科毕业20周年 作者： Canonical 众所周知，计算机科学得以存在的基石是两个基本理论：图灵于1936年提出的图灵机理论和丘奇同年早期发表的Lambda演算理论。这两个理论奠定了所谓通用计算（Universal Computation）的概念基础，描绘了具有相同计算能力（图灵…
https://zhuanlan.zhihu.com/p/502628232
什么是好的模型？
昨天在介绍模型驱动的时候，有位同学问我如何设计一个好的模型？这是一个很难回答的问题。因为好很难定义，如何到达所谓的好更没有一定之规。 首先，好的定义往往是场景相关的，一个当前最优的选择随着场景的变迁也可能不再是好的选择。即使是放之四海而皆准的更好，比如广义相对论 vs. 牛顿力学，在解决具体问题的时候，也可能简单的牛顿力…
https://zhuanlan.zhihu.com/p/452251297
关于“从实现原理看LowCode”
吴多益：从实现原理看低代码 在这篇文章中谈到了对LowCode的一些观点。我总体上赞同他的看法，但是关于可视化编辑与LowCode之间的关系，以及代码生成的适用范围，我也有一些不同的意见。 1. 可视化编辑对于低代码来说是不是必不可少的？ 单就低代码产品来说，可视化编辑可能是必不可缺的功能，因为这是一个非常重要的卖点。但是…
https://zhuanlan.zhihu.com/p/380251899
我的文章为啥写得这么难看？
本文使用 Zhihu On VSCode 创作并发布 我的文章的阅读量一直不高，阅读完整率基本在20%左右，可以说是相当不讨喜的。根据我个人的分析，有一个很重要的原因（排除语文能力堪忧和论题混乱/没用等等原因）：猛不丁冒出一些似是而非的物理名词，非常劝退。 一些朋友反映我的文章普遍看不下去或者看不懂，而且越是计算机科班的同…
https://zhuanlan.zhihu.com/p/377740576
从可逆计算看Delta Oriented Programming
本文使用 Zhihu On VSCode 创作并发布 多年以前，为了向领导汇报，需要鼓吹一下可逆计算理论的原创性和普适性，所以我做了一点文献调研，查阅了国际软件工程大会(ICSE)历年的文章，发现最接近的理论是1997年出现的Feature Oriented Programming（FOP）[1][2]和2010年左右由…
https://zhuanlan.zhihu.com/p/344845973
从可逆计算看LowCode
2020年低代码（LowCode）这一buzzword频繁亮相于主流技术媒体，大背景下是微软/亚马逊/阿里/华为等巨头纷纷入场，推出自己的相应产品。一时之间，大大小小的技术山头，无论自己原先是搞OA/ERP/IOT/AI的，但凡认为自己有点技术的厂商，不说改旗易帜，至少也要加绣一条LowCode的花边，表示不落人后。 根…
https://zhuanlan.zhihu.com/p/344368626
关于"业务逻辑拆分模式:file/dir/repository"的几点讨论
@陶文 组织了一个微信群"业务逻辑拆分模式撰写组"，在讨论中他提出一个观点 业务逻辑最终都是要分解成文件，文件夹，git仓库的。那是否应该从这个角度入手：什么东西适合用文件，什么东西适合用文件夹分，什么东西适合用git仓库分呢? 软件工程的本质是否就体现在这种分解过程中？是否存在一般性的可操作的规则来指导我们进行…
https://zhuanlan.zhihu.com/p/193117183
Paxos的魔法学研究报告
Paxos算法并不长，写在纸上也仅有短短的四句话。它之所以看起来有些像是微言大义的天书，主要是我们并不清楚这几条简单规则背后的设计意图是什么，为什么它能起作用，不采用这些规则是不是就不行？分布式系统的底色是生的自由、死的随机的一片混沌，矛盾冲突无处不在，但是Paxos算法却偏偏在这一片混沌之上建立了统一一致的共识世界，…
https://zhuanlan.zhihu.com/p/64800798
从React Hooks看React的本质
后jQuery时代的前端革命是由AngularJs发起的，它最初的一个想法是将后台的技术架构复制到前台来。后端的一个核心技术是所谓的模板技术(template)。它可以用一个公式来描述 html = template(vars) 这是一个特别直观的想法：模板就是一个普通函数，它根据传入的变量信息（无特殊要求）拼接得到字符…
https://zhuanlan.zhihu.com/p/163852896
可逆计算的技术实现
最近和一些朋友交流Low Code平台的开发经验，发现大多数工作都是由前端架构师主导的，主要精力集中在可视化界面设计器方面，这与可逆计算的理论有着很大的区别。 维特根斯坦有一句名言：语言的边界就是我们世界的边界。语言之外的世界是一片黑暗，难以感知且不可言说。当我们专注于通过类型（Type），函数（Function）…
https://zhuanlan.zhihu.com/p/85492497
从可逆计算看声明式编程
可逆计算是笔者提出的下一代软件构造理论，它的核心思想可以表示为一个通用的软件构造公式 在这一公式中，所谓的领域特定语言（DSL）占有核心位置，而可逆计算在实践中的主要策略就是将业务逻辑分解为多个业务切面，针对每个业务切面设计一种DSL来描述。DSL是声明式编程的一种典型范例，因此可逆计算可以被看作是声明式编程的一种实现…
https://zhuanlan.zhihu.com/p/85491177
什么是声明式编程
一. 声明式 vs. 命令式。 什么是声明式编程？一般来说我们对于声明式的理解都是相对于命令式（imperative）而言的。图灵教会了我们imperative的真谛，并赋予了它数学意义上的精确定义：一台有状态的机器，根据明确的指令（instruction）一步步的执行。而所谓的声明式，它可以看作是命令式的反面。曾有人言…
https://zhuanlan.zhihu.com/p/66548896
NOP --- 下一代软件生产范式
作者： Canonical 什么是NOP？NOP是Nop is nOt Programming 以及 Nop Oriented Programming的递归缩写，它代表了一种以可逆计算理论为指导，采用非编程的方式，通过人机智能协作，批量化进行软件定制生产的下一代软件生产范式。NOP的目标是在提升10倍生产率的同时提升10…
https://zhuanlan.zhihu.com/p/65449477
写给小白的Monad指北
最近公司来了个新同事，他姓白，年纪又很小，我们都叫他小白。小白最近在学习函数式编程，前几天他过来问我一个问题。 小白：我正规985学校毕业，为什么看了这么多Monad介绍，还是云里雾里的。是这些文章写得的有问题，还是我的理解力有问题？ 我：你学什么专业的？ 小白：高分子。毕业后我在家自学了半年编程。 我：好吧...…
https://zhuanlan.zhihu.com/p/64822099
基于可逆计算的模型驱动架构
怎么把大象装到冰箱里？只需要三步： 把冰箱门打开 把大象放进去 把冰箱门关上 同样，基于可逆计算实现模型驱动架构也只需要三步： 1. 首先针对自己的业务领域设计领域模型。 这个模型应该同时存在文本表示和图形表示，比如ballerina语言（https://www.infoq.cn/article/ballerina-integration-tutorial-part-2）。当然每次做一个领域抽象都搞出一个DSL语…
https://zhuanlan.zhihu.com/p/64153956
从可逆计算看kustomize
kustomize是kubernetes最新版（1.14）中力推的声明式配置管理机制。它明确提出了“Customization is reuse”的概念。其核心思想是仿照Docker的设计原理，将配置文件也类似文件系统一样进行分层管理。最底层是一个作为基础的base文件，然后将不同的patch文件覆盖（overlay）…
https://zhuanlan.zhihu.com/p/64020543
从可逆计算看JavaScript的编程范式
为什么JavaScript是世界第一编程语言 ​ 根据Stack Overflow最新发布的2019年开发者年度调查报告，JavaScript已经连续第7年蝉联最常用的编程语言。JavaScript无疑是目前受众最广的编程语言，但它是否是世界第一的最好的编程语言？百姓网的架构师贺师俊（网名hax）的回答是“…
https://zhuanlan.zhihu.com/p/64007521
可逆计算的方法论来源
对于软件领域的大量设计原则和所谓的方法论，我一直持有很深的怀疑态度。为什么会存在这些原则，能否从科学的层面证明它们的有效性？可逆计算理论试图为软件构造提供一个更加坚实的理论基础，它明确提出应该将“差量”提升为第一性的概念，将全量看作是差量的一种特例（全量=单位元+全量），围绕差量概念去重建整个领域概念体系。可逆计算的思…
]]
[[[
[[
xxxxxx
]]
[[
https://zhuanlan.zhihu.com/p/502628232
[
模型需要明确定义它对外部环境的依赖，并尽量缩减它对外部的依赖点。模型的价值首先在于它可以被独立的解释和认知。

模型的内容重于形式，但是形式应允许反向析取。大量使用某种语言或者某种框架内置的机制来表达模型，虽然可以简化一次性编写的成本，但长期来说对于模型演化并不有利。为了最大化模型的价值，模型作为描述性信息应该是多用途的，不应只服务于某种单一目的，需要支持对模型信息进行再加工和形式转换。
]

canonical
千山万水
什么是好的模型？
1 个月前 · 来自专栏 可逆计算

昨天在介绍模型驱动的时候，有位同学问我如何设计一个好的模型？这是一个很难回答的问题。因为好很难定义，如何到达所谓的好更没有一定之规。

首先，好的定义往往是场景相关的，一个当前最优的选择随着场景的变迁也可能不再是好的选择。即使是放之四海而皆准的更好，比如广义相对论 vs. 牛顿力学，在解决具体问题的时候，也可能简单的牛顿力学更实用。

第二，如果我们能够设计出一个适用范围很广、能够应对很多变化的模型，那么本质上的原因也是领域逻辑具有某种内在的规律，模型只是这种规律的一种自然体现。软件设计目前还远谈不上是一种精密、复杂的科学，即使不懂得任何设计理论，多观察一下别人的成功和失败经验，一般也能达到一个差不多的程度。

第三，创造性的解决问题的方案在一开始可能显得离经叛道，与当前的生态格格不入，反而有可能看上去是不好的。

虽然很难以一种明确的方式去定义什么是好的模型，我们仍然可以根据一些表观条件来过滤掉一些次优的选择。

    设计是多目标优化的。我们可以把问题分解为多个维度，在每个维度上单独衡量，然后再综合评估。
    设计是多层次的（空间），不要试图设计一个最好的、万能的模型。比如，存储层和应用层可以有不同的对象结构，没必要使用统一的对象结构一统到底。使用DDD领域模型驱动也不需要排斥根据物理模型来生成实体存储层的代码。不同抽象层次、面向不同使用意图的元素不要混杂在同一个模型中。基于可逆计算理论，可以通过增量化代码生成来实现不同结构的模型共享部分基础信息。
    模型应是面向演化的（时间），不应过早引入限制未来选择的设计决定。基于可逆计算理论，可以通过差量机制永远为模型保留最细粒度的扩展能力和多模型融合的能力，可以通过元编程弥补组件和插件机制的不足。
    模型的复杂度应适中。解决方案的复杂度与问题的复杂度，以及具体执行人所能适应的复杂度要相匹配。简单的问题不应该采用明显过于复杂的解决方案。如果执行人的能力范围有限，即使一个方案可能在技术层面更优，但更容易出现误操作、出现问题更难独立解决，那么可能还不如使用执行人能够充分理解、具有充分自主控制权的方案。反之，一个复杂的问题可能不存在简单的解决方案，简单粗暴将意味着拆东墙补西墙，疲于奔命。
    模型需要明确定义它对外部环境的依赖，并尽量缩减它对外部的依赖点。模型的价值首先在于它可以被独立的解释和认知。
    模型内在的概念完备性和一致性非常重要。基于可逆计算理论，对于模型可参与的运算，我们需要进行配对设计，即每个改变状态的动作（差量）都对应一个反向动作（差量），使得系统在某种意义上可以恢复到前一个状态。不能反向往往意味着信息记录的缺失和设计空间的不完备性，面对异常情况时会无法处理。
    任何一个具有一定复杂度的模型都应具有分解、合并和二次抽象的机制。比如支持组件封装，import子模型等。可逆计算理论为此提供了一整套通用的解决方案，无需针对每种模型再进行单独设计和实现。
    对模型信息的处理利用可以是多阶段的。应尽量在代码生成、编译期、预处理等阶段进行处理，不要把与运行时状态无关的逻辑和运行时逻辑纠缠在一起。
    模型的内容重于形式，但是形式应允许反向析取。大量使用某种语言或者某种框架内置的机制来表达模型，虽然可以简化一次性编写的成本，但长期来说对于模型演化并不有利。为了最大化模型的价值，模型作为描述性信息应该是多用途的，不应只服务于某种单一目的，需要支持对模型信息进行再加工和形式转换。
    模型应该由元模型来定义。通过元模型可以最大限度的发掘不同模型之间的语义和结构共性，便于实现它们的互联互通。通过元模型可以自动生成模型解析器、IDE插件和设计器等。

发布于 2022-04-21 18:06

]]
[[
https://zhuanlan.zhihu.com/p/452251297

canonical
千山万水
关于“从实现原理看LowCode”
4 个月前 · 来自专栏 可逆计算

吴多益：从实现原理看低代码 在这篇文章中谈到了对LowCode的一些观点。我总体上赞同他的看法，但是关于可视化编辑与LowCode之间的关系，以及代码生成的适用范围，我也有一些不同的意见。
1. 可视化编辑对于低代码来说是不是必不可少的？

单就低代码产品来说，可视化编辑可能是必不可缺的功能，因为这是一个非常重要的卖点。但是对于广义的低代码而言，可视化并不应该是必须的选择。可视化实际上是意味着同一份信息同时具有两种表示：文本表示和可视化表示，而且这两种表示之间是可以进行可逆转换的。声明式并不一定可以从展现结果反向推导到源码，可以反向的只能是声明式的一个可逆子集。

从广义的角度上说，真正的发展方向是可逆的表达方式：同一份信息具有多种表达方式，而且它们之间可以相互转换，最终使得信息能够摆脱单一形式的约束，实现无阻碍的自由流动（第一次工业革命源于人们发现能量在不同形式之间可以相互转化）。典型的，AMIS 框架向下兼容这一优势与可视化并无关系，它只是说AMIS的信息表达方式在某种程度上是自我完备的，它的语义仅依赖于其自身的结构定义，从而它可以具有多种解释的可能性，在不同的时期、不同的技术环境中我们可以为AMIS的逻辑表示提供不同的执行层面的表示而已。

传统上面向代码编程时，我们并不是很关注描述信息的完备性，很多信息存在于文档中、程序员的头脑中，或者散在于外部图灵完备的语言、框架中，从而难以通过简易的手段对信息进行反向抽取，更无法为它提供逻辑等价的不同表达形式。

进一步的论述可以参见我的文章
canonical：从可逆计算看LowCode57 赞同 · 4 评论文章
2. 生成代码的方案算不算低代码？

原则上生成代码与基于JSON格式进行解释并没有本质上的差别。例如在形式上，我们可以这样看待amis框架的运行过程：

result = renderAmis(json, data)

renderAmis作为一个解释器接受amis规范所定义的json文件以及外部传入的data数据，从而在运行时产生最终的结果。

我们知道，多参数函数可以通过curry化转化为单参数函数，所以这一过程实际上等价于

result = (renderAmis(json))(data)  

即 renderAmis与json先结合，产生一个函数，然后再把这个函数作用到data上。

如果renderAmis(json)的信息在编译期已经能够确定，那么完全可以在编译期经过编译优化得到一个编译后的组件。

component = renderAmis(json) // 在编译期执行 
result = component(data)   // 在运行期执行

在数学上，所谓的编译过程可以看作是将一个原先运行期的函数拆分成了两个部分：编译期的函数生成器 + 运行期的函数。这一过程，可以被看作是将函数提升为了泛函或者物理上我们常说的算子。

理论上说，生成代码并不是做不到“持续的可视化编译”，只要通过即时编译技术实现动态的差量编译（差量化的产生式编程），所有解释模型能做到的事情，多阶段编译技术都能够做到。

更详细的分析可以参见我的文章
canonical：可逆计算：下一代软件构造理论131 赞同 · 41 评论文章
canonical：可逆计算的技术实现55 赞同 · 22 评论文章

当然，目前业内并没有公开的开箱即用的现成解决方案，基于代码生成有很多工程问题需要去解决。
3. 低代码是不是存在着先天的局限性？

低代码是不是只适用于特定领域？依赖低代码构建的程序是不是对特定的领域模型具有强依赖，从而本质上丧失了灵活性？

低代码的力量在于它内置了很多领域相关的假设，从而可以减少不必要的重复表达（通过引擎内部的自动推理减少了手工编写的各类关联和转换代码）。但是一旦领域假设局部假设被突破，会不会导致整体程序结构被摧毁？

最基本的，明明是一个字段级别的需求问题，但是经过低代码封装后，我们如何进行字段级别的定制？如何才能定制修改封装后的组件？还是说要对整个页面进行特殊处理，甚或是废弃整个框架从头来过？

回顾一下物理学中的成功经验，我们总是以递进式的方式来解决问题，零阶模型、一阶模型、二阶模型...。当越来越多的特殊化的信息进入我们的认知之后，我们并不会直接推翻此前基于少量通用信息所建立的模型，而是可以不断补充一个高阶模型来对差异化部分进行描述。

可逆计算在理论层面提供了一个完整的解决方案，它指出本质上低代码并不会受到这些局限性的限制。
4. 图形化的逻辑表达

图形化的方式确实不适合表达细节逻辑，因为它的信息密度很低。图形的好处是可以充分利用人脑并行模式识别的能力，迅速发现二维或者三维的某种组织模式，但总的来说，人类的文化不是围绕着图形化表达方式建立的，除了数学符号之外的图形化表达方式一般缺乏文化背景，导致传达的信息量很有限。

当我们用代码来表达逻辑时，它潜在利用的信息很多：

    函数调用、算术运算、算符结合律等复用了我们花费多年学习的数学知识 程序语法要素和书写形式类似于我们习惯的自然语言 代码文本的顺序潜在的表达了代码运行时的执行顺序 通过括号、缩进、函数调用等表达的嵌套结构，与程序运行时的堆栈变化存在直接对应关系

相比于流程图，与现代程序的运行时更接近的其实还是直接支持堆栈概念的某种Tree结构。通过Tree的嵌套，我们可以隐式的表达goto到某个状态，然后必然会返回到前一状态这一基本运行时结构。游戏领域常见的behavior tree可以看作是通过Tree结构表达逻辑的一种范例。
What is a Behavior Tree? - Opsive​
opsive.com/support/documentation/behavior-designer/what-is-a-behavior-tree/
5. 低代码的后端存储

单从存储的需求上说，后端采用K-V格式按照键值对保存所有数据是最灵活的。因为底层的数据库在逻辑层面就是这么干的！实际上分布式数据库TiDB可以看作是在分布式的TiKV上所建立的一种封装层。

当我们把数据按照KV格式保存之后，我们就拥有了一种灵活性：重新实现并定制所有数据库机制的灵活性。我们在KV存储基础上所干的所有工作只是在实现一个简易版的数据库而已。

理想的情况下，我们可以通过一个ORM引擎来屏蔽对底层存储结构的依赖，即无论它是直接按照数据库表存储，或者预留多个通用类型列，抑或采用KV键值对形式存储到纵表中，我们在业务层面都察觉不到这些变化。ORM引擎在概念层面所提供的是一种面向业务的虚拟数据库。

发布于 2021-12-31 22:53

]]
[[
https://zhuanlan.zhihu.com/p/380251899

canonical
千山万水
我的文章为啥写得这么难看？
11 个月前 · 来自专栏 可逆计算

    本文使用 Zhihu On VSCode 创作并发布

我的文章的阅读量一直不高，阅读完整率基本在20%左右，可以说是相当不讨喜的。根据我个人的分析，有一个很重要的原因（排除语文能力堪忧和论题混乱/没用等等原因）：猛不丁冒出一些似是而非的物理名词，非常劝退。

一些朋友反映我的文章普遍看不下去或者看不懂，而且越是计算机科班的同学，可能这种感觉越强烈，因为我总是偏离大家普遍理解和接受的表述方式和表述内容，很喜欢借助物理学相关的隐喻，使得阅读的时候需要掌控的信息变得更多更含糊了。

造成这个问题的主要原因还是在于我的写作目的：我写作的最核心目标是鼓吹可逆计算理论，确立我对这个理论概念的优先权（目前在搜索引擎中搜索可逆计算关键字，排在前面的已经是我的文章了），所以我缺少为读者着想的念头（当然，我也没有与读者对着干这种反人类的念头）。

我写作的内容不是向读者介绍已有的概念/技术/惯用法等，而是希望传达一种原创的理论，以及引导我到达这一原创理论的一些启发式的思想，它必然涉及到一些非常个人化的理解问题的角度。这些启发式的思想对创作者而言是非常重要的指引，但对于理解具体的技术问题来说可能是无用的，甚至是误导性的。比如（我下面要举的这个例子就是误导性的）狄拉克发现狄拉克方程的时候，他所依据的是个人的有些无厘头的哲学观念：二阶方程不好（所以Klein方程有问题），一阶方程更美丽。他对于正电子的解释是：真空中所有负能级都填满了电子，电子被激发后留下一个空穴，就成为正电子（这真是一个天才的想法，负的负能量=正能量）。但是目前狄拉克的这些想法已经被量子场论所抛弃，在物理上也没有什么真正的意义。

所以
canonical：可逆计算的方法论来源14 赞同 · 8 评论文章

这样的文章对于理解可逆计算理论而言完全是不必要的，特别是熵的概念的种种引申应用对于不熟悉物理学的同学来说可能完全是一种信息干扰，它只是记录了我到达可逆计算理论的一个有意识的寻找过程。

有时，我会写一些个人原创的对已有技术问题的理解方式，比如
canonical：从React Hooks看React的本质91 赞同 · 16 评论文章
canonical：Paxos的魔法学研究报告14 赞同 · 2 评论文章

我所试图表达的不是当前这个具体技术的内容是什么（实际上我也不关心），而是我去理解这个问题的时候的直觉是什么：在完全不依赖任何技术细节的情况下，为什么我觉得这个技术是有价值的/正确的。我希望表达的是一种启发式的观点，而不是对于科学知识的准确传达。

比如，对于Paxos的问题，我一直有个疑问，那就是如果我是Lamport，在什么样的理解下我才可能发现Paxos这个算法。实际上，在我得到时间静止+单调性这个图像之前，我对于Paxos的理解必须借助于证明和算法细节，而不能形成一个直觉上的正确性概念，也不能把Paxos算法和向量时钟、CRDT(Conflict-free Replicated Data Type)数据结构等分布式相关概念建立联系。

正是因为以上写作目标的原因，我对于自己文章的接受度没有什么期待，基本处于一种废物利用的心态。如果有同学觉得有参考价值，欢迎随意截取、转发、转载，也不要求增加原作者引用。
编辑于 2021-06-13 05:21

]]
[[
https://zhuanlan.zhihu.com/p/377740576

canonical
千山万水
从可逆计算看Delta Oriented Programming
27 天前 · 来自专栏 可逆计算

    本文使用 Zhihu On VSCode 创作并发布

多年以前，为了向领导汇报，需要鼓吹一下可逆计算理论的原创性和普适性，所以我做了一点文献调研，查阅了国际软件工程大会(ICSE)历年的文章，发现最接近的理论是1997年出现的Feature Oriented Programming（FOP）[1][2]和2010年左右由德国的教授Schaefer提出的Delta-Oriented Programming（DOP）[3]。可逆计算理论由我在2007年左右提出[4][5][6] ，它的思想来源不是传统的软件工程或者计算机领域，实际上我的学术背景是理论物理学，而且我对于软件工程理论方面的历史成果事前也并不了解，因此在基本原理层面可逆计算与学术界现有的理论并不相同。在本文中，我简单介绍一下可逆计算理论与类似理论之间的区别和联系。
canonical：可逆计算：下一代软件构造理论131 赞同 · 41 评论文章
一. 软件产品线工程与可变性管理

谈到软件工程理论，就绕不开卡内基梅隆大学软件工程研究所（Software Engineering Institute，SEI）。它不仅是理论界的扛把子，而且是理论联系实际的典范（每年CMM认证授权费就收到手软）。自从SEI提出所谓的软件产品线工程理论（Software Product Lines）[7] 之后，学术界的众多理论都经历了一个校正调整的过程，把自身的概念校准到软件产品线的话语体系中来。软件产品线工程是横跨管理和技术领域的综合性理论，试图利用一切可行手段去解决非常宏大的系统级、产品级软件复用问题（远远超越细粒度的组件复用技术）。


reuse-history


软件产品线工程所提出的核心技术问题是所谓的可变性管理。这几乎是一个万能箩筐型的问题。我们在软件开发和演化过程中所遭遇的几乎所有困难都能够很容易的被归因于应对变化的能力不足。经过校准之后FOP将自己定位为软件产品线的某种自然而且高效的实现途径。而后来的DOP将自己解释为对FOP缺陷的改进，同样是实现可变性管理的一种关键技术手段。按照同样的校准逻辑，可逆计算可以看作是对DOP的进一步发展和提升。当然，实际情况是，可逆计算的提出时间要早于DOP，而且它所遵循的是完全不同的思想路线。

根据理论上的分析，可变性管理的真正困难在于如何有效的管控预料之外的（unexpected）变化。如果我们对一个领域非常熟悉，而且领域内的变化方式为有限的几种，那么就可以在关键位置设置几个恰到好处的扩展点，举重若轻的解决可变性问题。但如果变化的可能位置不断增加，变化的方式不断翻新花样（换句话说，也就是变化的自由度不断增加，直至趋于无穷），那么迟早这种变化的自由度会超越手工枚举能够管控的范围。在这种充满未知的演化图景下，我们如何实现对无限多的变化自由度的有效描述和管控？在物理学中，这实际上属于一个已经被解决了的问题。

在高中阶段我们所学习的牛顿物理学是所谓古典力学中的刚体力学。它的世界观是完全机械化的：刚体的运动完全由它的质心坐标和尺寸形状朝向等少数几个参数来描述，刚体的内部构造无法被观测也无关紧要，刚体之间通过直接接触发生相互作用，刚体的形状必须精确匹配才能构成一个无缝的整体（可以对比一下软件组件的黑箱模型）。即使是在古典力学中，稍微高级一点的观点也都会转换到拉格朗日表述或者哈密尔顿表述，它的精神实质是转向场论的世界观。所谓的场（Field），其实就是建立一个无所不在的坐标系，然后在坐标系的每一点上都可以指定一个物理量。场的自由度是无限的，但是通过坐标系它是可描述的、可定义的、可研究的，在坐标系的每一点上我们都可以精确的度量局部的变化。基于同样的精神，可逆计算的基本设定是首先建立一个足够精细和通用的领域描述坐标系，在这个坐标系中我们能够做到指哪打哪和打哪指哪（坐标的唯一性）。建立场的观念之后，我们就可以在下一节对FOP和DOP进行一些理论分析了。
二. 从面向特征(FOP)到面向差量(DOP)

面向特征编程，顾名思义，其最核心的概念就是所谓的特征（Feature）。那么，什么是特征？按照文献[2] 中的定义

    A feature is a unit of functionality of a software system that satisfies a requirement, represents a design decision, and provides a potential configuration option.


fop


比如按照上面的特征模型，车（Car）必须具有引擎（Engine）这一特征，引擎可以是燃油的或者是电动的，甚至是混动的。而变速箱(Transmission)可以是自动的或者手动的，但不能既是自动的，又是手动的。按照软件产品线工程的设想，具体软件开发类似买车时在配置菜单中打勾做选择（也可以类比于到饭馆点菜），选择指定的特征之后，由生成器负责将它们转换为可执行代码，自动生成可运行的程序。


fosd


FOP最基本的洞见在于特征（我们在业务层面所关注的内容）往往不能很好的和面向对象（组件）或者函数分解结构对齐，而几乎必然会成为一种横切关注点（crosscutting concern）。这其实也很好理解。特征是在问题空间中有价值的、可识别的结构，而组件/函数是在解空间中的有效抽象和描述，从问题空间到解空间的结构映射在一般性的业务环境中都是非平凡的，因此两种描述方式无法有效的对齐。套用人工智能领域的话语，我们可以说：有用的特征都是分布式的（distributed）。

在软件产品线工程中，实现特征定义和组合的一种基本技术手段是类似C语言的预处理机制（条件编译）。


preprocessor


FOP对于软件产品线工程的贡献在于，它提供了更为规范和强大的特征定义和组合机制[8][9]。

    定义语言无关的特征结构树（Feature Structure Tree, FST）通过语言无关的Tree Superimposition来实现特征组合

所谓的FST就是一个通用的树形结构，每个节点具有名称(name)和类型(type)，其中子节点的名称各不相同，从而可以区分开来。Tree Superimposition就是两棵树之间的合并过程，节点按照名称逐级合并，合并节点的类型需要匹配。

    Superimposition is the process of composing software artifacts by merging their corresponding substructures.


fst



compose



superimposition


早期的FOP并没有意识到树结构以及树结构合并算法的通用性，它所采用的是对已有语言进行语法扩展的路数。


fop


Apel在2008-2009年左右发表的一系列工作将FOP推进到一个新的抽象高度。不仅仅限于代码文件，文档、测试用例等等一切相关artifact都可以纳入特征结构树的管辖范围。FeatureHouse通过为EBNF语法规则增加FOP相关标注的方式，允许为任意语法结构引入通用的合并规则（不再需要为FOP引入特定的程序语言），从而极大的扩展了FOP的应用范围。

    FEATUREHOUSE relies on three ingredients:
    (1) a language-independent model of software artifacts
    (2) superimposition as a language-independent composition paradigm
    (3) an artifact language specification based on attribute grammars.


featurehouse


根据上一节的分析，FOP的这一系列做法其实非常容易理解。所谓FST树，就是一种通用的描述坐标系，所有的artifact都必然可以分解到这个坐标系中获得一个唯一的、确定的表示。之所以是树形结构，是因为树结构中任意节点到根节点的路径都是唯一的，因此可以作为坐标来使用。确定坐标之后，坐标点上的合并过程完全是Generic的，与具体的业务逻辑和业务结构完全无关。这一点，在Apel引入的Feature Algebra形式代数[10]中表达的非常清楚。


feature-algebra


如果与AOP做个对比，可以发现一个非常有意思的情况。AOP的pointcut能力非常强大，可以直接使用正则表达式这种复杂算子来实现过滤选择，但是丧失了坐标的唯一性，难以建立Feature Algebra。同时，AOP与程序语言深度绑定，难以扩展到其他artifact层面。所以，强大的表达能力并不是我们所需要追求的全部，可逆计算非常强调可逆性，强大到破坏了可逆性的行为是需要被限制，甚至被禁止的。

FOP的理论看似已经非常完善，但从可逆计算的角度看，它仍然存在很大的发展空间。2010年，Schaefer发现了FOP的一个不足之处，提出了所谓的Delta Oriented Programming（面向差量编程）。Schaefer的发现是

    It is not possible to start from an existing legacy application comprising a larger set of features and to remove features.

如果抛弃所有关于feature的业务解读，直接把它定义为功能的差量(Delta)，立刻就可以发现FOP只包含覆盖和新增操作，没有定义删除操作！DOP最初是引入了一个类Java语法:DeltaJ


deltaj



delta-spl


后来DOP也学习FeatureHouse，引入了DeltaEcore，可以为任意语法引入差量结构。


delta-core


最早的时候，DOP需要包含一个core product，所有的delta作用到core product之后产生最终的产品。但是，按照可逆计算理论，在存在单位元的情况下，差量和全量之间是可以互相转化的。Schaefer很快也发现了这一点，立马又灌了一篇论文[11]，指出不需要core product，仅依赖delta module就可以构建所有系统。

从可逆计算的角度去观察DOP，会发现它仍然存在很大的发展空间，最明显的是它缺少Generator的部分。不过，与可逆计算相比，DOP对于Delta的认知也仍然处于比较初级的程度。taowen前两天提到一篇论文[12]，其中描述了一个与差量有关的技术XVCL，它与DOP也有一些相似的地方。在下一节我将分析一下可逆计算中的差量概念与DOP和XVCL等技术之间的区别。
三. XVCL与Frame Technology

XVCL宣称自己的理论基础源于所谓的Frame technology，而Frame technology宣称自己的概念源于人工智能领域的Frame，而Frame这个概念由Minsky于1975年发明（没办法，为了发论文每个人都得给自己的概念找个体面的祖师爷）。简单的理解起来，Frame就是一个结构模板（architype），其中挖了一些洞，叫做slot，可以被定制，基本上和vue component没多大区别。

    选择一个example X将X内部容易变化的细节部分标记出来，把它转化为frame参数（slot），同时将example X的原始内容作为缺省值（slot的body）（。。。好吧，这就是一个vue组件）


网上有一篇2008年对Frame technology发明人Bassett的访谈[13]，这篇文章还是包含了一些有趣的观点的（基本都是我基于可逆计算理论表达过的观点，这算英雄所见略同，还是历史就是一个loop？）：

    Frame可以有效描述 "A与B很相似，除了..."这种情况，也可以描述 "A与B+C很相似，除了..."这种情况程序员通过拷贝粘贴修改代码即耗费人力，又不可靠，通过frame指令实现对代码的增删改，又快又准Frame可以互相嵌套构成Frame Tree，可以架设在任意语言所表达的结构之上（比如说在自然语言所写的文本文档中增加frame标记就可以实现文档的frame扩展）在Frame的观点下，maintenance不再是与development相互割裂的过程。整个开发的过程和维护的过程一样，都是在外部逐步增加frame差量来实现的（不需要修改原始的frame，在原frame中只需要增加标记）。similar programs often differ by small amounts of code，差异部分可以被局限在frame delta中，一般只有总量的5% - 15%任何领域都有所谓的自然粒度（natural graininess）。具体的实现技术，如类、函数等会将自然的结构拆分的稀碎（比如成百上千很小的类和函数），导致不必要的复杂性Frame基于semi-lattice数学结构，可以处理多重继承问题（基本和scala语言的trait机制类似，通过规定覆盖顺序来避免继承导致的概念冲突）Frame就是一个architype，它可以被看作是一个模糊集合（fuzzy set）的中心元素。与其他抽象技术不同，并不需要事前确保frame的抽象正确无误。如果发现还需要增加变化点，只要在原始frame中增加slot标记就好了（完全兼容此前的代码，也没有任何运行时成本）。

以上观点听起来很神奇，但对应的XVCL实现代码却是朴实无华的。


x-frame


XVCL类似于一种模板语言，其中可以定义变量、判断、循环等。adapt类似于函数调用，可以嵌套调用其他frame。而break标签用于标记一个扩展点，类似vue中的slot标签。因为类似模板语言，所以可以用于生成代码，也可以用于生成文档。例如生成Use Case文档。


x-frame


XVCL与vue组件毕竟是不同的，它提供了某种差量编程的能力：当通过adapt标签来调用其他的frame的时候，可以通过insert-before/insert/insert-after等对定制内容进行较为复杂的控制（adapt的时候insert标签对应部分将修改基础frame中break标签所标记的部分），使用insert empty也可以实现删除缺省内容的效果。


xvcl


相比于C语言的预处理器，XVCL是一种进步，因为它可以应用于任意文本格式的文件，而不仅仅限于特定程序语言（虽然任何模板语言都能干这个），同时XVCL具有更严格的变量作用域规则，并提供了受控的差量定制机制（C语言预处理器无法提供slot定制功能）。

不过，如果按照可逆计算理论的分析框架，XVCL所建立的坐标系统实际上是比FeatureHouse要更弱的： XVCL通过把系统分解为frame，并在frame中增加break标记构造了一个可用于支持定制的坐标系统，但是frame文件之间基本上处于无组织的状态，而FeatureHouse好歹按照目录结构把所有artifact都管理起来，并在每一级目录上都定义了合并算子。frame-break这种两级抽象基本类似于class-member结构，FeatureHouse通过Feature Structure Tree可以毫无压力的模拟frame机制。而DOP相比于XVCL，也提供了更多的feature组合能力。

虽然FOP、DOP和Frame Technology都采用了差量概念，但它们所定义的差量与可逆计算理论中的差量是有着明显区别的：可逆计算指出差量不仅仅是要表达差异，更重要的是它意味着可逆的运算结构，从而可以有效的限制系统的熵增。基于可逆计算进行设计时，引入任何机制都需要进行配对设计（正向与逆向）。在下一节中我将更详细的阐述一下可逆计算的不同之处。
四. 可逆计算有什么不同之处？

在可逆计算的介绍文章[14]中，我首先阐述了一个启发式的观点：可逆计算可以看作是图灵机理论和Lambda演算理论之外实现所谓图灵完备的通用计算的第三条逻辑路径。强调这个观点的目的是为了指出，可逆计算并不是一种简单的程序技巧或者是仅适用于某个领域的设计模式，它是一种具有普适性的计算结构，可以用于各种抽象层面、各种应用领域。可逆计算与物理学中熵的概念息息相关，它所揭示的规律也并不仅仅限于软件应用系统。

可逆计算引入了可逆的差量这一核心概念，明确指出全量= 单位元+差量, 因此全量和差量是可以互相转化的。这一概念的一个基本推论是：全量和差量可以是同构的，应该用同一个schema去约束。这与DOP和XVCL的做法有着很大的区别，在DOP和XVCL中，差量都是以修改动作的形式出现，差量的表达方式与全量的表达方式截然不同，这样的话如何去描述差量的差量？差量与全量同构的情况下，差量的差量仍然是一个普通的差量。很多人将差量的作用看作是 base + patch，认为base是主要的，patch是次要的。但是，实际上base也可以被看作是patch的patch，base与patch之间是对偶关系，在理论上没有必要把它们区别对待。差量具有独立存在的价值，它并不需要依附于base才能够被理解。

在XVCL中，我们需要主动在代码中插入break标签来标记扩展点。但是可逆计算的普适性决定了以下事实：DSL模型既是在坐标系中定义的实体，同时它又构成了坐标系本身。我们没有必要单独为了扩展点在模型中增加额外的描述信息，而只需要采用类似FeatureHouse的做法，在EBNF规则/Schema定义中增加少量标注信息即可。

在FOP中，特征模型特别高层，基本退化为了开关树，难以容纳复杂的领域逻辑，而具体的特性表达手段又特别低层，一般与通用程序语言语法类似，或直接依附于通用程序语言（如Java等），这导致根据特性组合编译为具体产品的过程必然与很多细节知识绑定在一切，难以扩展到复杂的应用场景。这从FOP论文所举的实例多半为玩具项目也可窥见一斑。可逆计算明确了DSL的核心地位，为渐进式的引入领域知识指明了方向。

    DSL与DSL如何无缝融合？DSL的本征结构采用Tree结构描述，但是每一个节点都可以具有不同的表观层文本语法，并且可以关联不同的可视化界面。因此不同的DSL可以无缝嵌套在一起不同的DSL如何共享部分信息，避免出现逻辑冲突？ DSL2 = Generator<DSL1> + Delta, 可以从DSL1模型中反向抽取共享信息，然后通过生成器再传播到DSL2模型中，非共享的部分直接通过Delta机制进行描述即可。

FOP虽然引入了Feature Structure Tree这种通用的树形结构，但是与业内其他主流实践类似，它也陷入到了类型理论的逻辑陷阱中难以自拔。类型理论可以看作是提供了一个两层坐标系统：任何结构都具有一个确定的类型，根据属性名或者方法名我们可以定位到指定的子结构（相当于是一种局部相对坐标）。定制过程也分为两步：1. 根据类型找到对应的对象 2. 打开对象，修改其中的属性或者方法。但是，以类型作为坐标系统，明显是不精确和不完善的。

作为一个坐标系统，最基本的能力是提供如下两个操作

    value = get(path)set(path, value)

所有需要识别的对象在此坐标系中都应该具有唯一的存取坐标。

但是类型的本义是对相同的结构进行归并表达：不同的对象具有相同的类型。这导致使用类型在领域空间中进行唯一定位并不是理所当然的一件事情。最基本的一个问题是，如何定位数组中的某个元素（数组中的元素具有同样的类型）？我们可以使用数组下标来作为数组中的局部坐标，但是这一坐标表示一般情况下是不稳定的。当我们在数组中插入一个元素时，所有后续元素对应的下标都会跟着变化。参考一下虚拟DOM的diff算法的实现，我们就可以发现，有必要为数组中的每个元素规定一个特殊的id属性，用于作为该元素稳定的坐标表示。当然，肯定可以通过对类型系统进行扩展，把这一概念包含到类型定义中，但是如果一个模型对象始终只有一个实例，那么有多大必要将自己局限在类型理论的范畴内讨论问题是很值得存疑的。

FOP的特征结构树对应的是包-类-方法这样的组织层级，当我们需要进行特化处理的时候，必然会导致引入大量不必要的类型。可逆计算按照领域结构进行组织（DSL模型本身可能对应多个层级，而不是类-方法这样两层），在领域结构上明确规定坐标的唯一性，因此结构具有唯一的坐标表示，而生成器相当于是一个映射函数，它将一个对象的坐标表示映射到一个新的坐标表示（类似物理系统在相空间中的演化）。生成器本身也是在同样的坐标系下进行表达的，可以通过同样的动力学过程驱动它的演化。与FOP相比，可逆计算明显具有更好的适应性。

FOP和DOP是学术界对于如何构建复杂系统所进行的有益的理论探索，它们也确实带给我一些新的启发。特别的，我在可逆计算中吸收了特性选择器的观念，允许在任意模型节点上通过feature:on='特性选择表达式'这一标注来决定是否启用特性相关部分，这一处理过程在模型结构解析之前发生，因此是完全通用的机制，与特定DSL模型无关。
五. 可逆计算的开源计划

能坚持看到这里的，估计也没几个人了，握个手吧。如果你对可逆计算确实感兴趣，可能觉得纯理论说得云山雾绕，没多大意思，不如show me the code。这个可以有。我预计在今年年底开源一个可逆计算的参考实现Entropy Platform 2.0，目前正处在代码整理过程中（主要是代码重构以突出可逆计算的理论概念，不过鉴于作者的勤奋程度，也存在很大的可能会跳票到明年上半年）。后端使用java（不依赖spring框架），前端使用vue3.0，第一阶段的开源部分主要包含从模型定义到GraphQL服务这条链路所涉及到的所有技术。计划中主要展示如下内容：

    模型驱动的代码生成：只需输入一个Excel格式的数据模型，即可得到前后端全套可运行代码，可以完成对多主子表数据结构的增删改查操作。渐进式的模型增强：在已生成代码的基础上，可以进行增量式的微调。手工调整代码与自动生成代码相互隔离，互不影响。基于同态映射的可视化设计：代码和可视化模型可以看作是同一逻辑结构的两种同态表示，根据元模型定义自动生成对应的可视化设计器。多版本差量定制：无需修改主程序代码，即可为不同部署版本定制不同的实现逻辑。定制代码以差量形式存放，粒度可以精确到单个函数和单个按钮展现。设计器与应用的协同演化：设计器本身也是模型驱动的产物，它并不是固化的工具。设计器可以针对特定应用进行定制优化，同时随着应用功能演进不断增强。设计器定制逻辑与应用定制完全相同。编译期元编程：通过元模型可以随时定义新的模型，并自动得到对应的解析器、验证器、可视化设计器等。大量的模型构造和转化工作在编译期完成，大幅简化运行期结构，同时可以将同一模型适配到多种运行时引擎上。GraphQL服务、消息服务和批处理服务的统一：无需编程，同一份业务处理逻辑可以发布为在线GraphQL服务，或者消息队列处理服务，或者批处理文件处理任务等，并自动实现批量加载和批量提交优化。模型驱动的自动化测试：无需编写测试代码，在系统调试过程中可以自动录制服务输入输出数据以及数据库更改记录，并实现回放测试。自动化测试引擎会自动识别随机生成的主键和主子表关联等信息，并执行对应校验代码。基于变化检测的即时更新：自动识别模型文件变更，并实现即时重编译。通过FileWatch监视文件变化主动触发重编译。分库分表、多租户、分布式：对于复杂应用场景的内置支持。

后续还将逐步开源IDE插件和WorkflowEngine、 RuleEngine、ReportEngine、JobEngine等运行时引擎，并集成GraalVM虚拟机，基于Truffle框架实现XLang运行时，支持编译为二进制程序等。

项目地址(现在还是空项目)：
https://gitee.com/canonical-entropy
参考

    ^An Overview of Feature-Oriented Software Development http://www.jot.fm/issues/issue_2009_07/column5.pdf^Feature-Oriented Software Development:A Short Tutorial on Feature-Oriented Programming,Virtual Separation of Concerns, and Variability-AwareAnalysis https://www.cs.cmu.edu/~ckaestne/pdf/gttse11.pdf^Delta Oriented Programming https://homepages.dcc.ufmg.br/~figueiredo/disciplinas/lectures/dop_v01.pdf^Witrix架构分析 http://www.blogjava.net/canonical/archive/2007/09/23/147641.html^从编写代码到制造代码 http://www.blogjava.net/canonical/archive/2009/02/15/254784.html^模型驱动的数学原理 http://www.blogjava.net/canonical/archive/2011/02/07/343919.html^Software Product Lines Essentials https://resources.sei.cmu.edu/asset_files/Presentation/2008_017_001_24246.pdf^Superimposition: A Language-Independent Approach to Software Composition https://www.se.cs.uni-saarland.de/publications/docs/MIP-0711.pdf^FEATUREHOUSE: Language-Independent, Automated Software Composition https://www.infosun.fim.uni-passau.de/cl/publications/docs/ICSE2009fh.pdf^An Algebra for Features and Feature Composition https://www.infosun.fim.uni-passau.de/cl/publications/docs/AMAST2008.pdf^Pure Delta-oriented Programming https://www.se.cs.uni-saarland.de/apel/FOSD2010/49-schaefer.pdf^XVCL: a mechanism for handling variants insoftware product lines https://core.ac.uk/download/pdf/82147954.pdf^Frame technology http://www.stephenibaraki.com/cips/v46/bassett.html^可逆计算：下一代软件构造理论 https://zhuanlan.zhihu.com/p/64004026

编辑于 2022-04-24 22:17

]]
[[
https://zhuanlan.zhihu.com/p/344368626

canonical
千山万水
关于"业务逻辑拆分模式:file/dir/repository"的几点讨论
1 年前 · 来自专栏 可逆计算

@陶文 组织了一个微信群"业务逻辑拆分模式撰写组"，在讨论中他提出一个观点

    业务逻辑最终都是要分解成文件，文件夹，git仓库的。那是否应该从这个角度入手：什么东西适合用文件，什么东西适合用文件夹分，什么东西适合用git仓库分呢? 

软件工程的本质是否就体现在这种分解过程中？是否存在一般性的可操作的规则来指导我们进行正确的业务逻辑拆分？在本文中，我想结合可逆计算理论谈谈自己的看法。
一. 树形结构：长程关联

我们可以从信息认知的角度来理解树形结构的作用。当信息匮乏时，我们只能认知到存在的一。当信息逐渐增加时，我们会识别出差异，认识到一分裂为多。如果认知的复杂度进一步增加，我们会识别出差异中的同，经过分组汇聚之后实际上形成一个嵌套结构。

[公式]

所以，树形结构是一种非常自然的认知框架。这个框架的一个令人瞩目的衍生特性在于：树可以有效的表达一种受控的长程关联。也就是说，当在父节点上施加某种控制的时候，我们会在所有子节点以及孙子节点上产生相应的影响，比如在根目录上控制访问权限。同时，节点对自己的父节点以及祖父节点存在确定且唯一的影响途径，比如DOM消息冒泡处理。

树形结构表达了整体和部分的构成关系，它的一个特例是父节点和子节点具有类似的结构，比如目录由子目录和文件构成。当存在这种整体和部分的自相似性时，我们只要掌握少数核心结构即可通过推演来理解系统整体结构。比如，在程序语言理论中，通过递归应用有限的语法规则，即可生成无限多合法的程序语句。这种现象在自然界中是广泛存在的，它被称之为分形（Fractals）。

树形结构的每个节点具有局部可区分的名称，比如文件名，同时它在整个树形结构中存在唯一的路径，这是在全局结构中可用于定位的坐标。比如，对于二叉树，我们可以通过二进制来为每一个节点赋予唯一的编号，例如0表示左分支，1表示右分支，1011表示沿着路径右左右右所到达的节点。

当我们认知世界并对世界施加控制的时候，我们需要一个有效的坐标系统，同时我们也需要一种有效的控制传递手段，所以树形结构就经常成为某种必然的选择。
二. 如果评价拆分方式的优劣？

首先我们需要认识到在给定的情况下，往往是存在多种可选的坐标系的。比如，在平面中我们可以选择无限多的X-Y正交坐标系。从一团乱麻中挣脱出来，我们需要的是一个认知上的切入点，具体从哪里切入不一定那么重要。比如，在不同的X-Y坐标系中，我们都可以建立类似的解析几何方程，并采用统一的代数方法去求解。

对于特定的问题，可能存在着某种最优的表达方式。例如圆这个结构在笛卡尔坐标系下是二维结构，当圆心为坐标中心时，我们可以很明确的识别出上下左右结构的对称性。但是，圆的本质是一维的，只有在极坐标系下我们才可以实现最简的表达。所以，最有效的表达是降维的。当我们进行拆分的时候，我们当然希望是沿着不变的边界进行分离, 例如坐标r保持为常量。但是，往往只有在演化的过程中，我们才能发现变化的脉络。而一个不巧的事实是，只有在时刻t我们才能观测到时刻t-1的演化结果，所以为了实现最有效的拆分，终极的一种需求是把未来的知识以某种方式输运到当下。

对于所有问题所构成的集合，显然不存在什么最优表示方案。在多个树形结构中进行选择时，决策树机制提供了一种评价标准：选择特征使得信息增益最大化（信息不确定性减少的程度最大），简单的说就是切分后减少混杂。但是出于不同的使用目的，我们的关注重点可能是变化的。比如某些情况下我们看重特征B，而另外一些情况下我们看重特征C等。受限制于人的认知能力、历史习惯、环境限制等，往往我们习惯于选择唯一的一种主切分方式，它只能是一种综合妥协的结果。

理想中的结构抽象应该是简单明了的反映领域中的本质关系。但是因为任何一个复杂结构事实上都不是直接构造出来的，而是逐渐生长出来的。生长依附于它所处的生态，并不会凭空的发生，而万物生长的过程又会反作用于生态，导致情况的进一步复杂化。例如，作为一个无神论者，你可能认为宗教是彻头彻尾的谎言，完全无用的痴言妄语。但是，人类社会围绕着宗教建立了庞大的经济、文化、政治体系，大量人类文明的珍宝依托在宗教这个看起来并不靠谱的概念体系之上，而且大部分时候社会运转良好。

到底什么东西适用于文件？什么东西适用于文件夹？什么东西适用于git仓库呢？从完全抽象的角度上说，我们所需要的可能只是一种贯通一致的、在各个层面统一的通用管理手段。但现实是，想要拿来就用的功能只在某些层面存在。比如，我们可能希望权限管控的基本单位是任意目录，但是git不支持啊，当然可以自己搞，但有挺多工作量，还有外围一堆配套工具的问题，还有使用者培训的问题，那还是算了吧。

文件存储是一种静态的表达，或者说是信息的一种序列化形式，它并不是我们知识的全部。比如，分子生物学发现生物的遗传信息本质上由ATGC等少数几个抽象符号构造的DNA序列来保存和传递。但是如果要真正理解这些信息如何起作用，为什么要这样组织，最终我们还是要参考它的运行时结构，发生在不同时空位置的转录、剪切、折叠等等知识。
三. 可逆计算对于拆分的新见解

可逆计算理论提出了一个新的软件构造范式：

App = Biz x-extends Generator<DSL>

本质上，它对应于 Y = F(X) + Delta 这样一种分解模式。
canonical：可逆计算：下一代软件构造理论131 赞同 · 41 评论文章

首先，这是一种生成式系统。我们所表达的DSL信息并不是被直接使用的，而是事后可以通过转换器/生成器进行再解释的。当情况发生变化时，我们可以通过简单的将变化信息通过DSL模型输入到系统中，从而自动传播到系统各处。 大范围的信息传导机制便于实现拆分的局域化。

第二，DSL是对信息的一种结构化表述。在可逆计算的具体实现中，我们不仅仅需要引入结构化表达，同时需要引入对这种结构化表达的一系列处理手段，比如转换、合并、生成等。git在文件级别管理差量更新，而可逆计算需要把这个粒度推进到文件级别以下，同时将整个应用看作是一个完整的树形结构表达，来进行整体结构管控。

第三，Delta差量和自动化的差量合并机制是可逆计算的核心。差量是可逆性的自然结果

[公式]

可以进行差量分解实际上是我们这个世界之所以能够被理解的一个本质原因。在数学上，任何一个解析函数都可以分解为Talyer级数，牛顿力学本质上对应于一阶线性项，而在物理中，我们总可以通过不断的追加二阶项、三阶项来逐步深化对系统的理解。
canonical：可逆计算的方法论来源14 赞同 · 8 评论文章

根据可逆计算的构想，为了有效的控制熵增，我们采用如下两个策略：

1. 尽力保持系统的可逆性

2. 通过Delta差量把不可控的混乱部分分离出主体

可逆性表现为加入系统中的信息需要能够很容易的分离并删除，比如很容易的屏蔽或删除某个特性。在开发阶段它可能表现为版本管理，在部署运维阶段则体现为自动回滚、灰度发布等。可逆性可以成为关注点分离的一种评判标准，同时它也能成为一种系统化的结构构造手段。

大型系统的腐化源于系统结构不断接受各类偶然性需求的冲击，根据热力学第二定律，一个自然发展的系统必然是不断熵增的（除非是不断新陈代谢的耗散系统，比如说不断重写）。但是不能控制熵增，我们仍然可以控制熵增的地点。基于差量机制，我们可以把偶然性需求隔离在某个差量Delta中。在可逆计算的具体实践中，所有逻辑都是可以进行差量定制的，因此在开发完一个产品之后，我们可以在完全不修改主版本代码的情况下，通过存放的差量描述，对主版本逻辑进行细粒度的定制。

在可逆计算的视角下，软件构造不再是从部分到整体的一种逐步组装的部分-整体构成关系，而是一种基于结构运算的转化关系。

      App1 = A + B + C
      App2 = A + B + D = App1 - C + D = App1 + Delta

在完全不拆解App1的情况下，我们可以通过单纯的"追加"操作实现App2的构造。从生产模式上说，可逆计算将传统的"生产即组装"模式改变为更适合抽象逻辑结构构造的“运算即生产”模式。

所以基于可逆计算，我们对于业务逻辑拆分可以多问下面三个问题：可逆否？差量乎？今天你DSL了吗？
编辑于 2021-01-18 15:21

]]

[[
https://zhuanlan.zhihu.com/p/193117183

canonical
千山万水
Paxos的魔法学研究报告
27 天前 · 来自专栏 可逆计算

Paxos算法并不长，写在纸上也仅有短短的四句话。它之所以看起来有些像是微言大义的天书，主要是我们并不清楚这几条简单规则背后的设计意图是什么，为什么它能起作用，不采用这些规则是不是就不行？分布式系统的底色是生的自由、死的随机的一片混沌，矛盾冲突无处不在，但是Paxos算法却偏偏在这一片混沌之上建立了统一一致的共识世界，这看起来宛如神迹。但是，凡人是很难理解神迹的，他无法站在神的高度俯瞰众生，只能凭借自己有限的生活经验去追索揣摩神的意图，最终必然会产生属于凡人的困惑。本文试图从异次元魔法学的角度对Paxos算法做一个解读，建立Paxos算法背后简明的魔法学图像，从而实现我们对这个算法的直观理解。
一. 神的烦恼

首先我们来看一下神所面临的问题，以及他可能的烦恼之处。

假设神需要让一队人马去集体完成同样的事情。他所遇到的第一个问题就是所有人都不靠谱。你向A分配任务，他可能因为神游物外压根没有听见，也可能反应迟钝、磨磨蹭蹭，最过分的是直接中途躺倒，拒绝工作。这个问题相对来说比较好解决，一个人不靠谱无所谓，只要一堆人中有几个靠谱的就行，先进可以带动后进。神只要每次抓住几个骨干，指导他们把事情做好，剩下的人再从骨干那里学习神谕即可。

真正棘手的问题是，总有很多事情在并行的发生。神刚给A分配好工作，正在给B讲解的时候，A的情况又发生了变化（比如接到了别的神的神谕）。神只能屁颠屁颠的跑回A处，给他分配新的神谕。这边A刚搞定，那边B又出新的幺蛾子了，神又忙不迭的拍马赶到。这么搞了几次之后，作为至高无上、全知全能、无远弗届的神，即使脾气再好，他也会忍不住发作的。
二. 九级魔法：时间静止

神是凌驾于一切有限客体之上的最完满的存在，所以他并不会真的遇到上述烦恼。因为，他只要轻轻说一声：定，施展一个九级魔法”时间静止“就可以让这个嘈杂的世界彻底安静下来，然后从容的去做任何他想做的事情。

按照我们这个位面的现代物理学的理解，所谓的时间只是对变化的一种度量。我们通过比较钟摆的周期运动和其他运动的关系来建立时间的概念。如果没有发现任何变化，实际上意味着感知到的时间保持不变。特别的，如果宇宙中所有原子的振荡齐齐的慢了一拍，身处其中的人类是无从发现的。

回顾一下Paxos算法的步骤，Proposer先通过promise步骤，从所有Acceptor处确定一个唯一的ProposalID，然后当发生任何需要识别的事件时，例如接到了新的消息，ProposalID都会自动增加，因此ProposalID实际上就是某种时间的标记。当Acceptor接收到accept消息时，如果发现ProposalID与此前promise时相比没有变化，则可以判定在此过程中时间保持静止，没有任何需要关注的事件发生。

每一个Acceptor都记录了一个只增不减的ProposalID，相当于建立了本地的时间箭头。而整个系统通过ProposalID对齐到同一时间点，相当于是将多个局部的时间箭头对齐后，捆绑为一个粗粒化的、整体性的时间箭头（对齐的前提条件是同样的时间点上发生的事件完全相同，例如设置同样的值）。时间的流逝类似于波阵面扫过整个系统。

所以，从神的视角来看，Paxos算法不过是通过时间静止魔法，强行将多条时间线对齐为唯一的一条主时间线的雕虫小技而已。

这种”停止-对齐“的技术是我们在分布式系统中获得共识的一种基本策略。例如，在kafka消息队列中，同一个消费者分组中的多个消费者是独立行事的，但同时它们必须就如何分配工作达成共识。因此，当消费者分组中的成员增减或者topic结构发生变化时，会触发所谓的再平衡（Rebalance）过程。再平衡过程中，Coordinator首先要求所有worker停止当前的工作，集体切换到下一个世代(epoch)，然后再下发新的分配方案。一个分配方案仅在一个世代中有效。

我们在数据库中常用的乐观锁也是同样的处理策略。刚进入处理程序的时候去读取MainRecord的版本号，然后再修改MainRecord以及相关联的SubRecord，最后在一个事务中批量提交修改，同时尝试更改主记录的版本号。

update MainRecord
  set version = version + 1
  where version = :record_version

如果能够更新成功，说明在整个处理过程中时间静止，没有其他人执行相冲突的动作。
三. 八级魔法：大傀儡术

施展九级魔法是相当消耗魔力的行为。一个具有社会主义核心价值观、勤俭节约的神绝对不会无端的浪费魔力。所以一旦时间静止下来，为了维系分处多地的节点的行为一致，神的最佳选择是施展一个八级魔法”大傀儡术“，将一个节点上的行为复刻到其他所有节点上。

这种复刻源自于神的力量，因此一旦leader发动新的动作，它将穿越千山万水，无视物理阻隔直接降临于远端的follower身上，follower没有反驳的权利，只有执行的自由。不过，俗话说的好，上面动动嘴，下面跑断腿。在我们这样一个低魔世界中，实现大傀儡术并不是一件很轻松的事情，一般通过在发送端和接收端各自增加一个日志文件来实现。

发送端把动作决定写入日志，从而使它成为不可变的神谕。发送组件扫描日志系统，确保将其逐条传达到远端。如果连接不上接收端，或者发送出错，或者发送后没有接收到期待的响应信息，发送组件不能抱怨，不能放弃，唯有努力工作，不断重试，直到接收到成功响应为止，这一过程可以保证至少成功发送一次（At Least Once）。接收端必须无条件接收所有消息，不能拒收，不得篡改。因为有可能多次接收到同一个消息，它必须通过本地日志进行幂等检查，过滤掉所有重复消息，从而实现最多成功处理一次（At Most Once）。如果消息需要通过一个流式处理系统（Stream）进行接力处理，为避免每次从源头开始不断重播，需要中间节点能够通过快照机制把已经完成的处理结果记录下来。

毫无疑问，MultiPaxos和Raft算法都是以上复刻策略的一种具体实现。一旦选主成功，代表任期的Term编号就可以被多次复用，通过同一个Term编号可以发出多条执行指令，只要这些指令通过log index能够区分即可。

如果仔细分析一下，我们会发现，从网络上接收到的消息可以分成两类：一类是请求（Request），接收方可以自由选择相应的处理方式，处理结果也是不确定的，可以成功返回也可以抛出异常。另一类是单向的通知（Notice），它对应的处理方式是固定的，接收方不能有反驳的意见。i

一个有趣的例子是两阶段提交。在Prepare阶段，Participant接收到的是请求消息，因此它可以根据自己的独立意志选择提交或者回滚。一旦Participant将自己可能的选择返回给Coordinator，它就向Coordinator让渡了自身的自主权，许诺今后只接收通知消息，将行为与Coordinator保持一致。当Coordinator决定提交时，Participant绝不会选择回滚。同样的，Participant如果回滚，我们知道Coordinator的选择也只能是回滚。它们两者的选择不再是独立的做出，而是纠缠在了一起。

如果我们单独看待各个Participant和Coordinator，它们各自都可能随机的处于提交和回滚两种状态。但是如果我们把它们作为整体来看待，我们会发现并不是所有状态都是可能的，只有|提交，提交>和|回滚，回滚>是整个状态空间中允许的状态，也就是说2PC运行的过程中，整个系统实际处在|提交，提交>和|回滚，回滚>所构成的量子纠缠态中！

基于上面的考虑，在我们这个位面中，量子纠缠不失为实现傀儡术的一种可行机制。
四. 魔法学的秘奥：看不见的即不存在

作为一介凡人，我们并没有魔力去驱动魔法。但是我们都看过魔术，也都经历过所谓”见证奇迹的时刻“。奇迹的诞生源于魔术师引导我们只去观察显露出来的事实，under the hood的秘密则是不足为外人道也。魔法作为魔术的加强版，本质上的原理也是类似的：只要确保所有不符合魔法学原理的事实都从我们的认知中删除就好了！

Paxos算法运行起来之后，我们试图让时间静止下来，但是恼人的干扰信息总是不停出现。Acceptor有可能会接收到来自过去的消息（ProposalID小于当前值），Paxos算法的解决方案就是假装没看见，直接扔掉！另一方面，Acceptor也有可能会接收到来自未来的消息，最简单的解决方案仍然是直接扔。但是这样的话会产生类似分布式锁的情况，导致容错性不够：在本次时间静止的周期里，有可能Proposer已经挂掉，没法继续完成向Acceptor设值的任务。所以面对当前和未来两个抉择，为稳妥起见，Acceptor只能放弃本次周期已经取得的成果，选择未来的可能性（魔法失败并不丢人，假装没看见，继续下一轮呗）。当然，如果Acceptor已经通过Learner机制知道当前值已经被选定，那就没有必要继续运行下一轮Paxos算法了，可以直接拒掉来自未来的请求。类似的，在Raft协议中，为了避免集群不断重新选举导致振荡，在一定时间内只要通过心跳信息确定Leader仍然存在，则来自未来的RequestVote消息也会被无情的抛弃。

在需要Leader选举的算法中，一个经典的问题是如何避免脑裂？如果新生代的Leader已经得到了人民的拥护，而老一代的Leader却不肯退位，总在那里不停的搅局怎么办？一个一般性的解决方案就是：直接把旧Leader定义为zombie, 彻底忽略来自上一个世代的所有信息（比如拒绝所有epoch较小的请求）。实际上，我们并没有限制旧Leader的行为，在自己的小世界中，它完全可以自以为是的为所欲为，只不过它的行为最终无法上升为集体意志，无法对主世界产生影响而已。新的Leader一继位，需要未读先写，先在主世界中打上自己的epoch标记（类似于更改全局共享变量），这样老的Leader在提交计算结果的时候通过乐观锁发现自己已经失势，最终只能无奈放弃自己的处理结果。

在我们这个位面的物理学中，随着量子力学的发展，观察或者说测量已经具有了非常独特的理论意义。按照量子场论所描绘的视图，在我们看不见的虚时间中，无数狂野的事物在相互竞争、湮灭，最终反映到现实世界中的只是某种综合运算后的结果而已。透过诡异的量子隧道效应，实际上我们也可以窥见这背后的惊涛骇浪。

掩耳盗铃并不是一个荒唐的笑话，而是在我们这个世界中可以真实运行的法则。如果能有效的制造遮蔽一切的信息茧房，它是可以操纵我们所认知的世界真相的。所以，懂王，一个号称无限接近于神的男人，一直在疯狂的暗示：不检测，新冠肺炎就不存在！作为一个泄漏天机的盗火者，懂王，他真的很懂。
五. 凡人的共识：对称的破缺

神说，众生平等。用数学的语言来解释，就是每个人都没有特殊性，他们是对称的（Symmetric）！一个社会不能只有一种声音，每个人都可以有自己的意见，每一种意见都值得得到同样的尊重，那凭什么最后有一个人的声音被选择出来，盖过所有其他人的声音，最终成为所有人的共识？本质上，这是一个打破平等的过程，数学上称之为对称破缺（Symmetry Broken）。

最基本的一种对称破缺技术是多数派投票。因为一个集合里不可能同时存在两个多数派，所以只要在任意一个时刻（由ProposalID来确定），我们知道多数Acceptor都接受了某个值，我们就说这个值成为了被选定的值（chosen value），共识就达成了。
什么时候达成的共识？

当共识出现的时候，参与者中有谁知道已经达成了共识吗？一个有趣的事实是，当共识达成的那一刹那，系统中所有的参与者，包括Acceptor和Proposer，没有任何人知道共识已经达成！只不过，随着时间的推移，算法的运行会把共识已经达成这一事实逐步的揭示出来。

考虑有5个Acceptor，多个Proposer的情况。在ProposalID=t1的时候，提案P1被A1和A2接受，但是没有达到多数派，因此在这一轮处理中值并没有被确定下来。ProposalID=t2的提案P2同样没有达到多数派。ProposalID=t3的提案P3被多数派A2、A3、A4接受，从而达成共识。

首先，我们注意到当共识没有达成之前，Acceptor是有可能改变自己接受的值的，例如A3先接受了P2，后面又接受了P3。因为Proposer随时有可能失联，所以Acceptor只能选择接受新的值。这导致当A3接受P3的时候，它不可能知道共识已经达成，P3就是最终选定的值。同样的道理，A2和A4也只知道自己局部的情况，无从判断系统整体是否已经达成共识。而在Proposer一端，在接收到多数派Acceptor的成功响应之前，它也不知道自己提交的P3能否被多数Acceptor接受，成为最终的共识。所以说共识是属于整体的，单个参与者对于共识是否达成需要有一个理解的过程。
已经达成的共识能否被推翻？

在上一节的例子中，当ProposalID=t3达成共识之后，有没有可能在t4时刻我们达成一个新的共识P4？这样的话，t3的共识是P3，t4的共识是P4，而t1和t2时刻没有达成共识。对神来说，不同的时刻选定不同的值是完全OK的，No Problem，因为神是全知全能的。但是对于鲁钝的凡人而言，如果允许不同的时刻有不同的共识，他会出现认知障碍。

假如允许共识被推翻，一个只有有限认知能力的凡人，他怎么知道哪个值才是要用的值呢？很多时刻根本没有达成共识（例如t1和t2），他要从t1到tn遍历所有的时刻来获知所有共识的值吗？

现在，考虑上图中的情况。假设A3在处理P3的时候直接宕机了。从外部看来，存在两种情况：

    A3已经接受P3，所以达成了共识A3还没有接受P3, 所以尚未达成共识

除了A3自己之外，没有任何人知道它的处理情况。但是，A3已经挂掉了，它不能回答任何问题！所以，如果不同的时刻可能有不同的共识，那么我们有可能会陷入一个尴尬的境地，那就是历史结果完全处于一种量子不确定状态，无法简单的回答是或者否。

对于凡人而言，最理想的选择是系统具有某种单调性：它只会向着一个方向不断迈进，而且一旦到达目标状态，就永远禁锢于该状态中。这样的话，任何时候我们想从系统中提取信息，都可以直接将系统向前推进一步。如果系统已经达成共识，则继续前进一步得到的仍然是共识的值，如果没有达成共识，则我们将实际选定一个值，从而摆脱不确定的状态。例如，在上面的例子中，我们继续运行一步Paxos算法，无论t3时A3做出何种选择，我们一定会在t4得到P3的结果，从而在t4之后消除了系统中的不确定性。在郁白的文章中，这也称为最大提交原则。

注意，我们有可能因为多运行一趟Paxos算法，从而把系统从原本不确定的状态带到了确定状态。这就类似于量子系统，你观察一下它，它的状态就塌缩为某个本征态。如果此前它已经处于本征态，则观察行为不改变系统的状态。
如果确保共识保持不变？

共识是在主世界的主时间线上存在的知识。根据现代魔法学的研究，时间线的两个不同点上的知识是完全独立的！如果我们希望给这两个点上的知识建立关系，那必须引入某种”联络“机制，使得信息可以从一个时间点传递到另一个时间点。

首先我们知道所有主时间线上的事实肯定能按照发生的”时间点“排序，而共识是在主时间线的某个时间点上发生的写入。那么保持共识一致的最简单的方案就是，未写先读，写入之前先偷看一眼前面的情况。

在t4写入的时候如果能够偷偷看一眼t3的结果，直接使用t3的结果作为t4写入的值不就可以确保一致了吗？

在九级魔法的加持下，只需神念一动，即可在主时间线的任意一点完成读-处理-写这样一个复合的原子事件。主时间线上的事件可以分解对应到下级小世界中的事件。西游记中曾经记载：天上一日，人间一年。所以主世界的一点就映射为小世界中的一个区间了（小世界中如果有一个本地时钟，它会发现起始-处理-结束是一个较长的过程，而不是一个时间静止的点）。这种映射是保持了事件的原子性和相对位置关系的。例如，在上图中，A5的t4和t3都是不可分的，它们不会交叉。如果t3和t4交叉了，说明时间静止的区间内发生了意料之外的事情，这与时间静止的假定相矛盾。t4一定处于t3的后面，而且不会与t3相交，因此它一定可以看到t3的结果。

Paxos算法在第一阶段会收集多数派Acceptor上已经接受的值。

    如果共识已经达成，则第一阶段一定会返回这个共识的值，而且它一定是ProposalID最大的那个值。证明：如果t3时刻达成了共识，则紧随其后的t4一定看到了t3的结果，按照规则，它的值一定是共识的值。所以如果ProposalID最大的值不是共识的值，则表示在它之前不可能已经达成共识。
    如果共识尚未达成，则Proposer可以自由选择自己心仪的值，所以他主动成全别人，选择ProposalID最大的那个值也是完全允许的。

也许有些人会感到奇怪，Proposer提交别人的值，那他自己的值怎么办？请注意，Paxos算法的目的是实现共识，并不是为了满足个人的私欲，将自己的值变成共识。其实Proposer发现自己的值无法提交之后，他完全可以放弃后面的工作，并不影响算法的正确性。他主动帮助别人只是加速了系统的收敛过程。如果某个Proposer接收到了所有Acceptor的响应，他经过分析发现尚未达成共识，那么他完全可以选择不支持别人，坚持提交自己的值。互相帮助是人类的美德，这一次帮助别人推波助澜，下一次说不定别人也会帮助自己不是。
六. 不确定性之上的确定性

在凡人的眼中，这个世界充斥着令人心烦意乱的不确定性，每一步行为都产生三种可能的结果：1. 成功，2. 失败 3. 不知道什么结果。曾几何时，孤立的单机系统为我们提供了一种乌托邦式的幻象，世界是二分的，好与坏，成功与失败，光明与黑暗。但是真实的世界让人清醒，在由偶然所主宰的世界中，这种内在的不确定性造就了分布式系统的本质性的困难。

为了在一个偶然的、不确定的世界中奋力求生，我们唯有精诚合作，形成超越个体的集体意识。个体可以消亡，而集体通过新陈代谢实现永生。一个有趣的问题是，多数派（Majority）是否是形成集体意识的唯一选择？显然不是。精神的传承，只需要种子的存在。

来看一个Grid Quorum的例子，

对于上面3*6个Acceptor所组成的一个Grid，我们可以规定只要写入任意一列所构成的Quorum即可认为共识达成。显然，任意两列都是不相交的。为了避免做出自相矛盾的选择，我们需要横向架设一个桥梁，规定Paxos第一阶段读取的时候必须至少读取一行。假设某个时刻共识已经诞生，则下一个共识必然先经过一个行读取再执行一个列写入。因为任意的行和任意的列都是相交的，行读取必然会读到共识的值，因此写入的新值必然是和此前的共识保持一致的。注意到这个例子中的行Quorum与相交的列Quorum都没有达到多数派，而且它们的总元素个数为3+6-1=8个，也没有构成多数派。所以，读取和写入时候的Quorum既不需要相同，也不需要占据多数，只要能够相交，足以传递信息即可。

要超越个体，只需要把个体升华为Quorum中的一员。一个个体可以属于多个Quorum。只要过去和未来所有的Quorum协调一致，不会做出相互冲突的选择，最终我们就可以形成统一的集体意志。
七. 时间的秘密

对于凡人而言，时间是一种神奇的先验存在。似乎我们所有的协调工作本质上都是在利用时间箭头所提供的方向指引。在我们这个位面，牛顿爵士第一个发现，时间切分了因果，时间的左边是因，右边是果，为此他写下了伟大不朽的牛二定律

    F = m* a，因 = 线性系数 * 果

后来，爱因斯坦通过想象发射一个光子去探测周围的世界，不经意间揭示出一个惊天的秘密：时间线并不是唯一的！

如果时间线不唯一，我们该如何避免迷失方向？一个选择是，记住所有的时间线，这形成了所谓的向量时钟（Vector Clock）技术。而如果我们选择将所有的时间线对齐为唯一的一个，就成为了Paxos算法。

我们还有其他的选择吗？想象一下，如果可以彻底摆脱因果的枷锁，在时间线上自由的穿梭，无所谓过去，也无所谓未来，那是何等的拉风。因在左，果在右，为什么不能颠倒过来？本质上这是因为系统不满足交换律，当左右颠倒的时候得不到同样的结果。只有在一个高魔的世界中，无所谓左右，无所谓前后，在那里才可以施展真正的十级魔法：逆乱因果。CRDT数据结构了解一下？
八. 结语

人神之分，在于神域。神域之中，言出法随。制定规则，是神的起点，而谦卑的接纳规则、并狡诈的利用规则则是人之本质。

凡人中的一小撮人，名为程序员，自诩程序世界的伪神，总是试图僭越这一道鸿沟。但只有真正模拟过神的行为，人才能真正认识到自身的局限性和神的伟大。为什么发送了消息能接收到回应？因为所有的服务器都存放在地球上，它们之间距离有限。为什么可以通过本地时钟决定Lease租期？因为所有的服务器都存放在地球上，所处的引力场相近，本地时钟具有可比性。站在人的尺度上，我们是无法想象如何才能穿越大半个银河去实现共识的。

最后，让我们再次聆听一下神的意旨：

神说：要有时间

神说：时间静止

神说：大千世界

神说：亿万分身

神说：薪火相传
编辑于 2022-04-24 22:17

]]
[[
https://zhuanlan.zhihu.com/p/64800798

canonical
千山万水
从React Hooks看React的本质
27 天前 · 来自专栏 可逆计算

后jQuery时代的前端革命是由AngularJs发起的，它最初的一个想法是将后台的技术架构复制到前台来。后端的一个核心技术是所谓的模板技术(template)。它可以用一个公式来描述

html = template(vars)

这是一个特别直观的想法：模板就是一个普通函数，它根据传入的变量信息（无特殊要求）拼接得到字符串（无特殊结构）。这一模型完全不需要考虑面向对象传统的状态分散管理的问题，基本上是一种函数式的解决方案。

React的模式相当于是对模板渲染模型的一个面向领域结构的改进

vdom = render(viewModel)

vdom是面向浏览器的领域模型，而viewModel是基于业务领域概念所建立的页面显示模型，render相当于是两个模型世界之间的传送门。

传统上我们编程时是必须要知道界面模型的。我们所依赖的基础设施是浏览器内置的DOM结构和事件bubble机制，总是监听在DOM节点上，总是拿到具体的控件，然后从控件上拉取我们所需要的数据。而在React的模式下，我们首先在JS中建立模型，这个模型包含具体的领域知识，在领域内部的操作是更加直接的，而且可以利用程序语言所提供的各种抽象手段。典型的，在jQuery时代我们需要频繁的使用$el.find(".title")这种形式去动态查找到所需的元素，而在js模型中我们一般通过this.title属性即可直接定位到所需要的数据。实际上我们对于弱耦合的事件机制的依赖是大大下降了的，特别是我们一般不再需要业务含义不明确的事件bubble处理。redux和vuex从某种意义上可以看作是面向领域的消息总线，它们一般都是直接派发到具体的监听器，而且这些监听器的入口函数不再是某种通用的、与业务无关的Event对象，而是具体的领域状态对象state和业务参数param。

在新的范式下，viewModel的构造和管理成为一个独立的问题。而界面组件之间也不再直接交互，它们之间的关联通过共同依赖的js对象来得到隐式的表达。

control <--> js <--> control

如果我们改写一下形式，可以把React的本质看得更清楚一些：

viewModel => vdom

render函数可以看作是从viewModel上拉取领域数据，传送到vdom世界的一种信息管道。

但是我们知道，前端与后端有一个本质性的不同：前端是讲究交互性的，而后端强调的只是单向执行。因此，我们需要一个新的概念reactive，利用这个概念可以把上面的公式改写为

(props, @reactive state) => vdom

render函数是一种好不容易建立起来的信息管道，如果使用一次就随手丢弃，那实在是太浪费了，何不反复利用？通过引入具备响应性的状态变量，规定一个全局的响应式规则：“无论什么原因导致state变化，自动触发局部的render函数重新执行”，就可以使得render函数得到成功的升华，完美的将微观的交互性嵌入到了宏观的信息流场景中。

React兜兜转转很多年，一直没有能够找到最契合以上公式的技术表达形式，其本质原因还是在于受到了面向对象思想的束缚，总是意图带着面向对象的尾巴。直到Hooks机制横空出世，彻底和历史决裂，我们才看到了React本来就应该具有的面目：

import React, { useState, useEffect } from 'react';

function FriendStatus(props) {
  const [isOnline, setIsOnline] = useState(null);

  useEffect(() => {
    function handleStatusChange(status) {
      setIsOnline(status.isOnline);
    }

    ChatAPI.subscribeToFriendStatus(props.friend.id, handleStatusChange);

    // 返回一个函数来进行额外的清理工作:
    return function cleanup() {
      ChatAPI.unsubscribeFromFriendStatus(props.friend.id, handleStatusChange);
    };
  });

  if (isOnline === null) {
    return 'Loading...';
  }
  return isOnline ? 'Online' : 'Offline';
}

为什么Hooks需要限制只能在代码的第一层调用 Hooks，不能在循环、条件分支或者嵌套函数中调用 Hooks？因为本来它应该写在参数区的，只是因为语法的限制导致它没有专有的位置而已。

现代框架技术的发展仔细回顾起来，其实可以看作是对传统面向对象封装概念的反叛史。面向对象强调先有对象，再有属性和方法，做事之前先拿到this。而现代框架强调的是全局规则，直接表达，为什么无论干什么事都要找个this指针绕一下呢？对比一下React此前的类组件

class FriendStatus extends React.Component {
  constructor(props) {
    super(props);
    this.state = { isOnline: null };
    this.handleStatusChange = this.handleStatusChange.bind(this);
  }

  componentDidMount() {
    ChatAPI.subscribeToFriendStatus(
      this.props.friend.id,
      this.handleStatusChange
    );
  }

  componentWillUnmount() {
    ChatAPI.unsubscribeFromFriendStatus(
      this.props.friend.id,
      this.handleStatusChange
    );
  }

  handleStatusChange(status) {
    this.setState({
      isOnline: status.isOnline
    });
  }

  render() {
    if (this.state.isOnline === null) {
      return 'Loading...';
    }
    return this.state.isOnline ? 'Online' : 'Offline';
  }
}

真正的核心函数是render, 其他的都是外围支持性函数，这些函数之间通过this指针间接进行交互。仔细琢磨一下，我们不禁会有个疑问，所谓的生命周期函数为什么要从属于组件对象，它是局限于某个对象的知识吗？难道它的触发时刻不是一种全局知识吗？useEffect函数深刻理解了这一点，它成为一个静态函数，直接钩挂到全局执行引擎中，通过函数闭包直接实现多个生命周期回调函数之间的信息传递，而不是必须要造出某个this指针来随身携带。

长期以来，面向对象语言中存在三种标准的信息传递方式，参数（param）、全局变量（global）和成员变量（this），但是当面对复杂的领域模型时，我们经常需要表达某个局部范围内的隐含的背景知识，这是一种自定义的、与领域紧密相关的上下文变量（context），不应该显式传递。因此，数据驱动的核心公式可以被改进为

   (props, @reactive state, @implicit context) => vdom

React Hooks中为implicit context这个概念也找到了一个对应的技术形式，把上下文定位方式确定为根据类型进行查找，相当于是某种import implicit机制。

const user = useContext(CurrentUser);
const notifications = useContext(Notifications);

React Hooks机制的出现意味着面向对象组件会衰落下去吗？我想也不尽然。传统的力量是强大的，而有生命力的文化总是具有包容性的。我们在Hooks概念之前在Vue技术体系中就已经通过元编程大法解决了相应问题：在编译期声明在一起的代码块，可以通过元编程机制拆分后挂接到组件对象上的各种插槽上。作为一种运行时，面向对象完全没有任何问题。
编辑于 2022-04-24 22:16

]]
[[
https://zhuanlan.zhihu.com/p/163852896

canonical
千山万水
可逆计算的技术实现
26 天前 · 来自专栏 可逆计算

最近和一些朋友交流Low Code平台的开发经验，发现大多数工作都是由前端架构师主导的，主要精力集中在可视化界面设计器方面，这与可逆计算的理论有着很大的区别。
canonical：可逆计算：下一代软件构造理论131 赞同 · 41 评论文章

维特根斯坦有一句名言：语言的边界就是我们世界的边界。语言之外的世界是一片黑暗，难以感知且不可言说。当我们专注于通过类型（Type），函数（Function），类（Class），属性（Property）等等这样的术语去描绘我们以为的世界的时候，一些必然的事实就会被自然的遮蔽起来，成为我们视野之外的偶然。我的学术背景是理论物理学，所以可逆计算的思想来源不是传统的计算机科学，而是数学和物理学，所以我在软件构造中所想要强调的不是类型系统，不是函数式，不是对象化，而是结构（Structure）、复杂性（Complexity）和源起于物理世界的规律（Law）。
canonical：可逆计算的方法论来源14 赞同 · 8 评论文章

下面我简单介绍一下可逆计算的一些具体的技术实现方案，希望能让这些抽象的概念变得更加直观可见。
一. Tree: 以结构的名义

类（Class）是面向对象程序语言中的核心元素，它所参与的一个主要运算过程就是继承。抛去所有具体的语法形式，类在结构层面上可以看作是一组属性和方法的命名集合（可以通过名称定位到具体的属性和方法），类的继承则是定义在集合层面上的一种覆盖关系。

Map = Map extends Map

上面的表达式中，第二个Map实际上是一个差量定义，在传统的程序语言中，一般我们并不认为它能够独立存在（多重继承会导致一些本质性困难）。Scala语言打破了这一限制，将类的差量明确定义为所谓的trait，号称是提供了内置在程序语言内部的IoC（Inversion of Control）机制。

Map = Map with Map with Map

C++模板元编程可以看作是动态生成基类的一种机制

Map = Map extends MapGenerator<Map>

传统的程序语言中，单一的类是无法承载完整的业务语义的。我们总是把业务描述分解到众多的类中，再通过它们的组合来共同完成业务描述。但是，可逆计算的目标是解决更大粒度的软件逻辑复用的问题，它所需要建模的范围大大超越了类和组件的层面，因此它的选择是沿着复杂性的级列向上走一级，在Tree结构层面实现以上的分解/合并/生成逻辑（类似于从平面几何走向n维空间）

Tree = Tree x-extends TreeGenerator<Tree>

所有的程序结构都可以用抽象语法树（AST）来表达，因此上式中的TreeGenerator本质上也是同样的Tree结构。

Tree = Tree x-extends Tree<Tree>

所有的领域模型都可以通过领域特定语言（DSL）来表达，因此模型的本征表示（Representation）其实就是DSL的抽象语法树。

Linux操作系统的设计哲学是一切都是文件，本质上就是采用树形结构来组织所有文件层面的逻辑。Git版本管理工具相当于是以文件作为差量的最小单元把目录树管理起来。有些聪明的家伙会想到利用Git的多分支管理来实现应用逻辑的差量管理，例如将自动生成的代码保存在auto分支，开发人员所使用的dev分支和auto分支合并最终产生master分支等。这种做法的问题在于文件以下的结构并没有被纳入到Git的管理范围，而Git对文件的认知是基于文本行（Line）模型的，无法准确识别出程序结构的边界，因此文件内的合并需要程序员手工进行。

可逆计算的世界观是超越了系统、目录、文件、程序语言、类等等这些具体的软件结构概念的，它指出当我们在结构层面统一看待所有这一切时，我们会到达一个通用的结构构造范式

App = Biz x-extends Generator<DSL>

在可逆计算的具体技术实现中，是将整个分布式应用看作是一个Tree结构，并在其上执行抽象的结构运算。
二. x-extends: 类型之外的世界

类型理论是计算机理论科学中的明珠之一，它的晦涩难懂似乎不是它的缺点，反而彰显了某种数学的神圣性。而在实践中，类型系统确实也展现出了人力难以企及的穿透一切的上帝视角的威力。现代编程技术从类型理论汲取了充分的营养，大量的程序结构概念都是围绕着类型层面定义的，范型也已经成为了成熟编程语言的标配。

但是，当可逆计算试图在差量概念的基础上重建所有结构的时候，我们发现类型对于差量运算而言是不充分的。例如，传统上，类的扩展是在类型层面定义的，我们无法直接通过类继承来表达领域结构的差量运算。

class BasePage{
      Title title;
      List<Button> buttons;
      Body body;
   }

   class MyPage extends BasePage{
      // 如何定制基础页面中的某个指定按钮？
      // 如何打开Body类，为其增加新的元素？

      // 程序语言本身并没有提供直接的描述式机制
   }

一些应用层的框架会定义某种领域特定的扩展机制，但是这种定义一般是AdHoc方式的，缺乏统一的概念基础，也存在着种种限制。例如，Spring配置文件中允许通过parent属性设置来继承已有的配置项

<bean id="myBean" parent="BaseBean">
     <!-- 新增或者覆盖myAttr属性的配置 --->
     <property name="myAttr">
         如果myAttr是一个复杂属性，这里不想整体替换，只想进行局部修正怎么办？
     </property>

     <property name=“myList”>
       <list>
          如果不想整体覆盖整个List, 只想更新List中的某个元素怎么办？
       </list>
     </property>
  </bean>

可逆计算中的差量合并算子x-extends定义在实例层面，它的语义也不同于普通的类继承，不仅仅是简单的replace，而是至少可以具有merge/replace/remove三种选择。 1. remove表示删除对应结构 2. replace和普通的继承类似，表示覆盖基础结构中的对应部分 3. merge表示按照Tree结构逐级进行合并，合并规则：按名称递归合并，对于列表，则根据元素上的某个key值来定位合并。每一级都可以通过单独的x-override属性来精确控制合并行为。

可逆计算引入了三个基本语法元素x:extends, x:override, x:key，它们可以应用到任意的Tree结构上。例如基于百度的AMIS框架（一个采用json格式的前端界面框架），我们为它增加了如下扩展，用于实现复杂界面的分解/合并/扩展定制。

// page_crud.jon
   {
     "x:extends":"pages/xxx/_gen/_page_crud.json",
     "buttonBar":[{
         "x:key":"add",
         "x:override":"remove" // 删除已有的部分
     },{
         "x:key":"newButton"
         新增的按钮
     }]
   }

_page_crud.json是根据元数据自动生成的增删改查界面，它的内部也通过x:extends来引入新增/修改等表单页面。所有_gen目录下的文件都是自动生成的文件，每次生成都会被全量覆盖，而page_crud.json则表达了在自动生成代码基础上所做的差量修改。

实际实现过程中，XLang所定义的机制要比上面复杂一些，它为x:override提供了更多的选项，同时增加了x:abstract, x:default-override等反向控制机制。
三. 三明治架构

在应用可逆计算时，一般情况下，我们采用的是“三明治架构”

Model = Customization x-extends Generated x-extends Defaults

Defaults用于引入基础环境和全局的编译期变换规则，而Generated为编译期自动生成的部分，Customization为手工进行的增量修改。

因为差量计算是可逆的，所以我们可以反向求解出

Customization = Model x-diff (Generated x-extends Defaults)

这意味着通过可视化设计器对Model进行设计修改之后，我们可以将人工修改部分以差量文件的形式保存下来。显然，这一能力适用于任意设计器。
四. 对象之下，结构之上

在传统的编程思维中，我们思考的起点就是类和对象。对象是对一组状态和行为的封装，在做任何有意义的事情之前，我们首先要获取到对象，然后才能组合调用对象上的方法。

但是，在可逆计算的视角下，在五色斑斓的对象层之下存在着统一的、厚重的结构层。很大一部分逻辑处理并不需要被呈现到明确定义了类型和领域约束的对象层之上，而在结构层即可定义统一的运算规则。

举个例子，GraphQL语法中定义了extend type语法，可以打开一个已经定义的类型，为其增加新的属性等。

type User{
     name: String
   }

   extend type User{
      roles: [Role]
   }

在graphql-java的实现中，对于类型的合并是这么处理的： 1. 先解析得到ObjectTypeDefinition和ObjectTypeExtensionDefintion对象 2. 然后再通过编程把它们合并为GraphQLObjectType对象

而在可逆计算的实现中，合并是在结构层通过统一的算法直接完成的。无论是ORM实体定义的差量合并，还是Workflow的差量合并，或者是GraphQL访问模型的差量合并，它们都由同一个XModelLoader根据XDefinition定义（类似JSON Schema）来统一处理。我们并不需要那么多的Loader/Builder/Differ！

再举一个例子，Spring中提供了所谓的Profile机制，可以通过开关来控制一组配置是否启用。

<beans profile="dev">
    <jdbc:embedded-database id="dataSource" type="H2">
      <jdbc:script location="classpath:schema.sql" />
      <jdbc:script location="classpath:dev-data.sql" />
    </jdbc:embedded-database>
  </beans>

为了支持这一机制，spring需要在核心的解析器中增加额外的处理逻辑，一边处理bean的解析，一边检查profile的配置。

但是，在可逆计算的实现中，底层的XLang为所有模型元素都增加了feature控制开关。

<beans feature:on="a and b or !c">
     ...
   </beans>

这种开关控制可以作用于任意Tree结构节点，它是完全与领域模型无关的，不受领域语义的限制。而与之相反，Spring的profile开关仅在bean的层面起作用，无法控制单个属性的可选配置。

再以可视化设计器为例，无论是业务逻辑设计器还是界面布局设计器，本质上最终的结果不都要保存为某种树形结构吗，为什么我们不能从抽象的结构层面去认知可视化设计？这种树形结构中节点的业务含义真的那么重要吗？结构中的组件标签决定了组件的基本显示样式，它的属性控制了具体的显示细节。如果我们已经有了一个很强大的支持拖拉拽的前端界面设计器，为什么不能通过简单的配置文件使得它可以生成指定格式的json文件呢？我们的系统有着很强大的能力，却被禁锢为某个固定的形态，没有一个简单的出口可以使得这种能力得到充分的释放，这就是可逆计算所致力于解决的问题。

基于可逆计算理论，所有的引擎只要做好自己份内的工作就好了，不需要每个引擎都试图自行去解决可扩展性的问题。实际上，我实现Spring1.0语法的IoC引擎只用了不到3000行代码，而在此之上Spring2.0的自定义标签语法可以看作是基于模板引擎免费赠送的（只要将自定义标签展开成1.0语法的配置即可）。
五. 回归数学

有人给了数学家一个壶，问他怎么烧水。数学家回答：1. 将水壶接满水 2. 把壶放到煤气灶上 3. 打开煤气直到烧开。然后，有人又追问，如果水壶里已经有大半壶水了，该怎么烧水？数学家回答：把水倒掉，此问题已划归为前一个问题！嗯，很好很强大，这种奇葩的思路就是我们要学习的所谓的数学思维。

数学的威力源自于它坚定的形式主义。一个数学问题，只要能在形式上划归为已知的数学定理，我们就可以宣称它已经被解决了。但是，传统上应用软件与数学之间的距离似乎已经非常遥远。在数学意义上完全一样的问题，被不同的程序语言，在不同的业务场景下，甚至在同一软件的不同的版本中，被一遍又一遍的重复解决。软件的本质只是一些抽象的逻辑规则，但是当业务逻辑被某个具体的软件所实现之后，它就被锁定到软件当时的技术形态中，比如说不支持更换数据库，不支持高版本的依赖包，不支持相似但是不完全一致的需求的变更等等。注入到系统中的信息被锁定在一定的形式中，无法被反向的从系统中抽取出来，更无法在各个系统之间自由的流动。

可逆计算所试图解决的实际上就是形式转换问题，它并不能解决各个领域特定的本质性问题，但是会极大的缓解领域中的形式锁定问题。

举个例子，一般国内的工作流引擎都会内置所谓的会签步骤（一组人同时需要审批一个文件，全部通过才通过，有人反对则退回），但是本质上，这个步骤在数学上可以被拆解为两个步骤的组合：一个普通步骤和一个join等待步骤。在我设计的工作流引擎中，会签步骤的实现是通过模型文件解析前的一条ast转换规则实现的，核心引擎并不知道所谓会签步骤的概念。

ast:transform是XLang中所定义的类似xslt语法的一种描述式的Tree结构转换语法。它完全不涉及到运行时状态管理的问题，只是负责把一种Tree结构转换为另一种Tree结构。特别的，它可以转换到某种可执行的模板标签结构上，从而自动实现从描述式结构到可执行结构之间的转换。

<ast:transform>
   <!-- 额外插入的标签 -->
   <div>  
      <!-- 自动拷贝属性到标签上 -->
      <ui:Table ast:node=".">
          <columns ast:node="columns">
            ...
          </columns>
      </ui:Table>
   </div>
</ast:transform>

可逆计算的所有操作原则上都是形式变换，因此它可以嫁接到任何可执行引擎上。只要这个引擎能够读取某种可执行的领域描述，那么就可以通过可逆计算实现这一领域描述的解析器/编辑器/验证器等。所以，可逆计算本身是LOP（Language Oriented Programming）的一种实现方式，可以极大降低开发新的领域特定语言的成本，同时促进多种领域特定语言之间的无缝集成。

如果仔细思考一下lambda演算的本质，我们会发现，这种抽象的运算原则上所执行的只是符号的替换。如果我们用具体的字符串去表达符号，lambda演算实际上就是某种字符串拼接技术，因此我们可以说模板标签就是lambda演算的一种实现形式。

    更进一步，Lisp语言的本质就是建立在S-Expression所构成的树形结构的基础之上的，Lisp中的宏所实现的是编译期的同形变换，它与XLang中的cp:run机制本质上是一回事。从回顾的角度上看，也许我可以说XLang是一种形式更加平民化的Lisp？当然，Lisp中没有明确的可逆的思想，缺少专用的针对Tree结构的差量算子和相关的物理解释（虽然用Lisp宏啥都能模拟），在可逆计算的加持下，它可以换一种形态获得新生。Long Live Lisp！

六. 可逆计算的可行性

有些同学看了可逆计算的介绍，开始觉得不错，但转念一想，可能会有疑问，能实现吗？肯定能啊，核心工作量绝对在20万行代码以内（当然了，代码与代码是不一样的，写短短的代码可比写长长的代码难多了）。

我实现可逆计算的基本技术路线如下：

    通过XDefinition（类似JSON schema）定义领域模型结构 IDE插件和在线编辑器读取XDefinition定义之后，实现模型文件的语法检查和提示 XModelLoader根据XDefinition实现模型文件的分解/合并/定制。所有系统内部内置的组件和界面都可以在不修改原模型文件的情况下，通过delta目录下的定制文件进行差量修正。 MetaDesigner根据XDefinition结合XMeta模型所提供的界面控件和布局信息，自动生成模型文件的可视化编辑器，通过XModelDiffer实现差量保存。 模型文件底层的分解合并使用了类似Webpack的依赖跟踪机制，所以只要依赖文件发生变化，解析后的模型会自动重新编译，实现实时更新。代码转换的时候使用了类似SourceMap的源码位置跟踪技术，所以IDE插件在调试嵌入脚本时可以定位到正确的源码位置。通过ast:transform描述实现抽象语法树的结构转换，转换之后可以映射到模板标签直接执行，或者交由具体的Parser去解析。 XModelParser根据XDefinition可以直接解析得到一个具有执行语义的通用模型对象。也可以根据XDefinition生成特殊的模型类和解析器。

目前后端的基本工作我已初步完成，包括实现了XLang/IoC/ORM/Workflow/Report/Job/GraphQL/AutoTest等执行引擎和Idea基础插件。基于统一的机制自动去生成代码，实际每个引擎需要完成的工作量都大大下降了。 前端的工作主要由其他同学完成，因为一些不可控的客观原因，导致目前进展并不顺利（所以事实上，我工作主要是偏后端的，我并不是前端架构师啊）


@徐飞 ，@大王的角 ，还有 华为2012试验室的同学，希望我的介绍能对你们有所启发。华为，加油！
编辑于 2022-04-24 22:17

]]
[[
https://zhuanlan.zhihu.com/p/65449477

canonical
千山万水
写给小白的Monad指北
26 天前 · 来自专栏 可逆计算

    最近公司来了个新同事，他姓白，年纪又很小，我们都叫他小白。小白最近在学习函数式编程，前几天他过来问我一个问题。
    小白：我正规985学校毕业，为什么看了这么多Monad介绍，还是云里雾里的。是这些文章写得的有问题，还是我的理解力有问题？
    我：你学什么专业的？
    小白：高分子。毕业后我在家自学了半年编程。
    我：好吧...
    最后我决定写这篇文章，帮小白搞清楚这个问题。 

什么是Monad？从实用主义的角度上说，Monad就是函数式编程中特有的一种设计模式。为什么是函数式特有的？因为它说的就是函数之间如何组合的问题。
一. 函数

为了研究函数之间如何组合，我们首先需要定义什么是函数。初等数学中的函数，上初中的时候我们就学过，那是定义域到值域之间的一种映射关系。在编程语言中，我们可以通过类型来表示一个变量所能取值的范围，比如Integer表示取值范围为-2^31到2^31-1之间，因此函数就变成了从类型A到类型B的映射，形式上可以写成 f: A -> B。简单的说，编程语言中的函数可以被理解为从符号A到符号B的一个箭头，特别的，箭头本身也可以被看作是一个符号，因此从符号映射到箭头/从箭头映射到符号/从箭头映射到箭头也是一种函数，这就是所谓的高阶函数。

有了高阶函数的概念，我们就可以定义一个变换curry, 它负责将多参数函数化归为单参数函数。这样在理论上我们就只用研究单参数函数了。

function add(x,y){
     return x + y;
  }

   // 多参数函数的第一个参数可以和函数本身相结合，这叫作partial apply，
   // 返回一个新的函数（少了一个参数），而不是具体的值
  function curry_add(x){
     return function(y){
         return x + y;
      }
  }

  add(x,y) == curry_add(x)(y)

  // js内置了bind函数可以实现curry
  add(x,y) == add.bind(null,x)(y)

在数学上，我们可以将curry看作是以下变换（本质上就是把符号重新排列一下再给一个新的解释）

(a,b) -> c = a -> (b -> c) = a -> b -> c

第一个等式对应于curry，而第二个等式是lambda演算领域的一个约定，就是右边的箭头先结合，这样可以少写一个括号(数学家讨厌括号)。

    redux中间件那个看起来有点吓人的形式 store => next => action => { ... } 表达的本质上就是一个多参数函数

函数的基本性质是满足结合律，即(f ∘ g) ∘ h = f ∘ (g ∘ h)。如果不使用符号∘ ，而是写得啰嗦一些，实际函数的复合规律为

compose(compose(f,g),h) == compose(f, compose(g,h))

  // 这里为了和数学定义保持一致，约定了先执行g，再执行f。
  // 在一般的程序语言中，我们可能会觉得从左到右执行看着更顺眼
  function compose(f,g){
    return function(x){
       return f(g(x));
     }
  }

如果写成中缀形式，会看起来和数学的定义更一致一些

(f compose g) compose h = f compose (g  compose h)

    满足结合律意味着可以随意增加或者删除括号，甚至可以不写括号，因为计算结果与局部结合顺序无关。所以数学家们不喜欢不满足结合律的东西，因为不然的话他们要多写很多括号！

一个具体的例子：

function add_1(x){ return x + 1}

  function minus_2(y) { return y - 2}

  function multiply_3(z) { return z * 3}

  var p = compose(compose(add_1, minus_2), multiply_3)

  var q = compose(add_1, compose(minus_2, multiply_3))

  p(x) == q(x)

虽然在JS中，p和q是两个不同的函数对象，但它们在任何值上的运算结果都是相等的，因此在数学的意义上是等价的（一模一样）。

Monad本质上说的就是函数满足结合律这件事情，但它不是简单的说函数满足结合律（这不是明摆着的嘛），而是说某种特殊形式的函数满足结合律，而很多我们编程中常用的运算模式被证实都可以表达成这种特殊的函数形式。

    函数调用本来是一个嵌套关系，但是单参数函数的嵌套调用f(g(h(x))在数学上可以写成一个线性形式 (f ∘ g ∘ h)(x)。其实，这在数学上仅仅是一个符号变换的问题，在数学上只要两种表示法能够建立一一对应规则，则它们就是完全等价的。我们甚至可以随时编造更多的形式，比如 x => h => g => f, 或者 x | h | g |f (类似于Unix Pipe)，或者 $ = h(x); $ = g($) ; $ = f($); 这种形式上的线性化并不需要结合律的支持。

二. Promise

假设我们有如下两个异步调用函数，我们希望把它们复合成一个异步调用：

// String -> Promise<User>
async function getUserById(userId){ ... }

// User -> Promise<Dept>
async function getDeptByUser(user){ ... }

// getDeptByUserId: String -> Promise<Dept>
getDeptByUserId = compose(getDeptByUser, getUserById);

function composeM(f,g){
   return function(x){
       return g(x).then(f);
    }
}

异步调用函数可以通过一个特殊定义的composeM函数复合在一起，而且这种复合满足结合律。需要注意的是，异步调用函数对应于一个特别的函数类型： A -> Promise<B>。
三. List

类型为 A -> List<B>的集合变换函数也满足类似异步调用函数的规律。

// 有些浏览器尚未支持flatMap函数
  Array.prototype.flatMap = function(f){
    var ret = [];
    for(var ary of this.map(f))
         ret = Array.prototype.concat.call(ret,ary);
     return ret;
  }

   // 接收一个值，返回一个列表
  function duplicate(x){
     return [x,x];
  }

  // 接收一个值，把它包装成列表，或者返回一个空列表
  function positive(x){
     return x > 0 ? [x] : [];
  }

  function composeM(f,g){
    return function(x){
       return g(x).flatMap(f);
    }
  }

  var p = composeM(duplicate, positive);
  console.log([1,-1, 2].flatMap(p)) // 输出[1,1,2,2]

四. Monad

有了上面的基本概念，下面就开始数学的表演了。数学是一门只关注“形式”的科学，形式上一样的东西在数学上可以认为是完全等价的，这就是我们常说的“抽象”的威力。按照“数学思维”，异步调用函数和列表变换函数的类型都满足一个特殊的模式

A -> M<B>

如果改成使用小写字母（打字时方便一些），再偷懒省略掉范型符号，就可以把上述类型模式表达为

a -> m b

如果上述类型的函数可以复合，则对应的composeM函数的类型为

(a -> m b) -> (x -> m a) -> (x -> m b)

也就是说 composeM把一个类型为 x -> m a的函数和一个类型为 a -> m b 的函数复合成一个类型为 x -> m b的函数。

m是什么？它就是一个符号，把它替换成Promise就表示异步调用函数，把它替换成List就表示集合变换函数，而如果把它替换成Identity，我们就得到了普通函数！所以，Identity也是Monad, 只不过是一种“平凡”的Monad, 称为Identity Monad。

Identity b == b, 所以  a -> Identity b == a -> b

有了结合律composeM，数学家想做的第一件事就是定义单位元unit, 它是一个对结合律来说透明的家伙

f composeM unit == unit composeM f == f

无论是左结合还是右结合，都相当于是什么也没结合！

根据composeM的类型声明，我们可以确定unit的类型为 a -> m a

// composeM(f, unit) == f
  (a -> m b) -> (a -> m a) -> (a -> m b)

满足这样性质的unit是否一定能存在？对于Monad，它是一定存在的。为什么？因为数学上Monad的定义就是“自函子范畴上的一个幺半群”，而所谓幺半群的定义就是有单位元的半群！

// 对于Promise而言
  function unit(a){
     return Promise.resolve(a);
  }

  // 对于List而言
  function unit(a){
     return [a];
  }

    什么是半群？半群就是满足结合律的一切东西。为什么叫半群？因为它是不完整的“群”。为什么不完整？因为群要求具有单位元、结合律和逆元。Monad不是群，因为它没有要求有逆元。而可逆计算要求定义某种形式的逆元。参见 

canonical：可逆计算：下一代软件构造理论131 赞同 · 41 评论文章

如果我们采用一点“面向对象”的视角，希望突出一下那个看起来拽拽的m a, 则可以抛弃那个未知的x, 假定从m a类型的对象开始，定义一个新的函数bind(其实flatMap是一个更合适的名字)

// bind :: m a -> (a -> m b) -> m b
 function bind(ma, f){
   return composeM(f, ignored => ma)();
 }

bind(ma, f)对于Promise来说就是 ma.then(f), 对于List来说就是 ma.flatMap(f)。

如果采用中缀形式，并且连着应用多个函数，则类似于顺序执行，例如

ma bind f bind g

在概念层面上可以看作是从 ma开始，执行f, 再执行g。

数学是什么？数学是一种不安分，只要给数学一点颜色，它就要开染房！所以给了它一个单位元unit和一个结合律 composeM, 它就开始推导各种显然的和不显然的等价关系了。

上面我们用composeM定义了bind, 反过来，也可以用bind来定义composeM

function composeM(f,g){
     return function(a){
         return g(a).bind(f);
      }
  }

根据composeM的结合律，可以推导出bind的结合律

bind(unit(a), f) == f(a) 
  bind(ma, unit) == ma
  bind(bind(ma, f), g) == bind(ma, a => bind(f(a), g))

  // 翻译到Promise的实现，结合律对应于
  m.then(f).then(g) == m.then(function(x) { return f(x).then(g) } )

  // 翻译到List的实现，结合律对应于
  m.flatMap(f).flatMap(g) == m.flatMap(function(x){ return f(x).flatMap(g) })

利用bind和unit可以定义新的函数join和map

// join :: m (m a) -> m a
   function join(mma){
      return bind(mma, x => x); 
   }

  // map :: (a -> b) -> (m a -> m b)
  function map(f){
     return function(ma){
        return bind(ma, a => unit(f(a));
       }
   }

反过来，可以用join和map来定义bind

function bind(ma, f){
     return join(map(f)(ma))
  }

还可以证明更多的关系，例如：

compose(map(f), map(g)) == map(compose(f, g))
compose(join, map(join)) == compose(join, join)

为了得到上面这一串东西，我们付出的成本是什么？

    定义一个函数类型 a -> m b, 这里a/m/b都是抽象的符号，具体是什么完全无所谓，只要能把一个东西弄成这个形式就行。 定义一个结合律composeM，确定具有如上类型的函数如何结合。 确定一个单位元unit, 它把一个类型a提升为m a, 但是它和任何函数结合都等于什么都没干。

然后我们就有了join/map/bind等等，以及它们之间让人眼花缭乱的衍生关系：你是我的依据，同时我是你的来源。注意，这一切都是免费的。
五. 作为设计模式的Monad

类似于工厂模式/单例模式/状态机模式等对于面向对象语言的作用，Monad是专门适用于函数组合的一种函数式语言的核心设计模式。Monad提供了一种对函数计算过程的通用抽象机制，关键是统一形式，统一操作模式，统一概念集合, 复用代码。

如果采用Monad的概念来改造Promise的实现，则在Java中可能类似如下接口定义

interface Promise<A>{
    <B> Promise<B> flatMap(Function<A, Promise<B>> f);

    static <T> Promise<T> unit(T a) { ... }

    static <A,B,C> Function<A, Promise<C>> compose(Function<B, Promise<C>> f, Function<A, Promise<B>> g){
        return a -> g.apply(a).flatMap(f);
    }

    // 接口根据数学关系提供一个缺省实现，实现类可以提供逻辑上等价的性能优化版本
    default <B> Promise<B> map(Function<A,B> f){
        return flatMap(a -> unit(f.apply(a)));
    }

    default Promise<A> join(Promise<Promise<A>> m){
        return m.flatMap(x -> x);
    }

    ... 其他方法
}

因为这种模式在函数式编程中很常见，一些程序语言会提供语法糖来方便编写，例如Python和Scala语言中的for-comprehension。

for( x <- mx;   y <- my; z <- mz)
  yield x + y + z

会被翻译为

mx.flatMap(function(x){
  return my.flatMap(function(y){
     return mz.flatMap(function(z){
       return unit(x + y + z);
     })
  })
})

最后一个flatMap和unit函数的作用可以被缩减为map调用

mx.flatMap(function(x){
  return my.flatMap(function(y){
     return mz.map(function(z){
       return x + y + z;
     })
  })
})

语法糖只是一种形式上的变换，因此只要一个接口上定义了flatMap和map函数，就可以使用for-comprehension语法糖，甚至它不满足结合律也无所谓！

需要注意一个细节，上式中为了通过闭包传递参数, flatMap是右结合的。一般我们自己写代码的时候，为了减少嵌套调用，我们都是尽量使用左结合的。例如

mx.flatMap(f).flatMap(g) 而不是 mx.flatMap(x -> f(x).flatMap(g))

六. Monad干了什么？

Monad相比于普通的函数复合，关键是引入了一个包装结构m, 相当于是把value包装在一个context中（monadic value = a value in a context)，因此可以实现普通业务逻辑 + 统一环境处理的效果，有些类似AOP的作用。通过将一部分处理逻辑隐藏到环境中，整体调用形式就可以变成简单函数的嵌套调用，再通过形式变换即可实现线性表达形式，并且一般通过通用的for-comprehension语法提供语法糖支持。

参考List Monad， ma.bind(f)的执行逻辑可以分解为4步：

    从包装结构中拆解出value, value的类型是a。有可能存在很多个value，会调用处理函f很多遍。对每个value, 调用函数f, 返回一堆的包装结构，其中值的类型为b。 bind内部拆解出所有类型为b的值，把它们通过某种运算合并在一起（join提供展平机制）。 再次包装为m b返回（unit提供类型提升机制用于创建包装结构）。

七. StateMonad

Monad对于函数式语言还有一个特别的意义，它提供了某种环境封装机制，因此可以把副作用隔离到某个环境对象中，保证函数式语言内在的“纯洁”。具体的做法可以参见下面StateMonad的实现。

假设，我们需要在程序中使用随机数

function addRandom(a){
  return a + Random.nextInt();
}

上面的函数依赖于全局变量Random，因此具有副作用，需要把它改造成通过参数来传递状态变量

 function addRandom(a, random){    return [a + random.nextInt(), random]; }

上面这个做法是一个通用模式。简单的说，为了避免依赖全局变量，我们必须把所有需要用到的状态变量都随身携带！因此我们需要定义的有状态函数的函数类型为

(a, s) -> (b, s)

利用currying， 可以知道它等价于 a -> (s -> (b, s))。也就是说为了封装状态，将简单函数的返回值类型修改为 s -> (b, s)即可将普通函数扩展到支持状态变化的情况。

考虑到Monad需要的函数形式是 a -> m b, 我们必须找到m的定义。这个其实很好办，只要把s -> (b,s)这个形式中所有除了b之外的符号都移动到左边，再给它起个名字叫作m就可以了。 具体做法为， 首先定义 (State s) b = s -> (b, s) , 则有状态函数的类型可以修改为 a -> State s b， 显然 可以用 State s 这两个符号来代表m

注意, State s b 在给定b的情况下对应的是一个函数，它还需要传入s参数，才能得到一个具体的值 (b,s)

有状态函数的复合形式为 ((b,s) -> (c, s)) -> ((a,s) -> (b,s)) -> ((a,s) -> (c,s))

通过符号改写，可以被重新写成 (b -> State s c) -> (a -> State s b) -> (a -> State s c)

注意，上面的变换仅仅只是把符号顺序重新排列了一下，可以想象通过字符串替换就可以直接从一种形式得到另一种形式。

想清楚形式之后，就可以定义bind和unit了。

function unit(a){
   // 返回的是State _ a, 其实就是一个函数
  return function(s){
     return [a, s];
  }
}

function bind(ma, f){
   return function(s){
      var r1 = ma(s); // [a, s1] = ma(s)
      var r2 = f(r1[0])(r1[1]); // [b,s2] = f(a)(s1)
      return r2; // [a和b的某种处理结果, s2];
   }
}

回到随机数的具体例子，我们可以定义

function addRandom(a){
      return function(random){
           return [a + random.nextInt(), random];
        }
    }

function multiplyRandom(a){
      return function(random){
           return [a * random.nextInt(), random];
        }
 }

bind(unit(3), addRandom)(random)最后的效果相当于是 [3 + 随机数, random]。 通过把random这个随机数生成器作为状态不断传递，可以避免依赖全局变量。

bind(unit(3), addRandom)(random)
==   function(random){
      [a, random] = ma(random) // 返回 [3, random]
      [b, random] = addRandom(a)(random) // 返回[3 + random.nextInt(), random]
      return [b, random]
   }(random)

整个操作过程其实就是把直接返回数据改造成返回函数，这个函数具有一个名为state的参数。bind的作用就是把这些函数串起来形成一个新的接收state变量的函数。 bind的实现过程负责把不停传递state变量的过程封装起来，这样从最外层调用者看来，似乎所有地方都不需要传递state参数。

// 看起来像是执行，但实际上仅仅是构造了一个函数f
 f = unit(3) bind addRandom bind multiplyRandom 
 调用 f(random) 才实际执行

StateMonad为什么可以封装副作用？原因在于StateMonad的bind仅仅负责组装函数，它返回的最终还是一个函数，这个函数并没有真的执行！
八. 其他的Monad

Monad实际上是很常见的一种处理模式，例如

    空值判断。比如取值a.b.c，我们一般情况下需要检查对象是否为空

if(a != null){
    if(a.b != null){
         if(a.b.c != null){
              ...
           }
     }
  }

但是kotlin语言中提供一个?机制，使得 a?.b?.c?不用判断是否为null, 如果遇到空值就一直返回null。这类似于OptionMonad。

    延迟加载。ORM引擎通过load(entityId)取到的对象是Proxy对象，只有实际调用它的属性时才会加载对象，如果访问的是关联对象属性，则返回的仍然是Proxy包装对象。

entity.getDept() 相当于是 load(entityProxy, getDept);

  function getDept(entity){
    return buildProxy(entity.deptId)
  }

    Spark的RDD。RDD上提供了map/flatMap/filter等函数。而且spark的执行还利用了结合律，它通过依赖分析，把窄依赖的函数先结合在一起，然后再放到一个Stage中执行。

参考文献

    JavaScript Monads Made SimpleMostly adequate guide to FP (in javascript) 

编辑于 2022-04-24 22:16

]]
[[
https://zhuanlan.zhihu.com/p/64153956

canonical
千山万水
从可逆计算看kustomize
3 年前 · 来自专栏 可逆计算

kustomize是kubernetes最新版（1.14）中力推的声明式配置管理机制。它明确提出了“Customization is reuse”的概念。其核心思想是仿照Docker的设计原理，将配置文件也类似文件系统一样进行分层管理。最底层是一个作为基础的base文件，然后将不同的patch文件覆盖（overlay）到base文件之上就可以得到不同的配置变体（variants），从而实现对基础配置文件的复用。

kustomize所使用的目录结构如下所示：

someapp/
    ├── base/
    │   ├── kustomization.yaml
    │   ├── deployment.yaml
    │   ├── configMap.yaml
    │   └── service.yaml
    └── overlays/
     ├── production/
     │   └── kustomization.yaml
     │   ├── replica_count.yaml
     └── staging/
         ├── kustomization.yaml
         └── cpu_count.yaml

base目录下包含可以被共享的公共配置，someapp/base/kustomization.yaml文件负责将多个yaml文件合并成一个单一配置文件, 相当于是一种类似include的文件分解合并机制。

commonLabels:
  app: hello

resources:
- deployment.yaml
- service.yaml
- configMap.yaml

overlays目录下统一管理所有的定制配置。 例如，可以在someapp/overlays/production/kustomization.yaml中通过patches来对bases进行修正：

commonLabels:
       env: production
      bases:
      - ../../base
      patches:
      - replica_count.yaml

patch文件的格式与普通的k8s配置类似：

apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: the-deployment
      spec:
        replicas: 100

按照阿里公司张磊的说法，“上述PATCH的思想跟Docker镜像是非常相似的“，”PATCH才是声明式API的精髓“。还有人指出“一旦你真正了解了使用叠加层和补丁的模式，它就会开始感觉就像一个你想要在任何地方使用的模式”。

在kustomize出现之前，比较流行的复杂配置管理方式是采用一种模板（template）技术来动态生成配置，例如helm, 这种技术试图将可变的配置部分抽象为参数（Parameter），同样的模板传入不同的参数就可以产生不同的结果。作为一种重用技术，这种原始的参数抽象的方法面临一个基本困难：用户需求难以事先确定，因此很难抽象出稳定的参数集，如果要满足所有需求，则配置文件中的任何一个部分都可能被抽象为参数，结果就失去了抽象存在的意义。

kustomize的核心要点在于，它将patch（差量）看作是可独立存在、独立理解、独立操作的对象，patch的结构与普通的配置文件格式基本一致（实际上可以将普通的配置文件看作是patch的特例）。patch与base之间按照精确定义的合并规则进行合并，base文件不需要事先知道任何patch的知识，不需要事先为未来可能存在的patch做任何准备。当我们心智所关注的重点从base转移为patch时，很多问题的复杂度得到降低，例如base文件和patch文件可以由不同的人员维护，当base文件更新升级时，我们直接管理的patch文件一般情况下并不需要做什么调整（Delta差量并不随base的变化而变化）。这一点恰恰类似Docker相对于虚拟机的革命：我们只需要关心应用切片层，而不再需要直接面对复杂的操作系统基础层。

显然，kustomize中的差量合并机制是符合可逆计算原理的。事实上，早在2007年我就提出了类似kustomize的delta定制机制，可以参见我的博客文章"多版本支持"。


只要稍微留意一下，就会发现近几年来在各个领域都出现了大量Ad hoc的，类似kustomize的配置合并处理过程。例如：Java包管理工具Maven的pom文件也具有类似的继承与合并机制。

<pom>
      <parent>
           <groupId>entropy</groupId>
           <artifactId>entropy-root</artifactId>
           <version>1.0-SNAPSHOT</version>
           <relativePath>../../entropy-platform/entropy-root</relativePath>
      </parent>
      ...
      <!--    这里的配置节点会和继承的配置相合并，不同的子节点具有不同的合并规则 -->
      <build>...</build>
      <dependencies>...</dependencies>
   </pom>

kustomize相比于pom而言，它的进步之处在于定义了delete等操作，因此可以构成一个完备的Patch操作集。同时kustomize允许引入自定义的资源定义并使用同样的机制进行合并，相当于是提供了某种相对通用的机制，而不是完全写死的针对特定结构的固化算法。不过，如果按照可逆计算理论的分析，kustomize仍然缺失一些关键性的概念设计。

delta定制与kustomize的不同之处在于：

    delta定制是一种通用的机制，不仅仅适用于配置文件合并，而是广泛应用于各类结构的动态组织与合并。而kustomize仍然只是针对k8s配置的一种Ad hoc的局部解决方案。
    delta定制包含一个内置的元编程生成机制，因此可以很容易的支持二次抽象。使得最终用户不受限于基础模型的表达能力。k8s配置相当于是提供了某种针对云计算部署的某种领域特定语言，但是当我们在特定业务场景下使用时，仍然有很多业务领域知识可以被抽象复用，而在kustomize当前的机制下是无法封装这些业务领域特定知识的。
    delta定制非常强调可逆性，并积极主动的利用可逆性。其实仔细思考一下就会发现，如果我们可以实现精确的定制，那么必然意味着我们可以精确的定位到领域结构的任何地方，那么也就意味着我们可以取出领域结构任何一处的信息。也就是说，通过领域结构表达的信息是可以被反向抽取出来的。这种可逆性如果能够系统化的被利用，就可能释放出超乎想象的生产力

例如，在满足可逆性的体系中，我们很容易实现同一信息的多种展现形式，可视化设计仅仅是可逆语义的一个简单应用。

[公式]

领域模型采用领域特定语言（DSL）来描述，界面生成器可以理解DSL，从中抽取信息将其转换为可视化界面，同时界面生成器提供了对应的逆向信息提取机制，可以从生成的可视化界面中反向提取出DSL模型信息。所谓的可视化设计不过是模型的两种表现形式（representation）之间的可逆转换而已。

可逆计算基于差量概念建立了一个完整的软件构造理论，它的核心思想来源于物理学和数学，因此具有非常广泛的普适性，具体的理论分析可以参见我此前的文章“可逆计算：下一代软件构造理论”。事实上k8s本身的架构原理也可以在可逆计算理论框架下进行解释：

[公式]
发布于 2019-04-29 00:03

]]
[[
https://zhuanlan.zhihu.com/p/64020543

canonical
千山万水
从可逆计算看JavaScript的编程范式
3 年前 · 来自专栏 可逆计算
为什么JavaScript是世界第一编程语言

​ 根据Stack Overflow最新发布的2019年开发者年度调查报告，JavaScript已经连续第7年蝉联最常用的编程语言。JavaScript无疑是目前受众最广的编程语言，但它是否是世界第一的最好的编程语言？百姓网的架构师贺师俊（网名hax）的回答是“是”，并且针对这个问题做过好几次专题报告，阐述了blabla一大堆理由。我基本同意hax的论断，不过我想从一个稍微不同的角度重新解读一下所谓Modern JavaScript的技术形式。我的观点是JavaScript相比于其他编程语言，它的核心技术方案更接近可逆计算的技术原理，可以将JavaScript的最佳实践看作是可逆计算的一种比较原始的实现形式。

​ 可逆计算是笔者所提出的一种新的软件构造原理，它明确提出应该将“差量”提升为第一性的概念，将全量看作是差量的一种特例（全量=单位元+全量），并围绕差量概念去建立整个领域概念体系。在具体的技术形式上，可逆计算可以用如下公式来概括：

[公式]

也就是说，采用领域特定语言（DSL）来描述领域信息，通过生成器（Generator）对领域信息进行二次加工产生新的结构，然后再通过一个差量（Biz）对生成结果进行补充修正。如果从数学角度来解读，它的本质其实就是 Y=F(X)+△。
一. 原生JavaScript的计算模式

​ 现代JavaScript是一种内置嵌套对象字面量的、支持模块化的、动态弱类型的程序语言。这三点结合在一起，就很自然的可以实现可逆计算所要求的Y=F(X)+△计算模式。下面来看一个简单的例子

// a.js
var A = {
  a: 1,
  b: 2,
  c : {
     d: 3,
     children: [],
   },

  f1(){
     alert("f1 in A")
   }
}

var names = ["f2","f3"]
names.forEach(name => {
   A[name] = function(){
      alert(name + " in A")
   }
})

export default A;

​

// b.js
import A from "./a.js"

var MixinB = {
   b: 3,
   f1(){
     alert("b="+this.b);
   }
}

var B = Object.assign({}, A, MixinB)

B.f1();  // MixinB中的f1方法覆盖了A中的f1
B.f2(); // a.js中动态生成的方法

export default B;

在上面的例子中，最终我们所得到的对象B由导入的A和一个Mixin合并得到。这种计算模式在JS的日常使用中可以说是司空见惯。它有三个明显特征：

    使用对象字面量直接表达很复杂的嵌套结构。 对象字面量对于程序语言的内在表达能力而言至关重要。JSON正是利用了这一点，成功取代XML成为了服务数据交换的事实标准。一般的JS模块中都存在着大量类似对象A和MixinB的声明式结构。模块对象通过动态构建的方式得到。 JS导入模块时并不是一种类似Java的静态符号链接过程，而是隐含的会执行模块代码，这相当于是某种元编程（MetaProgramming）的能力，使得模块可以被动态构建出来。a.js中导出的模块A，它的一部分信息是直接声明得到的，但也有一部分信息是通过代码生成动态构建出来的。使用类似merge的操作对从各个模块得到的信息进行综合。 所有的信息都通过对象结构来表达，复杂的表达必然需要拆解为多个切片，而在动态弱类型语言中，我们可以定义一种通用的合成机制来实现多个切片的综合。因此，在JS中我们会大量使用Object.assign, deepMerge, JQuery.extend等合并算法。

总结起来，原生JS的计算模式可以表达为如下公式：

[公式]
二. Vue的计算模式

相比于原生JS，实现了数据驱动组件模型的Vue框架对于可逆计算的支持明显要更加细致一些。我们还是从三个方面来考察一下Vue框架的情况：

1. 领域信息表达

Vue组件对prop,data, method, watch等概念进行了区分，相当于是把组件对象的构成进行了如下领域特定的分解

[公式]

export default {
     extends: Base,
     mixins: [A,B],

     props: {
      size: Number
      },

     computed: {
      normalizedSize: function () {
        return this.size.trim().toLowerCase()
        }
      },

     methods: {
        hello: function () {
         console.log('hello!')
          }
      },

     watch: {
        size: function(){
             console.log("size changed");
          }
      }
  }

2. 动态构建

Vue组件就是一个普通的JS对象，因此可以使用各种方法来生成。一个比较特别的方法是使用Vuex框架

const store = new Vuex.Store({
     state: {
       count: 0
     },
     mutations: {
       increment (state) {
         state.count++
       }
     }
   })


import {mapState} from 'vuex' 
   
   export default{
       name:'test',
       store: store,
       data(){
         return{}
       },
       computed:{
         ...mapState([    
           "count" // 将this.count 映射为 this.$store.state.count
         ])
       },
       methods: {
       ...mapActions([
         // 将 `this.increment()` 映射为 `this.$store.dispatch('increment')`
         'increment', 
         
         // 将 `this.incrementBy(amount)` 映射为 `this.$store.dispatch('incrementBy', amount)`
         'incrementBy' 
       ])
   }

Vuex相当于是在Vue组件的基础上进一步进行抽象，将Vue组件中与界面无关的核心业务逻辑剥离到独立的Store对象中。或者说，相比于普通的Vue组件，对于描述业务逻辑而言，Store对象是更好的一种领域描述语言，而mapState/mapActions等函数所提供的是根据Store描述来动态生成Vue组件的一种动态构建机制。

3. 合并策略
Vue组件可以通过extend, mixin等多种方法实现合并（但其实其内部实现都是一样的）。

 // 定义一个混入对象
    var myMixin = {
      created: function () {
        this.hello()
      },
      methods: {
        hello: function () {
          console.log('hello from mixin!')
        }
      }
    }
    
    // 定义一个使用混入对象的组件
    var Component = Vue.extend({
      mixins: [myMixin],
      methods: {
         hello2: function(){}
      }
    })

Vue.mixin机制与Object.assign不同，它不是简单的按名称覆盖，而是对Vue组件的不同组分使用不同的合并策略。这些合并策略统一注册在Vue.config.optionMergeStrategies中，甚至我们还可以扩展实现自定义的合并策略。

// Vue框架源码
//  Option overwriting strategies are functions that handle
// how to merge a parent option value and a child option
// value into the final value.
var strats = config.optionMergeStrategies;
...

strats.props =
strats.methods =
strats.inject =
strats.computed = function (
  parentVal,
  childVal,
  vm,
  key
) {
  if (childVal && "development" !== 'production') {
    assertObjectType(key, childVal, vm);
  }
  if (!parentVal) { return childVal }
  var ret = Object.create(null);
  extend(ret, parentVal);
  if (childVal) { extend(ret, childVal); }
  return ret
};
strats.provide = mergeDataOrFn;

// 缺省合并策略为直接覆盖
var defaultStrat = function (parentVal, childVal) {
  return childVal === undefined
    ? parentVal
    : childVal
};

可以用一个公式来总结Vue的计算模式

[公式]
三. Webpack的计算模式

​ Webpack是目前前端开发不可或缺的重量级模块打包工具。作为一个大型工具系统，它的设计思想同样可以基于可逆计算理论进行分析和理解，而且经过分析可以发现，Webpack对于可逆计算的支持相比于小型的Vue框架要更加深入和全面。

​ 在Webpack出现之前，前端开发所使用的所谓工作流工具主要是Gulp/Grunt，这些工具对前端的自动化任务执行流程进行了抽象，可以实现自动刷新页面、转译js、编译less等一系列自动化工作，减少手工操作过程。而Webpack是所谓的模块打包器，它将所有资源文件（css,js,image,vue等）都统一看作是模块（Everything is Module），然后引入所谓Loader概念来装载模块，并分析模块之间的依赖关系，最后利用Plugin来实现各种综合处理过程。

从概念层面上说，Webpack与Gulp/Grunt并不是直接的替代关系，按理说应该是各有自己的生存空间。但是实际情况却是，自从用上Webpack，就基本上没有Gulp/Grunt什么事了。这里面的原因其实很简单，Gulp/Grunt致力于自动化和优化 前端的工作流，而Webpack却是提供了一种新的抽象机制，直接对前端单页应用打包建立了一套领域特定的描述式方案。Webpack所提供的领域模型，比起通用的编程式流程处理，无疑更加简单直接，而且很多全局优化可以在领域模型的指导下进行，从而克服了Gulp/Grunt打包大型单页应用时的诸多问题。

​ 下面对于Webpack， 我们仍然从三个方面来分析一下它所体现的计算模式：

1. 领域信息表达

Webpack彻底超越了JS对象表示形式的限制，直接通过领域特定语言(DSL)来实现领域描述。scss/less是css的扩展，可以看作是样式领域的DSL，而vue是单页面组件的DSL，甚至js文件自身也被看作是添加了ECMAScript最新语法糖的一种新的语言文件，它可以通过babel-loader转化为浏览器可以识别的ES5语法，我们可以自己写babel插件来插入自定义的语法规则。

2. 动态构建

Webpack的Loader机制扩展了JS内置的import语法的语义。现在的import实际返回的是Loader执行的结果

 import App from "./a.vue"
 
将会被转换为 require("./a.vue"), 
然后通过webpack的loader机制，调用vue-loader来加载vue文件，并转换生成对应的js代码  

3. 合并策略

Webpack中所有的综合处理逻辑由各路Plugin负责实现。Plugin可以对所有Loader的装载结果进行统一分析，实现拆分/合并/优化等工作。

​ 整个Webpack的运作原理可以用如下公式来表达（符号⊕表示Plugin所起的综合作用）

[公式]

除了对外提供的打包模型之外，Webpack自身的配置管理也是符合可逆计算原理的。

1. 通过一个很复杂的JS对象来描述WebpackConfig

const webpackConfig = {
  mode: 'production',
  output: {
    path: path.resolve(process.cwd(), './lib'),
    publicPath: '/dist/',
    filename: '[name].js',
    chunkFilename: '[id].js',
    libraryTarget: 'commonjs2'
  },
  module: {
    rules: [
      {
        test: /\.vue$/,
        loader: 'vue-loader',
        options: {
          compilerOptions: {
            preserveWhitespace: false
          }
        }
      },
      ...
    ]
  },
  plugins: [
    new ProgressBarPlugin(),
    new VueLoaderPlugin()
  ]
};

module.exports = webpackConfig;

​ 如果是在Java中实现同样复杂度的配置，需要动用IoC容器、XML对象映射、表达式引擎等一系列重型工具。相比较之下，JS中仅仅需要一句require("webpack.common.js")就全部搞定了，是不是有一种好用到要哭的感觉？

2. 可以通过代码生成WebpackConfig

例如element-ui控件库的构建脚本中，config.js文件动态生成webpack的externals配置

var Components = require('../components.json');
   var externals = {};
   
   Object.keys(Components).forEach(function(key) {
     externals[`element-ui/packages/${key}`] = `element-ui/lib/${key}`;
   });
   
   exports.externals = externals;

3. 合并策略

Webpack内部提供了webpack-merge模块，通过它可以实现多个配置对象之间的“智能”合并。与Vue的合并策略相比，webpackMerge的可定制化程度更高，更灵活，更强大。
四. 可逆从“无”开始

​ 在我看来，未来软件世界的发展必然是一个差量概念逐渐走上前台的过程。反映到程序语言中，它必然要求语言可以直接表达差量，并且内置差量相关的运算操作。而这方面的第一步改造是要跳出历史上的思维定式，不仅仅要表达“有”，还要能够表达“无”。JS在这方面，相对于其他语言还是存在着不少优势。

​ 现代编程体系越来越强调所谓描述式，也就是表达与执行分离，我们表达的顺序和内容不再受限制于实际计算机指令的执行顺序和内容。比如JS中的Promise对象，它表示了未来可以获得的一个值，在程序中可以作为参数传来传去，但是只有当我们明确调用await指令，并等待await返回时，我们才实际获取到了值。而传统编程概念中，函数的返回就表示执行完毕，如果是异步执行，则只能通过回调函数获取通知，在概念层面上我们并无法直接定义和使用“未来的值”。

async function asyncValue(){
    return new Promise((resolve, reject) => {
        setTimeout(() => resolve('a'), 1000)
     });
  }

  var result = asyncValue();
  doSomething(result);

  async function doSomething(input){
     console.log('begin');
     var result = await input;
     console.log('1 second later: result='+result);
  }

​ 未来的值虽然现在未来，但毕竟未来可期。但如果根本不知道未来是否会来，那能否给它分配一个表达形式呢？Vue2.0中有一个非常丑陋的$set函数，每当我们在data对象上新增属性时，都需要调用this.$set("x", xx)函数来设置一下，而不能直接使用 this.x = xx这种属性赋值语法。归根结底，其原因在于按照ES5的语法，在一个属性尚不存在的时候，无法进行任何信息表达，所以Vue.js无法捕获新增属性这一操作，并把新增的属性增强为响应式变量。ES6中的Proxy对这个问题提供了一个解决方案。

var obj = new Proxy({}, {
      get: function (target, key, receiver) {
        console.log(`getting ${key}!`);
        return Reflect.get(target, key, receiver);
      },
      set: function (target, key, value, receiver) {
        console.log(`setting ${key}!`);
        return Reflect.set(target, key, value, receiver);
      },
         deleteProperty:function(target, key){
             console.log(`deleting ${key}!`);
             return Reflect.deleteProperty(target, key);
           }
    });

      obj.x = 3;
      console.log(obj.x);

      delete obj.x;

​ 如果更进一步，我们不仅仅要表达“虽然现在没有，但是未来会有”，或者“现在没有，未来可能会有”，我们就是要表达“没有”，JS中也存在一个专门的表示：undefined。

var o = {a:1, b: 2};
   var patch = {a: undefined, b:3, c:null};
   var result = Object.assign(o, patch);
   console.log(JSON.stringify(result));   // 结果为 {b:3, c:null}

编辑于 2019-04-27 22:07

]]
[[
https://zhuanlan.zhihu.com/p/64822099

canonical
千山万水
基于可逆计算的模型驱动架构
3 年前 · 来自专栏 可逆计算

怎么把大象装到冰箱里？只需要三步：

    把冰箱门打开把大象放进去把冰箱门关上

同样，基于可逆计算实现模型驱动架构也只需要三步：

1. 首先针对自己的业务领域设计领域模型。

这个模型应该同时存在文本表示和图形表示，比如ballerina语言（https://www.infoq.cn/article/ballerina-integration-tutorial-part-2）。当然每次做一个领域抽象都搞出一个DSL语法来就太复杂了，所以需要一个语言工作台专门用于快速开发DSL， 比如JetBrains公司的MPS系统（http://www.jetbrains.com/mps/）。当然，MPS还是太复杂了，所以实际上要把这个过程简化为每次只要增加一个类似json schema的配置文件。这个schema本身也可以通过一个设计器来设计。

2. 根据领域模型利用代码生成器生成具体代码。

这个过程必须是高度自动化的，所以不能是普通的代码生成工具。代码生成工具每次模型发生变化都要手工运行工具，这节奏完全对不上。可以是类似webpack的watch + loader机制，也可以是类似C++的模板元编程机制。C++模板的本质就是根据传入的类型参数动态生成基类，把类型变量直接替换为更加复杂的领域模型就搞定了。

3. 定义模型的差量合并机制。

一般的代码生成工具有一个根本性的缺陷，就是生成过程是一次性的，一旦手工修改就无法与模型保持同步，所以需要一个类似kustomize的模型差量合并机制，可以参见canonical：从可逆计算看kustomize。最简单的情况下，你可以使用 class MyClass extends _GeneratedClass这种形式，当然这显然是无法处理稍微复杂一些的模型对象的。

Javascript的编程模型很适合以上模式，参见canonical：从可逆计算看JavaScript的编程范式。因此，如果要求不高的话，可以很容易构造出一个原型系统出来。
发布于 2019-05-06 16:23

]]
[[
https://zhuanlan.zhihu.com/p/344845973
[
领域抽象是发现领域中的本质性要素和它们之间的作用关系，换句话说，其实就是削减不必要的需求。当我们在一个领域浸淫多年，有了充分的领域知识之后，我们会发现很多需求都是没必要的细节，我们完全可以选择只做性价比高的事情。如果将这种领域知识沉淀为某种领域特定的描述语言，则我们就可以极大的降低信息的表达量。举个例子，前端css框架bootstrap库本质上是对前端结构的重新认识，它将颜色限定为success/info/warning/danger等少数几种，将尺寸限制为sm/md/lg等，而将布局限制为一行仅有12个可选位置。用惯了bootstrap之后，我们会发现实际上多数时候我们并不需要那么丰富的颜色搭配，也不需要那么多种尺寸选择。通过主动限制自己的能力之后，我们通过自律反而获得了某种自由--减少了不必要的决策和要求，同时达到了风格上的统一。

模型对于复杂性的化简往往是乘性的。比如说，100种可能情况如果通过两个基本要素的交叉组合来描述，100 = 10*10, 则我们只需要定义20个基本要素和一个组合规则即可。不止于此，模型的更大的价值在于它提供了关于系统的全局性的知识。比如，在有限自动机模型中，a->b->c->a，一系列状态迁移后系统并不会发散，而必然会回归到某个已知状态。而在自相似的嵌套模型中，整体由部分组成，部分结构放大后又回归到已知的描述。

全局性的知识极大的便利了信息的传播和推导。例如，如果所有组件实例在运行时都有唯一的名称和稳定的定位路径，则我们可以利用它来实现数据自动绑定（与Store中的数据项自动对齐），客户点击追踪等。而在传统的编程活动中，我们所依赖的主要是通用的、领域无关的程序语言和组件库等，缺少全局性的统一的结构约束，很容易就会破坏全局性的结构假定，导致自动推理链条的中断，只能通过程序员的手工工作负责接续。现代软件设计范式中强调约定优于配置（convention over configuration），其要点也正在于利用和保留全局知识。
]

canonical
千山万水
从可逆计算看LowCode
1 年前 · 来自专栏 可逆计算

2020年低代码（LowCode）这一buzzword频繁亮相于主流技术媒体，大背景下是微软/亚马逊/阿里/华为等巨头纷纷入场，推出自己的相应产品。一时之间，大大小小的技术山头，无论自己原先是搞OA/ERP/IOT/AI的，但凡认为自己有点技术的厂商，不说改旗易帜，至少也要加绣一条LowCode的花边，表示不落人后。

根据Gartner 2019年的LowCode报告，LowCode未来的钱景可谓是一片光明：

    到2024年，四分之三的大型企业将使用至少四种低代码开发工具进行IT应用程序开发和公民开发（citizen development，可以认为是非IT背景的用户进行开发，例如：业务用户/产品经理/业务顾问等）。 到2024年，低代码应用程序开发将承担65%以上的应用程序开发活动。

向LowCode转型意味着软件将进入工业化生产阶段。但自从上世纪七十年代以来，这种转向尝试早已不是什么新鲜事情，这一轮的LowCode运动又有什么特殊之处？它凭什么能完成前辈未竟之事业？本文试图从可逆计算理论的角度针对LowCode中的一些技术问题谈谈自己的看法。
canonical：可逆计算：下一代软件构造理论131 赞同 · 41 评论文章
一. LowCode的本质是什么？

LowCode，顾名思义就是 Code Low，在软件产品的构建过程中大幅降低所谓代码编程活动所占的比例。显然，LowCode这一说法仅仅是一种愿望表达，即我们希望大幅降低代码编程量，这意味着更少的工作、更快的交付、更稳的系统，然后从老板的角度，它带来更低的成本、更高的利润和更广的市场等。作为一种朴素而美好的愿望，LowCode的本质与FastCode/CleanCode一样，那就是它没有什么本质，或者说它的本质就是对理想中的一种现象的描述。当所有其他指标都相同的情况下，FastCode肯定比SlowCode强，同样的，在提供同样功能特性的前提下，LowCode肯定比HighCode更让人青睐。

相比于Case工具、模型驱动、产生式编程等等看似高大上，但实际不知所云的专业概念，LowCode无疑是更具体的、更亲民的，特别是结合可视化拖拉拽取代程序员、全流程免运维等这些商业上鼓吹的具有立竿见影的经济效益的卖点，更容易打动圈外的人。

实际上LowCode更像是一面旗帜，所有能够减少Code的实践和理念都可以归于其麾下，而且我们几乎可以肯定的说，LowCode一定是走在正确的技术发展道路上。你能想象500年后人们还像今天一样人肉码代码吗？如果那时候人类还没有灭绝，大概也不会再需要现在这种程序员去写什么业务代码了吧。坚信Code不会被LowCode取代的人明显是缺乏未来视角。在走向智能社会的过程中，我们一定会经历一个智力工作逐步向机器转移，Code逐步减少的过程，那LowCode岂不就是通向未来之路吗？

LowCode具体的技术内涵与外延目前并没有确定下来，现有LowCode产品厂商的具体做法也很难被定性为最佳实践，甚至可以说按照现有的方案实际上是很难兑现其商业宣传中的各种神奇疗效的。如果LowCode真的能深刻的改变技术和商业领域，那还需要我们做出更多革命性的探索才行。
二. LowCode一定需要可视化设计吗？

LowCode减少编码工作无外乎有两种方式：

    实质性的减少针对特定业务所需要编写的代码量
    将传统上需要编码的工作转化为非编码的活动

可视化设计在LowCode中的作用就对应于第二种方式。相比于编程，它有两个优点：

    可视化交互更加直观具体，所需编程知识更少
    可视化交互约束性更强，更不容易出错

可视化设计无疑是目前LowCode平台厂商的核心卖点之一。但如果第一种抽象方式做得足够简单，我们并不一定需要可视化设计器。买不起豪华设计的穷人一样可以LowCode。很多时候我们只需要针对业务领域制定一个专用的领域语言就可以在很大程度上解决问题。例如目前所有创作类网站广泛使用的MarkDown语法，相比于复杂的文字排版软件其功能无疑弱到了极点，但关键是它在大多数日常场景下够用啊，而且具有内生的扩展机制，允许通过自定义扩展来适应各种特殊情况（比如嵌入公式、图表，甚至任意HTML等）。通过这种设计上的偏置，我们可以极大简化常见场景的复杂度，从而使得可视化设计成为次级的设计目标。

一个很有趣的问题是，可视化设计是否生产力更高？很多程序员估计是要举双手双脚反对的。实际上，按照目前可视化设计工具的现状，设计器的输出产物有可能复杂度会超过直接手写的代码。更不用说，设计器相比于代码还存在多种缺陷：

    无法像代码文本那样采用多种工具、多种手段对目标进行自由编辑。
    无法像代码中的函数封装那样以简单的方式实现二次抽象，很多设计器甚至连简陋的组件组合和暂存机制都不提供。
    无法像代码中的继承和接口注入机制那样，对设计工具和设计产物进行局部修正和调整。

可逆计算理论针对以上问题提出了自己的解决方案，它指出可视化设计是可逆性的一种自然推论：

[公式]

领域特定语言DSL具有多种表达形式（文本和图形化），这些展现形式之间可以可逆转换。DSL内置通用的二次封装和差量扩展机制。设计器本身不是固化的产品，而是由元设计器结合DSL的结构信息动态生成，从而实现设计器与应用描述之间的协同演化。
三. LowCode要怎么Low?

如果把软件产品生产看作是对信息的一种加工过程，那么上一节所提到的LowCode的变Low的策略实际就是：

    减少信息表达
    采用Code之外的形式表达

如果我们仔细观察一下市面上的LowCode产品，会发现一些有趣的现象。以http://ivx.cn为例，它面向的用户是非专业程序员，能够以完全免编程的方式来设计界面和后台逻辑。这种所谓NoCode的方式确实可以降低对使用者的技术要求，它所依赖的除了可视化设计器所提供的直观性之外，还在于它主动的限制了使用者所面对的设计空间，放弃了编程中的很多便利性和灵活性，通过降低设计空间中的信息密度来达到降低技术能力要求的目的。

比如说，在一般的编程实践中，我们需要了解各种变量的作用域以及作用域之间的关系，在ivx中没有这些概念，都类似全局变量。编程时，我们可以写复杂的链式调用a.b(g(3)).f('abc')，在ivx中也不存在这种概念，设计器中的一行只能表达单一一个动作。对于完成工作这一基本要求来说，我们编程中所习惯的大量特性确实是没有必要的，限制“做一件事只有一种方式，执行一个动作只会产生一种后果”使得入门变得更加容易。

但是，需要警惕过度的简化会限制平台自身的能力上限，导致难以参与到更加复杂和更加高价值的生产活动中。

如果要求LowCode能够辅助专业开发，那么它一定要能在某种程度上本质性的减少信息表达。为了做到这一点，我们已知的策略大概有如下几种：

    系统化的组件重用基于领域抽象的模型驱动全端、全流程、全生命周期的一体化设计

3.1 组件重用

组件重用是降低系统复杂度的一种通用策略：将复杂的对象分解，然后识别出重复的组分。LowCode的不同之处在于，它鼓吹一种系统化的组件重用，比如提供完整的开箱即用的组件库，无需程序员到处收集，而且确保所有组件可以正确组合，并提供适当的文档和良好的设计器支持，同时组件的生产和消费过程也可以被纳入LowCode平台的管理范围，比如提供公开的物料库和组件市场等。目前LowCode领域所缺乏的是一种得到广泛支持的组件描述标准（可以类似Jetbrains公司的web-types标准 https://github.com/JetBrains/web-types），它使得不同来源的组件库可以在统一的层面得到管理。

    组件重用属于哲学上还原论的一种应用。还原论最成功的范例无疑是原子论。纷繁芜杂的世界表象下竟然是区区百来种原子的支撑，这无疑是关于我们这个世界的最深刻的洞察。但是，认识了原子并不等于认识了世界，大量的信息存在于原子的组合过程中，我们还需要对这个世界的多层次的、整体性的认识。

当前组件技术所面临的挑战在于，我们对于组件的动态性、可组合性、环境适应性等要求越来越高，因此必须要引入超越单个组件视角的、更加系统化的解决方案。比如，我们可能希望一套组件能够适应桌面端、移动端、小程序等多种运行环境。LowCode平台所提供的标准的解决方案是转译技术：把同一套组件描述针对不同的运行环境翻译为不同的具体组件实现（而不是把针对多种运行环境的实现细节封装在组件内部）。当转译成为一种日常之后，我们也就开始走入了模型的世界。
3.2 模型驱动

根据量子力学，在我们的世界中信息是守恒的。如果向一个系统投入少量信息就能够产生大量有价值的结果，那只可能是两个原因：

    看似多样化的结果背后存在一个简单的逻辑内核，系统的本质复杂性并不如表面上看起来那么高。
    结合其他信息源和全局知识，系统自动推导出了大量的衍生结果。

为了构造这样一个非线性（投入和产出不成正比）的生产系统，我们首先需要建立领域抽象，然后基于领域抽象建立一个可以被少量信息驱动的产品工厂。

领域抽象是发现领域中的本质性要素和它们之间的作用关系，换句话说，其实就是削减不必要的需求。当我们在一个领域浸淫多年，有了充分的领域知识之后，我们会发现很多需求都是没必要的细节，我们完全可以选择只做性价比高的事情。如果将这种领域知识沉淀为某种领域特定的描述语言，则我们就可以极大的降低信息的表达量。举个例子，前端css框架bootstrap库本质上是对前端结构的重新认识，它将颜色限定为success/info/warning/danger等少数几种，将尺寸限制为sm/md/lg等，而将布局限制为一行仅有12个可选位置。用惯了bootstrap之后，我们会发现实际上多数时候我们并不需要那么丰富的颜色搭配，也不需要那么多种尺寸选择。通过主动限制自己的能力之后，我们通过自律反而获得了某种自由--减少了不必要的决策和要求，同时达到了风格上的统一。

模型对于复杂性的化简往往是乘性的。比如说，100种可能情况如果通过两个基本要素的交叉组合来描述，100 = 10*10, 则我们只需要定义20个基本要素和一个组合规则即可。不止于此，模型的更大的价值在于它提供了关于系统的全局性的知识。比如，在有限自动机模型中，a->b->c->a，一系列状态迁移后系统并不会发散，而必然会回归到某个已知状态。而在自相似的嵌套模型中，整体由部分组成，部分结构放大后又回归到已知的描述。

全局性的知识极大的便利了信息的传播和推导。例如，如果所有组件实例在运行时都有唯一的名称和稳定的定位路径，则我们可以利用它来实现数据自动绑定（与Store中的数据项自动对齐），客户点击追踪等。而在传统的编程活动中，我们所依赖的主要是通用的、领域无关的程序语言和组件库等，缺少全局性的统一的结构约束，很容易就会破坏全局性的结构假定，导致自动推理链条的中断，只能通过程序员的手工工作负责接续。现代软件设计范式中强调约定优于配置（convention over configuration），其要点也正在于利用和保留全局知识。

模型描述所提供的知识，其用途往往是多样化的，可以参与多种推导过程。例如，根据数据模型，我们可以自动生成数据库定义/数据迁移脚本/界面描述/数据存取代码/接口文档等。而在传统的编程方式中，一段代码它的用途往往是唯一的。

LowCode平台目前的主流做法首先是试图提供一个“更好”的编程模型，然后再内置或者集成大量的领域特定的服务或程序模板。这个所谓的更好当然是仁者见仁，智者见智。有一些相当于是弥补当前编程语言的不足，提供增强的语法特性。比如自动将符合某些条件的同步操作翻译为异步调用，自动实现远程调用代理等，甚至自动实现分布式调度等。有一些是整合最佳实践，降低开发难度，比如将底层的React/Redux封装为类Vue的响应式数据驱动模型。而另一些则是引入更强的假定，缩小了编程模型的适用范围但是增强了平台的控制力，比如简化前端模板语言，自动将模板与前后端模型对象绑定，提供模板到多端的渲染能力支持等。

LowCode平台一般都会内置表单模型、规则模型、流程模型、BI图表模型等通用开发领域常见的模型引擎，同时可能提供丰富的前端界面模板、大屏展示模板等物料资源。很多还会提供领域特定的服务支持，比如针对IOT数据的流式数据处理服务等。
3.3 一体化设计

根据热力学，对于我们所观察到的世界，信息总是耗散的。当信息经过系统的边界不断传递时，它可能会丢失，会扭曲，会冲突。在日常工作中，我们很大一部分工作量不是在做什么新的事情，而是重复实现数据的格式调整、完整性验证、接口适配等本质上属于对接转换的工作。

我们所处的技术环境本身一直处在变动不居的持续演化过程中，这也成为持久的混乱之源。把编译环境架设起来，保证持续集成能够稳定运行并不是一件很简单的事情。经常会发现新人下载源码之后，半天编译打包不成功。移动端、云环境、分布式等复杂的运行环境使得非功能性需求的重要性不断上升，相应所需的知识量也在不断的膨胀。

监控运维和运营数据分析目前已经成为在线软件不可或缺的组成部分，也倒逼着功能开发必须要为运维埋点和数据分析提供支持。

目前LowCode平台对这一系列挑战的回答一般是一个涵盖各种输入输出端点、开发部署测试发布全流程、软件生产运维退役全生命周期的大统一的解决方案。一体化的设计便于减少信息的损耗，避免信息的重复表达，维护模型语义的一致性，屏蔽底层工具遍地是坑的悲惨现实。但无疑，这也是一柄双刃剑。维持一个遗世独立的稳定的乌托邦，需要非常大的投入。可能巨型的公司可以利用LowCode形式来作为自身基础能力的输出，反正它们本身就需要再造很多工具，而且希望其他人绑定到自身所提供的技术生态上，而第三方本身对依赖巨头也存在着默认可接受的事实。
四. LowCode与模型驱动有区别吗？

从目前的实际技术路线来看，LowCode平台目前所采用的策略方针与传统模型驱动领域并无本质的区别。只不过是在新时代的技术场景下，新技术的诞生使得一些事情变得更加简单，而开源技术的广泛流行使得各人能够操纵的技术元素和技术范围变得更加广泛了而已。确实，如果能够把稳定性问题完全外包给云计算基础设施，小团队借助适当工具后的开发能力完全可以支撑传统上的大型软件的研发工作。

新的时代也产生了新的需求，新的需求会促生新的思想。LowCode可以定位为继组件技术之后，试图实现超越组件粒度的、粗粒度、系统级的软件复用的一种集大成的实践集合。

    从编程思想上说，传统的模型驱动基本还是把整体研发逻辑适配到某种面向对象编程范式上，而目前随着函数式和流处理的兴起，多模型范式是一种必然的选择。传统的复用虽然目标设想的很大，但实际的操作路线比较粗糙，大多数情况下只是简单的实现参数化。

从可逆计算理论角度考察，我认为LowCode与传统模型驱动的一个差别可以是基于差量模型驱动的、拥抱模型演化的设计。对于任何一个模型，我们可以问一个简单的问题：能否允许定制，如何定制？追加一个问题就是：模型如何分解，如何在模型基础上实现二次抽象？

对模型可以增加一个衡量标准：是否可逆。很多问题，当我们明确意识到可逆性的存在和必要性之后，就开始变得明晰起来。

从适用的技术手段上说，随着转译技术的发展，和编译器技术的普及，目前在语言级别动刀子也不再是一件难以想象的事情。实际上，很多库作者的实际做法就已经是进入传统编译技术的领域了。在我们的武器库中增加了这一手段之后，特别是在应用层开放使用这种能力之后，很多拓扑结构上难以处理的大范围的信息传导问题就很容易解决。形式稳定性问题在使用本征表示之后往往也得以解决。

抽象最基本的方法是参数化。建立一个函数，把可变的部分作为参数抽象出去F ==> F(x)。如果有很多变化，就变成了

​    F(X1, X2, X3, ....)

如果从很粗糙的角度考虑，一个模型的复杂度我们可以从所需参数的个数来衡量，参数少的就是复杂度低，参数多的就是复杂度高。比如，如果参数X1,X2,X3之间是相互独立的，则模型所描述的可变范围显然和 X1, X2, X3的交叉积的个数直接对应。但是，实际的世界往往更加复杂，参数足够多之后，它们并不是互相独立的！

我们理解F(X1,X2,X3)的前提是，我们需要理解F，还需要理解X1,X2,X3在F内部传播并与F发生相互作用的具体过程。如果参数是相互影响的，情况可能还要更加糟糕，那就是我们需要理解这种相互影响到底是如何以微妙的方式发生的。但是，一个真正有趣的情况在于，如果我们为X1,X2,X3建立规范化的结构约束后会怎样？当参数足够复杂之后，它有可能自身构成一个有序变化的整体，我们可以用一个领域模型M来对它进行描述，从而使得我们可以在不依赖于F的情况下独立的理解M。

我们这个世界底层的逻辑是层展的。也就是说我们可以在不同的层面基于不同的结构建立对系统的理解。从一个层面进入到另一个层面时，我们对它们的理解可能是独立的（一个完备的参数系统升华为一个独立的概念空间）。当我们引入结构，并主动的管理概念结构时，我们所面对的复杂性情况就完全不同了。

参数化演变的终点是 f(DSL), 所有x构成一个有机变化的整体，从而实现整体领域逻辑的一种描述方式，而f成为领域的支撑能力。当然一个有效的DSL只能是描述某个业务切面，所以需要 f(DSL1) + g(DSL2）+ 。。。， 总结下来就是 Y = G(DSL) + delta

抽象的一个常见问题是抽象泄露。如果我们抽象出的DSL与实际情况不符合怎么办？在可逆差量的视角下，这个问题可以这么解决:

Biz = App - G(DSL1)

把剥离领域描述DSL1之后剩下的部分Biz看作是一个独立的研究对象。这类似于物理上我们可以把高斯模型作为系统的零阶解, 然后把原始方程重新表述为修正量所对应的1阶方程。

从底层技术的基本逻辑来说，很多业务问题背后的技术结构是似曾相识的，但是目前主流的技术手段并不足以我们把相应的技术实现从一种技术场景迁移到其他技术场景。总是有很多技术实现和业务内容强绑定，需要程序员拷贝粘贴过来之后手工进行剪裁修正。通过DSL抽象和差量化处理，我们可以实现不同层面逻辑的一种新的拆分模式，例如在不打开引擎盖的情况下换发动机。

程序员是站在上帝视角看待软件系统的，他并不需要完全被动的接收系统中的事实。上帝说，要有光，于是就有了光。程序员可以自己设计规则（Rule/Law），并约束所有元素的行为。现在有些人认为LowCode只能做从0到1的原型开发，最终还是要通过DDD之类的传统技术重构，这大概是认为LowCode只能是把业务对齐到少数内置的模型上，而不能根据领域的实际情况提供最合适的逻辑分解。而可逆计算的视角不同，它强调DSL本身应该是可定制的，可以根据需求变化做自由扩展。同时类似JetBrains公司的MPS系统，可逆计算的支撑技术应该是一种领域语言工作台，它为领域语言的开发/运行提供完整的解决方案。
五. LowCode需要技术中立吗？

LowCode试图实现更高级的复用，那么技术生态的分裂所导致的这种偶然的依赖性必然是它要试图屏蔽的内容。同样的逻辑内容为什么使用java实现了之后在typescript不能被直接使用？

技术中立存在几种策略：

    微服务。通过技术中立的通信协议实现分离，这是一种非常规范而成熟的方案。而且随着内核网络栈的优化，例如引入RDMA和DPDK技术，Sidecar模式下跨进程调用的性能极度优化后可以与进程内调用可比。
    虚拟机。GraalVM提供了通过编译混杂不同的技术栈的作用，这也是非常有前途的一种方向，它的好处是可以跨越技术边界实现协同优化。而在微服务的方案中，Java调用JavaScript的代码不能进行统一优化。
    领域语言。这是一种低成本的，控制权由普通程序员掌握的方案。如果编写解释器的复杂性能够进一步降低，比如类似于一个解释规则就是简单对应于一个函数调用，它可以成为我们解决日常业务问题的一种常规手段。

如果把每种具体的实现技术看作是一种不同的坐标系，那么采用不同的技术去实现就相当于是把一个确定的逻辑使用不同的坐标系统去表示。那么数学上是如何处理坐标无关量的？物理学的所有原理都是所谓参照系无关的，也就是坐标无关的，它们都采用所谓的张量（Tensor）来表示。张量的坐标无关本质上说的是，一个物理量在不同的坐标系里有不同的具体表示，这些具体的表示之间通过某种可逆的结构变换联系在一起。坐标中立并不意味着绑定到某种坐标系中，而是不同的坐标之间可以可逆转换。

所以依据可逆计算理论，我们并不一定要强求大一统设计，强求所有地方的信息表达都只有唯一的一种形式。而可以是多种表达，只要存在某种预定义的可逆机制可以从系统中反向抽取信息并自动进行转换即可。比如，现有的接口定义都存在接口描述，无论是采用protobuf描述，还是jsonrpc，抑或是grpc。因为它们都是描述式信息。原则上我们是可以根据其中一种描述，补充部分信息实现这些结构描述之间的自由转换的。如果我们的产品可以随时根据接口描述自动生成，它就可以不是一种固化的二进制代码。延迟生成，实际上就是一种多阶段编译技术，它可以是未来LowCode的发展方向。

可逆性是可以分而治之的。当一个庞大模型的每个局部都是可逆的时候，我们就有可能自动得到整体的可逆性。可逆性本身也是可以跨系统的。LowCode的未来不应该是单一的产品或者单一的SAAS应用，而是内与外、上下游可以实现信息的自由传递与转换，突破技术形式的绑定。

坐标中立的体系存在一个特例--零，它为系统带来了一种本质性的化简机制。一个坐标中立的零在所有的坐标系中都仍然保持为零。它的含义在于，有很多运算我们完全可以在坐标中立的表象中完成。大量的判断和结构转换/加工都可以在纯形式的层面完成，它们完全不涉及到复杂的运行时依赖。

可逆计算的一个核心观点是，坐标中立是形式层面的事情，可以完全脱离运行时来讨论。通过编译期的元编程技术，我们可以实现运行时结构与直接手写代码完全相同。LowCode在运行期可以不引入额外的间接处理层。
六. LowCode需要图灵完备吗？

说实话，图灵完备这个概念完全是计算机圈子内部的行话。说起模型，一个模型的重要性和有效性与图灵完备有半毛钱的关系吗？比如，化学分子式无疑是描述分子结构的一种非常有效的领域特定语言，化学反应方程是对具体化学反应过程的一种模型化的描述，它需要是图灵完备的吗？牛顿万有引力方程将天上的星星和地上的苹果联系在一起，是伟大的建模成就，它的计算可以指导四季耕作。微分方程模型的建立和求解需要图灵完备吗？

领域内最核心的知识并不需要图灵完备。我们需要图灵完备的地方是当我们需要做一些“通用”的计算和处理过程的时候，当我们需要机器代替我们去自动化处理某些平平无奇的动作的时候。当我们要以某种未预料的方式来处理某些事情时，我们需要保留图灵完备的处理能力。如果我们已经遇到过这种情况，往往我们能够进行算法封装，把复杂的逻辑运算封装到算法内部，外部使用者并不需要图灵完备。

LowCode为了完成足够广泛范围的工作，它肯定是要保留图灵完备的能力的。但是它所提供的核心的领域模型并不需要图灵完备。图灵完备反而可以只是某种边缘场景的应用。

图灵完备能力的获得可以是通过内嵌的DSL语言。当然这是一种非常廉价的方式，特别是可以充分利用IDE对语言本身的支持来免费获得实现对DSL的支持。但是这种做法的问题在于，嵌入式DSL往往只关注于正确表达的形式直观性，对于偏离DSL形式的情况缺乏约束。也就是说，如果使用者不按照约定的方式去编写DSL是完全可能的，虽然语义上是完全一致的，但从形式上就不符合原始DSL的要求。面向DSL的结构转换也就难以进行下去。

JSX这种方式是一种有趣的扩展形式。因为执行时我们可以获得虚拟DOM节点，相当于是拥有对结构的比较大的控制权限的。但是typescript的问题在于它没有明确的编译期。jsx的编译期处理非常复杂，运行期得到的是具体的VDOM节点。而在编译期我们需要分析代码结构，而因为停机问题的存在，普遍来说代码结构是难以分析的。所以vue template这种编译期可分析的结构是非常重要的。

图灵完备并不是信息完备。反向解析得到信息是目前所有主流技术都缺乏的。图灵完备实际上不利于信息逆向分析。习惯于手写代码的传统导致程序员对于程序结构的自动分析并不重视，因为这些工作此前都是编译器编写者的责任。而如果LowCode可以大规模在应用层使用这种技术，还需要更多的普及教育。现在所有语言的运行时能力很强，但是编译期的逆向能力都很差。很多人倾向于用json，本质上是想把逆向分析/转换的能力掌握到手里。

DSL也不一定意味着特殊的程序语法。我们对于可逆计算的具体实现是直接使用xml模板技术作为前后台统一的结构描述，相当于是直接编写AST抽象语法树。相比于LISP，好处在于结构形式更加丰富一些。显然html格式对于一般人员来说，比lisp还是要更加容易阅读。

可逆计算提供了将扩展能力累加到领域特定逻辑之上的方法。
七. 为了LowCode我们会失去什么？

一个有趣的问题是，LowCode带给我们的都是好处吗？使用LowCode我们会失去什么？

我的回答是，LowCode将使得程序员失去一家独大的控制权。传统的编程方式，所有软件结构的构造都源自于程序员的输入，因为程序员成为了应用和需求人员不可回避的中介。而LowCode技术所带来的一种变革在于，通过将逻辑分层分解，多种信息来源可能独立的参与系统构建。需求人员完全可能绕过程序员直接指示业务模型的构造，并在系统智能的支持下自主的完成业务设计-反馈的循环。当这些人员直接掌握控制权之后，可能他们也不想再回到此前那个需要被动等待的时代。

LowCode的技术策略虽然看来看去似乎并不新鲜，但是它确实在表述和立意上有所不同。它明确强调citizen programming，而此前的model driven本质上还是程序员内部的问题。

任何一场技术革命实质性的结果都是生产力和生产关系的变革。我们已经站在时代的边缘，使得多种信息掌控者：程序员、业务人员、人工智能等等可以通过分工协作、齐头并进的方式参与逻辑系统的构建，使得信息的流动有望突破形式的限制，绕过人类载体，跨越系统边界和时间演化进程。LowCode在传达这一核心概念的时候是不清晰的、存在误导性的。

基于可逆计算理论，我提出了一个新的概念： 下一代软件生产范式-NOP（非编程，NOP is Not Programming）。
canonical：NOP --- 下一代软件生产范式35 赞同 · 9 评论文章

NOP强调了这种生产范式转换所带来的本质性变化。从桌面互联网转向移动互联网技术之后，一个新的理念诞生，那就是所谓的移动优先。当我们设计一个系统时，首先考虑移动端的处理过程，然后再考虑桌面端。类似的，在LowCode的时代，我们在软件生产中需要考虑“描述优先”，通过领域模型将系统的逻辑结构以可以进行差量修正的形式明确表达处理，它作为一种后续的财富，使得我们的系统逻辑可以越来越多的摆脱某种当时当地的技术实现约束的限制，明确记录我们的业务意图。

描述的部分应该和常规代码的部分具有明确的边界。以Antlr4为例，此前的设计中，我们会在描述式的EBNF范式中增加action标注来控制语法解析器的行为，而在Antlr4中明确提出语法文件中只描述语法结构，一些特定的处理过程全部集中到Listener和Visitor处理器中。描述信息完全被隔离之后，antlr立刻摆脱了java的束缚，它可以根据同一份语法定义，生成java/go/typescript等不同语法实现的解析器，同时根据语法描述自动生成IDE语法解析插件，格式化处理器，IDE自动提示等，产生了多种用途。

在我看来，传统上的code使用的逻辑是机器运行的逻辑，把所有逻辑的表述形式都适配到适合图灵机或者lamba演算机运行的形式。但是领域逻辑具有自己特定的表述形式，它的组成元素有自己的作用方式，这些方式可以被直接理解，而不必非要划归为某个图灵机上执行的步骤去理解。一个语言就是一个世界，不同的世界有不同世界观。LowCode不是说code有多low, 而应是表述的方向不同。

LowCode并不等价于让不懂逻辑的人写代码（虽然很多产品试图给人这种错觉让人买单）。实际上很多数学家也不会写程序，但是他们非常懂逻辑。5-10年以后市场上会有不少40岁以上的曾经的程序员，但他们不一定再懂最新的开发技术，用一个更高层的逻辑描述不还是能开发业务逻辑并享用到最新的技术进展吗？
编辑于 2021-01-18 15:18

]]

[[
https://zhuanlan.zhihu.com/p/64007521
[
基于逆元可以在任意元素之间建立关联，从而实现任意元素之间的转化。这样元素之间的关系就突破了简单的整体-部分或者一般-特殊等关系的范畴，进入更加抽象的结构运算范畴。这种思想上的变革启发了哲学中的结构主义思潮。

在哲学上，结构主义提出结构具有三个要素：整体性，转换性（具有转换规律或法则），自律性（自身调整性）。整体性意味着结构不能被简单的切分，其构成要素通过内在的关系运算实现大范围的关联与转换，整体之所以成为整体正是以转换/运算的第一性为保证的。这种转换可以是共时的（同时存在的各元素），也可以是历时的（历史的转换构造过程），这意味着结构总要求一个内在的构造过程，在独立于外部环境的情况下结构具有某种自给自足的特性，不依赖于外部条件即可独立的存在并保持内在的活动。自律性意味着结构内在的转换总是维持着某种封闭性和守恒性，确保新的成分在无限地构成而结构边界却保持稳定。注意到这里对结构的评判并不是来自外在规范和约束，而是基于结构内在的规律性，所强调的不是结构对外部条件的适应性，而是自身概念体系的完备性。实际上，一个无法直接对应于当前实际环境的结构仍然可能具有重要的价值，并在解决问题的过程中扮演不可或缺的角色。在合理性这个视角下，我们所关注的不仅仅是当前的现实世界，而是所有可能的世界。结构独立于内容存在于抽象的数学世界中，一个“合理”的结构的价值必能在它所适应的具体世界中凸显出来。
]

canonical
千山万水
可逆计算的方法论来源
26 天前 · 来自专栏 可逆计算

对于软件领域的大量设计原则和所谓的方法论，我一直持有很深的怀疑态度。为什么会存在这些原则，能否从科学的层面证明它们的有效性？可逆计算理论试图为软件构造提供一个更加坚实的理论基础，它明确提出应该将“差量”提升为第一性的概念，将全量看作是差量的一种特例（全量=单位元+全量），围绕差量概念去重建整个领域概念体系。可逆计算的思想来源不是计算机科学本身，而是理论物理学，它将软件看作是处于不断演化过程中的抽象实体， 在不同的复杂性层次上由不同的运算规则所描述，它所关注的是演化过程中产生的微小差量如何在系统内有序的传播并发生相互作用。本文将介绍可逆计算从作为其思想来源的统计物理学和量子力学所获得的启发。
（一）熵增原理

在香农的原始定义中，信息是能够用来消除不确定性的东西。而在物理学中，所谓的不确定性就是系统的混乱程度，而用于度量系统混乱程度的物理量就是熵（Entropy）。接收到信息后，不确定性降低，也就意味着混乱程度的减少，因此信息也就被认为是负熵。

熵是物理学中的一个核心概念，它甚至比能量概念还要重要。热力学第一定律就是能量守恒定律，它指出能量只能被转化，而不可能被创造或者消灭。而热力学第二定律指出，即使有了能量，也不一定能够对外做功，必须考虑到热力学过程内在的不可逆性：热力学系统从一个平衡态演化到另一平衡态的过程中，其熵永不减少，若过程可逆，则熵不变，若不可逆，则熵增加，这 也就是所谓熵增原理。

熵增原理控制了所有自然发生的过程，驱动所有事物自发的向着混乱最大化的方向发展。因此，在软件开发过程中，我们同样可以观察到大型软件产品普遍存在着从有序到混乱的发展历程。伴随着人员的更替、需求的变迁，在软件中增加新的功能变得越来越困难，修改bug经常引入新的bug，没人能够说清楚如何才能抽取系统中的一小部分进行复用，最终只能推翻重建。

可逆计算的核心是可逆性，而可逆性之所以重要，不仅仅在于它方便了软件元素的灵活复用，深层次的原因是它体现了我们这个世界本质的运作规律。通过遵循可逆计算原则，我们能够有效的控制软件演进过程中的熵增速度。理想情况下，如果系统能够做到完全可逆，则熵是保持不变的。

在软件架构设计中，我们总是说要高内聚、低耦合、关注点分离，但是什么是高、什么是低、需要分离到什么样的程度？可逆计算给出了一个可操作性更强的标准：分离到可逆的程度就好了。对于具体的软件开发，可逆计算所提出的要求是，任何增加的功能都应该有配对的逆向取消机制，任何输入到系统中的信息都应该存在一种自动反向提取出来的方法。

可逆性是可以复合的，即如果每个部分都可逆，且部分之间的结合关系也可逆，则系统整体可逆。这一特点使得逐步构建大型的可逆系统成为可能。具体方式可以参考设计模式中的Command模式

[公式]

每个Command都包含一组配对的execute和undo操作，则一系列按顺序执行的Command可以被封装成一个BatchCommand，它的execute和undo操作可以由子命令复合得到。

现实世界中，熵增是无法逃避的宿命。但是即使无法完全消除熵增，我们仍然可以选择熵增发生的地方，例如将熵增集中在差量△中。特定客户的需求总是包含着大量随机的、偶然的因素，把它们纳入系统不可避免的会破坏原先统一均衡的系统结构，如果能够把这些偶然因素集中在一个可抛弃的差量△中，则可以保护核心架构不会受到侵蚀。当系统交付给新的客户时，我们不必携带上一个客户的个性化需求，可以始终从一个低熵的状态开始。
（二）量子力学中的世界图景

量子力学是描述宇宙的基本理论，它所研究的问题可以归结为算符（Operator）作用到所谓的态函数（State Vector）上，如何驱动系统发生演化的问题。

1925年海森堡提出了量子力学的第一种表述形式：矩阵力学，它也被称为海森堡图景。在这一图景中，态函数ψ为固定的对象，不随时间演化，而可观测算符A的演化满足方程

[公式]

1926年薛定谔提出了量子力学的第二种表述形式：波动力学，它也被称为薛定谔图景。在这一图景中，算符为固定的对象，不随时间演化，而态函数的演化满足大名鼎鼎的薛定谔方程

[公式]

其后不久，薛定谔证明了矩阵力学和波动力学的等价性。

1927年狄拉克提出所谓的“变换理论”，引出了量子力学的第三种表述形式：相互作用图景，它也被称为狄拉克图景。在这一图景中，首先将系统的Hamilton量拆分为已知的部分和待研究的微小扰动

[公式]

然后研究系统如何偏离已知模型进行演化，即我们所关心的是差量描述的演化情况。在相互作用图景下，态函数和算符都随时间演化

[公式]

[公式]

根据这三种图景都可以得到完全一致的物理测量结果

[公式]

相互作用图景是物理学家在实际工作中使用最多的图景。事实上，数学物理中存在一个专门的分支：微扰论（Perturbation Theroy），它系统化的研究在已知模型的基础上添加微小的扰动量，新的模型如何演化的问题。而理论物理中绝大多数有价值的计算都是在微扰论的框架下进行。

如果把量子力学和计算机理论做个对比，我们会发现量子力学中的世界图景和计算机理论的世界观之间存在一个有趣的对应关系

    薛定谔图景 <--> 图灵机海森堡图景 <--> lambda演算 狄拉克图景 <--> 可逆计算 

图灵机和lambda演算建立了通用计算机的概念基础，在理论上解决了计算的可行性问题，即为什么可以存在一种通用的机器执行机械化的动作，使用有限资源来完成所有我们能够想见的计算。在通用计算机已经普及的今天，我们所面临的最大的实际问题是如何有效的进行计算的问题。计算效率的提高依赖于我们发现计算中的“捷径”，而这依赖于我们对问题本质的洞察，而洞察的产生与问题的表述形式息息相关。表象（representation）变换本身甚至就是解决问题的一种方式，因为变换后的问题表象有可能使得解决方案变得清晰可见。可逆计算借助于领域模型和差量描述，使我们的注意力得以聚焦在待解决的新问题上。
（三）群和结构主义

自从爱因斯坦发现相对论以来，现代物理学的大多数基本原理都建筑在群概念的基础之上。例如，狭义相对论对应于Lorentz群，量子电动力学对应于U(1)规范群等。

​ 所谓群（Group），就是定义了一个二元运算（不妨记为符号+），并满足如下四条群公理的非空集合G。

    封闭律。集合中任意两个元素的运算结果仍属于该集合。 [公式] 结合律。运算可以局部进行，运算的最终结果与运算的结合顺序无关。 [公式] 幺元律。集合中存在单位元0,它对任何元素的作用结果都是无作用。 [公式] 逆元律。集合中对每一个元素a, 存在对应的逆元素-a，它可以完全取消a的作用。 [公式] 

这四条公理看似非常简单，却蕴含着非常深刻的数学内容。例如，如果只考虑元素个数有限的所谓有限群，不用增加任何其他假定，仅依赖这四条公理，即可推导出大量数学定理。在1955年至2004年间共100多位数学家在500多篇期刊文章中写下了上万页的证明，才完成了对有限群分类的工作。

封闭律是为了确保所有的运算结果都仍然在定义范围之内，不会出现运算结果无法描述的情况，这样运算就可以一直持续下去，构成很长的推理链条。例如，Lisp语言具有所谓的同像性（homoiconicity），Lisp宏的输出仍然是合法的Lisp语言，这正是封闭律的一种体现。

结合律意味着可以进行局部运算，而不用依赖于全局结构，这样才可能实现子结构的二次封装。例如，

[公式]

对于满足结合律的运算，可以将 B和C抽象为一个新的结构X，而将D和E抽象为一个新的结构Y，X和Y的组合可以被再次抽象为结构Z。

满足结合律的运算可以实现局部优化，即我们可以选择在合适的地方加上括号，实现局部的预计算。例如

[公式]

所谓的分而治之（Divide And Conquer）技术，之所以能够加速计算，很多时候所利用的也就是结合律，比如说归并排序。

幺元律的作用在于它使得差量成为第一性的概念。在具有单位元的系统中，任何量都可以被看作是与单位元之间的差量。例如

[公式]

从哲学上说，物理学格物以致知，我们所知的一切都只是世界的变化，世界的本体是不可观测的。所谓的差量（有正有负）实际上就是我们知识的全部。

如果满足封闭律，结合律和幺元律，在数学上就可以称之为“幺半群”。函数式编程中著名的Monad，只不过是自函子范畴上的幺半群而已。

Monad只是幺半群，它不满足逆元律。在群的四条公理中，最难被人们所认识的也是逆元律。从自然数发展的历史来看，欧洲数学家直到17世纪才接受负数的概念，这反映出本质上逆元的概念存在令人困惑之处。在当时的人们看来，负数对应于不存在的事物，既然对应的对象不存在，负数本身怎么能够存在呢？

逆运算对于很多数学推导来说都是必不可少的。例如在引入负数之前，

[公式]

这两个方程的结构是完全不同的，它们需要不同的求解技术，因此也就不可能利用符号抽象出二次方程的标准形式

[公式]

引入负数才使得我们能够以统一的方式提出问题，并研究通用的求解技术。

基于逆元可以在任意元素之间建立关联，从而实现任意元素之间的转化。这样元素之间的关系就突破了简单的整体-部分或者一般-特殊等关系的范畴，进入更加抽象的结构运算范畴。这种思想上的变革启发了哲学中的结构主义思潮。

在哲学上，结构主义提出结构具有三个要素：整体性，转换性（具有转换规律或法则），自律性（自身调整性）。整体性意味着结构不能被简单的切分，其构成要素通过内在的关系运算实现大范围的关联与转换，整体之所以成为整体正是以转换/运算的第一性为保证的。这种转换可以是共时的（同时存在的各元素），也可以是历时的（历史的转换构造过程），这意味着结构总要求一个内在的构造过程，在独立于外部环境的情况下结构具有某种自给自足的特性，不依赖于外部条件即可独立的存在并保持内在的活动。自律性意味着结构内在的转换总是维持着某种封闭性和守恒性，确保新的成分在无限地构成而结构边界却保持稳定。注意到这里对结构的评判并不是来自外在规范和约束，而是基于结构内在的规律性，所强调的不是结构对外部条件的适应性，而是自身概念体系的完备性。实际上，一个无法直接对应于当前实际环境的结构仍然可能具有重要的价值，并在解决问题的过程中扮演不可或缺的角色。在合理性这个视角下，我们所关注的不仅仅是当前的现实世界，而是所有可能的世界。结构独立于内容存在于抽象的数学世界中，一个“合理”的结构的价值必能在它所适应的具体世界中凸显出来。

在建立领域模型时，我们可能经常会问这个模型是否是对业务的准确描述，是否可以适应需求的变更，是否允许未来的各种扩展等等。但是如果换一个思维方向，我们会发现这些问题都假定了存在最适合业务领域的唯一理想的模型，我们想知道当前模型和理想的模型之间相差多远。这些问题都是针对最终确立的模型而发问的，而在模型构建的过程中，那些可被利用的，已存在的或者可以存在的模型又是哪些呢？每一个信息模型都对应着某种自动推理机，可以接收信息并做一定的推导综合工作。一个可行的问题是，如何才能更有效的利用已有的信息进行推导，如何消除冗余并减少各种转换成本。我们经常可以观察到，某一信息组织方式更充分的发掘了信息之间的内在关联（表现为它对信息的使用不是简单的局域化的，而是在多处呈现为互相纠缠的方式，难以被分解），这种内在关联足够丰富，以至于我们不依赖于外部因素就可以独立的理解。这种纠缠在一起的信息块自然会成为我们建模的对象。

如果我们不再强求单一的、大而全的模型，使得模型的“覆盖能力”不再是我们关注的重点，那么建模的思维图式将会发生深刻的转变：最终的模型可以由一系列微模型交织构成，每一个微模型在某种程度上说都是自己自足、自圆其说的，它的存在合理性由其内在逻辑的自洽性决定。在这种图式下，所谓的模型就相当于是已经确立的数学定理，如果增加新的假设，我们可以通过已有的定理推导出新的定理，也就是建立新的模型。
编辑于 2022-04-24 22:16

]]
[[
https://zhuanlan.zhihu.com/p/66548896
[
其实仔细思考一下人在软件开发中所承担的工作内容，就可以发现为什么我们需要如此多的人工。大部分程序工作并不是去建立新的抽象（编写复杂的组件、算法、框架），而是在做某种逻辑等价的形式转换。比如，将用户的查询请求转换成数据库可以理解的SQL语言，将流程流转逻辑适配到工作流引擎所要求的接口格式等。

同样的软件功能，会ios开发的一般并不会android开发，反之亦然。在某种意义上，很多程序员的工作其实类似于古时候代人写信的秀才，他们负责将人类普遍理解的逻辑翻译成计算机所理解的API调用，而且每个人掌握了回字的不同写法，写出来的东西也五花八门。
]

canonical
千山万水
NOP --- 下一代软件生产范式
25 天前 · 来自专栏 可逆计算

作者： Canonical

什么是NOP？NOP是Nop is nOt Programming 以及 Nop Oriented Programming的递归缩写，它代表了一种以可逆计算理论为指导，采用非编程的方式，通过人机智能协作，批量化进行软件定制生产的下一代软件生产范式。NOP的目标是在提升10倍生产率的同时提升10倍软件质量，在软件开发、测试、文档、部署、维护的全生命周期内降低10倍人力需求，为智能时代实现软件全面普及化奠定基础。
一. 智能时代的软件需求

大数据和人工智能的发展带来了第四次工业革命（工业4.0）的曙光，工业4.0所描绘的图景应该是万物互联、自主协同、实时感知、在线演化，而这一切智能都需要由软件来赋予，软件就是智能时代的电力和能源。2017年中国国际软件博览会全球软件产业发展高峰论坛的主题就是“软件定义未来”。但是软件定义未来，谁来定义软件？

反观软件生产自身，我们不得不正视一个令人尴尬的事实：软件研发一点都不智能，它是严重依赖大量程序员手工劳动的一种效率极其低下的过程。即使是一名高级工程师，一整年能输出的有效代码量也很难超过2万行，软件研发的成本让世界顶级奢侈品都相形见绌。

软件的经济学与物质生产具有本质不同：构造成本很高，但是复制成本近乎为0，在完全不修改的情况下没有折旧一说，增加一个使用者的边际成本极低。如果投入大量人力物力维护唯一的软件产品，让所有人都使用同样的功能集，那么软件的生产成本可以被摊薄，创造出远超物质生产的价值产出，这是互联网经济的内在技术逻辑。

但是随着互联网进入下半场，to B市场的逻辑开始挑战to C市场的成功经验。互联网巨头们都在强调千人千面，展现给每位用户的都是针对该用户通过AI算法”精心优化“的界面。但是千人千面，却没有一面是用户可以随意指定的一面，没有一面是用户真正能够掌控的一面。

企业客户不是沉默的看客，而是需要为生存拼尽全力的主动猎食者。企业软件需要实现客户需求，而客户需求就是客户为适应自身商业环境所需要特化的逻辑。现在的AI可以识别、可以预测，但却不能产生新的逻辑。一个有趣的现象是，大数据和人工智能公司在真正项目实施时投入大量人工，所做的却都是普通开发工作（这里编个接口，那里做个界面），与大数据和人工智能没有半点关系。

企业软件面临的现实是，任何一个功能点的潜在用户数都是极其有限的，而所有投入都要量入而出。大部分企业用不起定制软件，用得起的也多半养不起。就算软件开发商倒闭了，相关硬件绝版了，企业软件的用户一般也是宁肯操作系统降级、软硬件型号绑死，也坚决不升级。智能要进入企业市场成为一门挣钱的生意，难度要远超消费者市场。即使是SalesForce那样可扩展的云端SAAS应用，它的二次开发成本以及支持用户自定义逻辑的深度，也是远远不足以支撑工业4.0的目标蓝图的。
二. 智能时代的软件生产

如果我们做一点逆向思维，假设智能时代已经实现，想象一下此时的软件生产场景。

首先，人类社会传统的专业分工将会发生根本性改变，人与人之间靠着专业化、熟练度形成的隔离将被打破。未来的分工首先是人与机器之间的分工，所有依赖经验性的、可机械化的工作将由机器承担，人所负责的是创造性、探索性的工作。限制我们的，是每个人的想象力和他可以输出的逻辑要求，而不是这种逻辑的具体实现方式。

第二，劳动生产率的大幅提升使得小团队即可掌控复杂产品，传统软件工程为了控制人这一最复杂、最不确定的生产要素所提出的按功能细分纵向划分成多个团队的组织原则将变得不再有意义。

第三，机器与机器之间存在大量的直接交互，不再需要人作为中介参与。软件接口的设计原则向机器容易理解的方向倾斜，而不单纯强调适合人类的阅读理解。理想的软件接口应该具有多种展现形式，方便人和机器选择各自适合的方式进行处理，便于双方协作。

目前主流的软件开发技术所考虑的受众都只有人，认为只有人是软件生产的参与者和理解者。大部分程序语言以及领域特定语言（DSL）的设计强调类似自然语言（其实只是类似英语语法），并不利于机器解析和扩展。

互联网开发因为团队庞大，很多人推崇polyglot多语言编程，方便不同背景的程序员在实现特定业务功能时选择采用最适合的编程语言和开发工具，但是如果原本需要50人协作开发的产品最终交由一个5人团队完成，多语言开发就不可能成为一个合适的选择。

其实仔细思考一下人在软件开发中所承担的工作内容，就可以发现为什么我们需要如此多的人工。大部分程序工作并不是去建立新的抽象（编写复杂的组件、算法、框架），而是在做某种逻辑等价的形式转换。比如，将用户的查询请求转换成数据库可以理解的SQL语言，将流程流转逻辑适配到工作流引擎所要求的接口格式等。

同样的软件功能，会ios开发的一般并不会android开发，反之亦然。在某种意义上，很多程序员的工作其实类似于古时候代人写信的秀才，他们负责将人类普遍理解的逻辑翻译成计算机所理解的API调用，而且每个人掌握了回字的不同写法，写出来的东西也五花八门。

第一次工业革命发明了蒸汽机，将化石能源转化为热能再转化为机械能，推动机器代替了手工劳动。而第二次工业革命发明了电，经由电这个媒介，能量可以在各类形态之间发生自由转化，促使生产方式发生了进一步变革。智能时代的驱动力是信息，但目前信息却经常固化在特定的表达形式中, 只有受过专门训练的程序员才能理解软件中的信息并转化信息的表达形式。

近20年来软件世界的繁荣离不开开源软件的贡献，借助于人这一最高级别的智能转化媒介不断的对已有信息进行理解和改写，信息终于可以在各个公司之间、各种技术应用场景之间、各种表达形态之间发生流动了。使用单一公司提供的产品会发生供应商锁定问题，如果供应商倒闭，不仅仅供应商本身的软件功能无法使用，更重要的是我们基于供应商的软件所表达的业务逻辑也被锁定为固定形态而无法继续向前发展了。

使用开源软件避免了供应商锁定，但是仍然无法避免技术形态锁定。我们花费了巨额开发成本，基于某种技术开发的应用随着技术升级换代将会迅速过时，很多新兴技术自身的生存周期只有1-3年，而我们的业务逻辑却需要长久的存在下去，这就造成了循环往复的形态转化需求。

面向未来的软件生产范式应该是支持信息自由转化，支持人与机器更好的分工协作，支持用户特定的逻辑很自然的融入系统、驱动系统运行的。
三. NOP --- 让信息无界流动

NOP是以可逆计算理论为指导，综合利用模型驱动、差量编程、大数据和人工智能等技术所实现的一种新型软件生产范式，它致力于满足未来智能社会的软件生产需求。

目前企业软件的开发模式一般采用我们所谓编程（Programming）的方式：

    使用适用于所有业务领域的通用开发语言（例如Java/C#）和开发框架（如SpringBoot/dotNet Core）开发团队成员包括项目经理、需求人员、架构师、UI设计、程序员、测试和文档编写人员等开发过程一般由项目经理组织架构师、UI设计和需求人员进行沟通、讨论，确定界面展现形式和业务功能点对应的业务逻辑规则等。设计人员和需求人员讨论完毕后，编写出需求规格说明书、软件功能设计说明书等。开发人员拿到需求文档和设计文档后，理解文档编写人员的意图，使用熟悉的开发语言和开发框架，将其翻译为具体的技术实现代码。开发人员开发完毕之后，由测试人员负责进行初步的需求验证和正确性检查等，待产品功能基本完备后提交需求人员进行试用和验收。文档人员根据交付软件功能编写使用手册等。开发过程中发现实现出现偏差或者需求发生变化，则由相关人员提交对应测试文档、需求变更文档、设计修改文档等，重新交由上游人员按照流程处理。

以上生产过程在生产每一个功能点时都涉及到多处信息传递，而且都需要人的参与，人将信息编写为文档，再由另外的人理解文档，反向抽取信息再加工成机器可理解的信息（代码）。整个生产是一个相当复杂的过程，从需求人员提出需求到他可以直观的看到系统运行结果，一般至少需要一周以上的时间。

编程是我们非常熟悉的生产范式，无论是敏捷开发还是更传统的瀑布式开发，它所依赖的都是人与人之间的协调，而它的瓶颈也就在于人。人的不精确性和复杂性也会渗入到生产过程中，增加生产的困难。例如，一般情况下，软件需求文档、设计文档、使用文档和具体系统实现之间会逐渐出现偏离，最终可能完全相互脱离，文档失去参考价值。

NOP是一种非编程的生产范式，它强调的是开发人员、需求人员和机器三者之间协同工作，信息采用中立形式表达不再需要人工传递和转换。从编程到NOP需要经历所谓的范式转移过程，这意味着软件整体开发思想、开发架构、开发工具等都要经过彻底的改造，在新的技术思想指导下重构所有相关概念。

根据可逆计算理论，软件的构造可以被分解为两个相对独立的步骤：

    使用领域模型所构成的特征向量来描述业务需求 [公式] 领域模型经过生成器转换以及差量描述调整后，产生最终所需的软件产品 [公式] 

NOP不是编程，也不是不编程，它实际上是两种工作之间的一种新的相互配合方式。

用户所能直观理解的逻辑，也就是用户需要自己控制的业务需求，它们通过所谓的领域模型来表达，而领域模型可以通过可视化工具来进行自助式设计。需求人员是有足够的逻辑能力来表达自身需求的，他们只是不熟悉具体程序开发所需要的语言和工具而已。比如说，一般的需求人员都能熟练使用Excel、Visio等工具，并能够通过Excel公式、决策表、流程图等形式表达业务处理规则。

开发人员的工作可以看作是面向NOP编程（Nop Oriented Programming），他们所编写的不是对应具体需求的业务代码，而是对整个业务领域进行模型抽象，为业务用户提供可视化设计工具，并编写转换代码将领域模型映射为底层技术实现。对于部分很难进行直观展现的业务需求，开发人员能够通过差量编程的方式对已有模型进行补充和增强。

NOP的核心是具有可逆语义的领域模型空间。NOP以可逆计算为指导理论，它在各个层面上都强调可逆性。领域模型的可逆语义指的是机器在不需要人工参与的情况下，可以自动从领域模型中抽取信息（部分或全部），自动将其转换为所需形式，并自动应用到所需场景。

    人工参与的本质原因在于系统自身不具备可逆性，因此需要补充系统之外的信息，例如我们世界的背景知识，存在于其他文档中的全局设计信息，以及只存在于程序员头脑中的经验和设计思想等。一段通用语言编写的代码很可能无法通过工具自动分析得出其精确的设计意图，只有通过人这种最高级别的智能分析才可以实现逆向工程，反向抽取出其内在语义。但是如果采用精心设计的领域模型，则机器就可以很容易的理解模型语义，并在多种场景下以不同的方式使用同一信息。

在可逆语义假设下，我们很容易实现同一信息的多种展现形式，可视化设计仅仅是可逆语义的一个简单应用。

[公式]

领域模型采用领域特定语言（DSL）来描述，界面生成器可以理解DSL，从中抽取信息将其转换为可视化界面，同时界面生成器提供了对应的逆向信息提取机制，可以从生成的可视化界面中反向提取出DSL模型信息。所谓的可视化设计不过是模型的两种表现形式（representation）之间的可逆转换而已。

NOP要求每一个领域模型都能进行可视化设计，这表面上看起来是一个非常大的工作量，因为我们需要为每个领域模型都要提供相应的可视化设计工具。但是可逆计算理论指出可逆性可以复合，我们只需要构建一个通用的设计器的设计器，即所谓的元设计器，使用它就可以无限量的生成针对特定DSL的可逆的可视化设计器。

为了保证模型语义的可逆性，可视化设计器必须允许用户扩展，将用户特定的业务逻辑直接在DSL层面进行表达。否则，头脑简单的机器将无法直接理解复杂的用户逻辑。NOP中的设计器的设计器正是传统模型驱动架构（MDA）所缺失的部分。

NOP生产范式下的生产过程：

    需求人员与机器协作完成业务建模：需求人员不需与技术人员沟通，直接使用类似Office的可视化工具对业务逻辑进行描述。人工智能可以在这一过程中扮演辅助角色，例如分析多个数据样本与指定领域模型的匹配情况，从而自动建立初步的模型描述等。
    需求人员与机器协作完成业务验证：业务建模的结果是直接可以运行的系统，需求人员可以立刻从系统得到反馈，验证自己的业务设计。
    机器自动录制测试用例，执行测试用例，完成回归测试和压力测试：因为业务系统根据领域模型自动生成，所以机器掌握了系统内在的很多逻辑信息，它可以将用户的业务验证操作步骤直接录制为可以直观理解的测试脚本，作为回归测试用例和压力测试用例。机器也可以自动进行探索式测试，并将测试路径以用户可以直观理解的步骤形式展现出来。
    机器跟踪用户操作过程，结合用户录入的模型信息，推知用户意图，从而自动生成相应操作手册和文档等。并且可以录制用户操作过程，作为在线教程。系统运行出现异常时，也可以录制用户操作步骤，便于技术人员复查。
    机器根据领域模型，自动生成数据库设计、概要设计、详细设计等设计文档。
    程序员在业务模型基础上补充分布式部署架构等纯技术层面信息。
    程序员使用差量编程完成少部分特殊需求的代码实现。如果需求很常见，程序员使用元设计器（设计器的设计器）改进可视化工具，从而减少自己未来的工作量。
    机器根据领域模型，自动生成相应运维监控指标，并对关键性数据进行采集和记录。
    机器在系统运行过程中，利用大数据和人工智能对运行数据进行分析，自动进行局部程序优化，例如SQL执行计划、数据分布策略等。
    机器根据领域模型，自动发布对外服务接口，并根据转换模型自动实现集成数据格式转换等。

借助于具备可逆语义的领域模型空间，通过NOP方式生产的软件不再是一个封闭的黑箱，而是打破了信息载体的形式边界，使得信息可以在人和机器，以及机器与机器之间自由流动。

NOP将会带来新的工作分工方式，更多的非软件专业人员可以参与到业务逻辑的构建过程中来，扩大软件的应用领域，加快软件的演化速度。NOP极大简化了机器眼中的软件构造，使得人工智能和大数据更容易和具体应用相结合，可以快速推进AI技术落地。

NOP生产是从简单到复杂的一个连续进化过程，通过不断补充对领域模型的解释方式，细化领域模型的描述粒度，我们可以不断改进已有的软件。
四. NOP的本质

生产力决定生产关系，生产关系反作用于生产力。第四次工业革命意味着生产力新的飞越，伴随它的必然是生产关系的根本性变革。智能时代的本质是机器智能的崛起，机器不再是被动的工具，而是能力与日俱增，逐步成长为生产活动的主动参与者。同时，面对越来越复杂的应用场景，直接面对需求变化的相关人员也逐渐成熟起来，他们不再接受固定的软件功能，而是有着自己特定的利益诉求，希望能够主动参与到软件构造过程中，主导软件在应用过程中的调整和演化。

在这种背景下，NOP生产范式本质上所体现的正是生产关系的一种新的变化，它所强调的是开发人员、需求人员和机器三者之间的协同工作，或者说三者合作完成最终软件功能的实现和调整，每一方都有自己的价值和活动空间。

传统的软件生产其核心只有开发人员，所有最终的生产活动都是围绕开发人员组织实施的，这种单纯依靠编程（Programming）的生产模式将所有压力集中在程序员身上，导致程序员不堪重负(不996干得过来吗？)。


另一方面，人工智能的火热发展让人们浮想联翩，采用“人工智能写代码”看似是一条解决问题的捷径。但问题在于，目前的人工智能只是所谓的浅层智能，可以解决简单的判断、识别问题，无法进行更加复杂的逻辑组织，在可预见的未来，人工智能写代码还只是一个美好的设想，没有真正能够落地的技术方案。

实际上，目前计算机科学对于程序结构的理解过于简单，只有简单的函数、类、对象等概念，明显是无法支撑复杂逻辑的自动化构建的（对比物理学就可以知道，夸克、原子、分子、固体、液体、气体、凝聚态、等离子体...，我们掌握了多少物质形态和物理规律才创造了现代工业化生产体系）。

为了使得机器和非专业技术人员也能够平等的参与软件生产，我们必须要建立一种新的逻辑抽象方式，使得逻辑可以按照复杂性分级，简单的可以被直观理解的逻辑，以及简单的可以被机器自动识别处理的逻辑需要被明确分离出来。可逆计算理论为实现这种逻辑分离提供了一条可行的技术路线。特别是可逆概念的系统化应用将构建一个信息转化友好的逻辑世界，使得智能更容易产生和成长。

NOP是面向未来的软件生产范式，在强人工智能诞生之前，它代表了机器智能、专业开发知识以及其他领域的人类智能相互协作的一种典型方式。在追寻强人工智能的漫长旅途中，我们需要加深对软件所处的逻辑空间内在构造规律的认知，智能社会的实现不可能是一蹴而就的，NOP的发展将是人工智能不断扩大应用范围的必经之路。
五. NOP不是什么
（一）NOP不是可视化编程

可视化仅仅是NOP的一个副产品，并不是NOP的目标。NOP首先是采用创新的技术思想，基于领域模型和可逆性的概念极大降低了软件结构构造的复杂性。在NOP中，通过领域模型的抽象，我们对于软件结构的认知更加深刻了，表达同样的业务逻辑，相比于传统的编程方式，我们所需要传递的信息总量大大下降了。即使完全不使用可视化设计工具，我们的生产效率可以出现指数级的上升。

一般的可视化编程强调的是模型的可视化语义，导致程序语义只能通过可视化界面来理解。如果可视化设计器出错了，则我们没有任何其他途径可以越过可视化设计器来直接修改业务代码。如果我们对现有的可视化设计器不满意，没有任何技术手段可以对可视化设计器本身进行定制修改。当我们在多个业务场景中需要有不同形式的可视化设计器来设计同一底层模型时，也没有规范化的方案来保证多个设计器语义之间的一致性。

更为严重的问题是，一般的可视化编程为了降低自身实现难度，会要求业务代码的实现结构也针对可视化设计器做大量侵入性的修改。业务代码中能够使用的抽象手段受到极大限制，阻碍了业务模型的深度复用。同时，可视化设计器自身的升级修改也可能导致业务代码需要进行相应的调整。

在NOP中，强制要求所有领域模型都具有可逆语义，因此同一个模型很自然的可以具有多种展现形式，可视化设计仅仅是可逆语义的一个简单应用而已。在NOP中，不需要针对每一个领域模型单独编制其对应的可视化设计工具，元设计器可以利用模型的可逆语义自动的生成对应的设计器。
（二）NOP不是代码生成工具

NOP依赖于内置的代码生成器（Generator）来推导产生大量的衍生代码，但这种代码生成是一个抽象的概念，它类似于反复应用不同的数学定理来推导产生新的定理，具体实现中可以对应很多种不同的实现手段。

一般概念中的代码生成工具都是单向的、一次性的脚手架生成器。程序员设计好模型后，手工运行代码生成工具，根据模型生成脚手架代码，然后程序员再手工调整生成出来的代码，填充更多的细节等。如果模型发生变动，重新运行代码生成工具时将导致已生成的代码被覆盖，手工调整的部分将会丢失。在这种开发模式中，代码是第一位的，而模型是相对次要的、仅起参考作用的。当代码和模型冲突时，胜出的永远是代码。

NOP中，模型是第一位的，代码必须永远与模型保持一致。因此，NOP中的代码生成机制应该采用类似C++模板元编程（Template Metaprogramming）的编译期模板展开技术来实现。当模型发生变化时，由编译器自动重新生成代码，无需程序员手工操作。同时，基于可逆计算理论，NOP是支持增量模型变化的，当模型变动时不会覆盖程序员手工编写的代码，而只会传播模型的增量变化部分，同时自动实现模型代码和程序员手工编写代码之间的差量合并。
（三）NOP不是零代码开发

零代码（zero-code/no-code）开发平台的目标用户不是专业程序员，而是具有一定技术理解力的业务人员，它强调的是普通人经过简单培训即可独立实现业务软件模块的快速开发。为了尽量减少对业务人员的技术储备要求，同时尽量降低业务人员在操作过程中出错的可能性，零代码开发平台唯一的选择就是尽可能多的替用户做决定，呈现给用户尽量少的技术选项。因此，零代码开发平台如果好用、易用，就必然是用途非常狭窄的、功能固化的。它一般只针对小型系统，很少考虑架构层面的可扩展性，也很少考虑性能、安全性等非功能性需求。

为了克服零代码开发的弊端，最近几年还出现了一种所谓的低代码开发（Low-code Development）模式，它通过可视化设计结合少量编码的方式极大扩充了自身适用的应用范围。

NOP面向的群体是专业程序员以及业务人员，它能够支持从简单的小型应用（如普通的OA和MIS系统）到复杂的大型关键性应用（如银行核心系统）之间的连续演化，可以有效的实现专业程序员和业务人员之间的分工协作。专业程序员的核心价值在于建立领域抽象，将业务领域中常见的逻辑组织模式通过领域特定语言（DSL）和业务组件的方式固化下来。业务人员在已经确定的技术范围之内，就可以使用可视化设计工具创建和修改领域模型（使用DSL来表示），从而实现业务功能模块的开发。

NOP不仅仅不是零代码开发，它也不是低代码开发。零代码开发是完全没有扩展能力，低代码开发是允许开发人员编写第三方组件和插件，在一定程度上扩展可视化开发工具的能力。但是低代码开发平台的扩展能力仍然是非常受限的，这典型的就表现为low code开发平台本身并不是使用low code开发技术开发出来的，而且low code开发平台一般会给扩展代码增加大量限制性要求，这对于开发人员而言，意味着他所能动用的技术武器库是有着明显倒退的。

而NOP与low code的不同之处在于，NOP的理论基础是可逆计算理论而不是模型驱动架构（MDA）和组件/构件理论，它从本质上摆脱了现有主流技术体制对软件构造过程的基本限制。在NOP中，所有的领域模型设计器都是基于可逆计算原则利用元设计器逐步构建出来的。
（四）NOP不是更强大、更高级的程序语言

从汇编到Fortran，到C/C++语言，再到Java/C#语言，一路走来，程序语言的抽象层次在不断提高，越来越多的通用逻辑结构被内置到语言中，语言变得越来越强大。一些现代高级语言不断追求代码形式的表现力，如号称综合了面向对象和函数式编程等多种编程范式的Scala语言，往往一句话可以顶传统编程语言的n句。所谓第四代程序语言（4GL）更是内置了数据库管理、界面布局等大量针对特定领域的语言结构，使得开发专项应用时如鱼得水。

NOP的核心并不是一个单一的、与现有编程语言相比更加强大的高级程序语言，它强调的是由大量不同的领域特定语言（DSL）所共同构建的领域模型空间，以及领域模型空间中所需要满足的可逆性原则。如果仔细回顾一下历史，我们会发现，传统的编程语言都是图灵完备的通用程序语言。通过不断引入强大的通用语言结构，我们在所有业务领域都免费获得了新的更高层次的抽象能力，每一代的程序语言都相当于是更好的、更强大的图灵机。

但是正如摩尔定律终将走到尽头，通用程序语言的这种免费的抽象提升也逐渐陷入停滞，这表现为主流程序语言内置的语言特性开始出现加速趋同的倾向。不同的语言具有类似的语言特性，它们在某种意义上是完全等价的，差别仅仅是语法形式上的，或者说是文化习惯上的。

可逆计算理论指出可以定义一个新的通用语言结构：可逆的差量运算，从而再一次为所有领域免费提供了抽象提升的机会。但这一概念真正的重要性在于，它打开了一条与此前完全不同的抽象上升通道。可逆计算将领域特定语言（DSL）推到了应用前台，而DSL相比于通用语言不是更强大，只是更有用。

在可逆计算理论中，DSL需要超越通用语言提供针对特定领域的更有效的逻辑表达形式，同时在结构层面需要满足某种可逆性要求，DSL为了将某一方面推进到极致就必须放弃很多其他方面的能力，导致它往往不是图灵完备的！

NOP中，大量图灵不完备的、只针对特定领域的DSL构成一个语言森林，我们不再依赖单一的、固定的语法结构，而是直面世界的复杂性，开始构建细腻丰富的结构层次。同时，NOP中需要根据领域模型推导生成衍生代码，这在DSL层之下开辟了一个新的战场：编译器所在的元模型空间。传统上，程序语言的语法规则是固定的，即使是内置领域相关结构的第四代程序语言（4GL），也是不允许程序员定制和选择编译规则的。NOP中，代码生成规则也只是普通的代码，程序员可以自由的定制和扩充，整个编译规则空间是图灵完备的。NOP打破了旧世界对程序员创造力的桎梏，就像一句口号所鼓吹的，未来“只有想不到，没有做不到”。
（五）NOP不是人工智能

NOP虽然致力于解决智能时代的软件生产力瓶颈问题，但是它并不依赖于人工智能的概念和技术，它与人工智能是一种相辅相成的关系。

人工智能可以作为庞大的充满不确定性的世界和确定性的小型模型空间之间的一个桥梁。

[公式]

或者作为更加人性化的输入输出接口

[公式]

NOP通过可逆的领域模型简化了人工智能所需要处理的逻辑结构，并可以利用人工智能来与人类世界以及大数据世界交互。人工智能负责解决的问题往往是局部性的非常困难的技术问题，它要发挥最大作用还需要和周边系统和人员发生协同作用，而NOP所提供的正是一种整体解决方案。

以下为闲聊时间

TL;DR

不知诸位看官有没有发现，业内与差量（Delta）相关的概念正如同雨后春笋一样纷纷冒头。前段时间Databricks公司发布新产品，干脆直接叫作Delta Lake。搞神经网络的家伙们也沿着ResNet越走越远，最近流行的概念已经是differential programming。这反映了整个业界正在经历从全量思维向差量思维的转变，差量革命一触即发。

很多人已经敏锐的意识到了技术发展到了一个转折点，一种新的技术可能性已经出现。现在这种情形其实非常类似多年以前Ajax和Agile概念诞生的前夕，有很多独立的实践，有各种聪明的实现，但是还缺乏一个有灵魂的概念，能够把它们统摄在一个具有普遍意义的命题之下。

我的观点是差量不仅仅是简单的差别、增量、变化，可逆才是它的灵魂！可逆计算理论可以为下一代软件构造提供一个合适的理论框架，突破简单的组件式、积木式构建思想的束缚，为前端的、后端的、应用层的、系统层的等等诸多表面上形式不同的逻辑构造方案找到统一的理论解释，并推动它们的协同演化。当从细部到整体，从内部组成到外部环境，各个层面都满足可逆性要求时，软件的构造将出现真正本质性的变化。
canonical：可逆计算：下一代软件构造理论131 赞同 · 41 评论文章

智能时代的软件需求必然催生新的软件生产模式。国外逐渐开始出现所谓的Low Code开发模式，而国内也是一众的免编程、No Code的某某云。但是这些概念在感觉上总是差点意思。

No Code基本上就是No Brain，注定无法生产足够复杂的商业逻辑。而Low Code听着也有点"low"(谁让它的名字里就带个low字呢)，而且Code的概念是程序员圈子里的“黑话”，投资人不一定懂，万一说你这是码农思维，那还怎么从他身上扎钱呢？

其实，免编程也好，快速开发也好，直接作为生产力工具在中国的大环境里不一定有着很大的实际优势。我们有着奋斗者的精神，有996/007的福报，税务上再找点"优惠"，整体利润瓶颈不一定在人工上。再说，很多系统的建设目的本来就不是为了用的，toB市场的水，深不见底。

NOP是我们团队所提出的一个新的概念。它的核心不是简单的降低生产成本，而是可以促成新的分工方式，从而促进软件形态的变革，创造新的商业模式。另外，关键的关键，是它的名字起得好啊！

    NP ?= P 是计算机科学的核心问题之一。 NP中间加上一个元音o之后，发音朗朗上口。 NOP是Nop is nOt Programming和Nop Oriented Programming的递归缩写，这符合黑客社区的传统。 nop在计算机领域也有空操作的意思，这符合可逆计算“正+负=空”的思想。

总之，NOP即有理论支撑，又有文化渊源，高端大气上档次有木有？总而言之，这么闪亮的概念，你值得拥有。我们的口号是You can Nop it!

码这么多字，目的就是为了传播可逆计算和NOP的思想。希望更多的架构师能够从单纯的业务系统构建过程暂停一下，喘喘气，将思考的方向从如何构建好用/高效的系统转向如何将更多的逻辑分离，如何通过差量的方式表达逻辑。它的目的不一定是提高生产力，而首先是为了加深我们对世界基本构造规律的认识。

前段时间，和 @徐飞 、 @侯振宇 等人也作了简短沟通，交流了一下业界情况和相关技术方案，发现很多队伍已经上路了，看起来还都兵强马壮的样子。欢迎有兴趣的同仁和我联系（canonical_entropy@163.com），共同探讨未来软件的架构模式。

支付宝现在跑得很快，一些做法可以纳入到NOP的范畴中考察。侯振宇对此作了很好的总结，很值得参考一下。
侯振宇：长夜未央——企业级研发提效的下一阶段170 赞同 · 11 评论文章
侯振宇：十倍效能提升——Web 基础研发体系的建立647 赞同 · 30 评论文章


听风看雨，无问西东。

生死看淡，不服就干！
编辑于 2022-04-24 22:16

]]
[[
https://zhuanlan.zhihu.com/p/64004026

canonical
千山万水
可逆计算：下一代软件构造理论
25 天前 · 来自专栏 可逆计算

    谨以此文庆祝清华建校108周年，及5字班本科毕业20周年

作者： Canonical

众所周知，计算机科学得以存在的基石是两个基本理论：图灵于1936年提出的图灵机理论和丘奇同年早期发表的Lambda演算理论。这两个理论奠定了所谓通用计算（Universal Computation）的概念基础，描绘了具有相同计算能力（图灵完备），但形式上却南辕北辙、大相径庭的两条技术路线。如果把这两种理论看作是上帝所展示的世界本源面貌的两个极端，那么是否存在一条更加中庸灵活的到达通用计算彼岸的中间路径?

自1936年以来，软件作为计算机科学的核心应用，一直处在不间断的概念变革过程中，各类程序语言/系统架构/设计模式/方法论层出不穷，但是究其软件构造的基本原理，仍然没有脱出两个基本理论最初所设定的范围。如果定义一种新的软件构造理论，它所引入的新概念本质上能有什么特异之处？能够解决什么棘手的问题？

本文中笔者提出在图灵机和lambda演算的基础上可以很自然的引入一个新的核心概念--可逆性，从而形成一个新的软件构造理论--可逆计算（Reversible Computation）。可逆计算提供了区别于目前业内主流方法的更高层次的抽象手段，可以大幅降低软件内在的复杂性，为粗粒度软件复用扫除了理论障碍。

可逆计算的思想来源不是计算机科学本身，而是理论物理学，它将软件看作是处于不断演化过程中的抽象实体， 在不同的复杂性层次上由不同的运算规则所描述，它所关注的是演化过程中产生的微小差量如何在系统内有序的传播并发生相互作用。

本文第一节将介绍可逆计算理论的基本原理与核心公式，第二节分析可逆计算理论与组件和模型驱动等传统软件构造理论的区别和联系，并介绍可逆计算理论在软件复用领域的应用，第三节从可逆计算角度解构Docker、React等创新技术实践。
一. 可逆计算的基本原理

可逆计算可以看作是在真实的信息有限的世界中，应用图灵计算和lambda演算对世界建模的一种必然结果，我们可以通过以下简单的物理图像来理解这一点。

首先，图灵机是一种结构固化的机器，它具有可枚举的有限的状态集合，只能执行有限的几条操作指令，但是可以从无限长的纸带上读取和保存数据。例如我们日常使用的电脑，它在出厂的时候硬件功能就已经确定了，但是通过安装不同的软件，传入不同的数据文件，最终它可以自动产生任意复杂的目标输出。图灵机的计算过程在形式上可以写成

[公式]

与图灵机相反的是，lambda演算的核心概念是函数，一个函数就是一台小型的计算机器，函数的复合仍然是函数，也就是说可以通过机器和机器的递归组合来产生更加复杂的机器。lambda演算的计算能力与图灵机等价，这意味着如果允许我们不断创建更加复杂的机器，即使输入一个常数0，我们也可以得到任意复杂的目标输出。lambda演算的计算过程在形式上可以写成

[公式]

可以看出，以上两种计算过程都可以被表达为Y=F(X) 这样一种抽象的形式。如果我们把Y=F(X)理解为一种建模过程，即我们试图理解输入的结构以及输入和输出之间的映射关系，采用最经济的方式重建输出，则我们会发现图灵机和lambda演算都假定了现实世界中无法满足的条件。在真实的物理世界中，人类的认知总是有限的，所有的量都需要区分已知的部分和未知的部分，因此我们需要进行如下分解：

[公式]

重新整理一下符号，我们就得到了一个适应范围更加广泛的计算模式

[公式]

除了函数运算F(X)之外，这里出现了一个新的结构运算符⊕，它表示两个元素之间的合成运算，并不是普通数值意义上的加法，同时引出了一个新的概念：差量△。△的特异之处在于，它必然包含某种负元素，F(X)与△合并在一起之后的结果并不一定是“增加”了输出，而完全可能是“减少”。

在物理学中，差量△存在的必然性以及△包含逆元这一事实完全是不言而喻的，因为物理学的建模必须要考虑到两个基本事实：

    世界是“测不准”的，噪声永远存在 模型的复杂度要和问题内在的复杂度相匹配，它捕获的是问题内核中稳定不变的趋势及规律。

例如，对以下的数据 ​ ​

我们所建立的模型只能是类似图(a)中的简单曲线，图(b)中的模型试图精确拟合每一个数据点在数学上称之为过拟合，它难以描述新的数据，而图(c)中限制差量只能为正值则会极大的限制模型的描述精度。

以上是对Y=F(X)⊕△这一抽象计算模式的一个启发式说明，下面我们将介绍在软件构造领域落实这一计算模式的一种具体技术实现方案，笔者将其命名为可逆计算。 所谓可逆计算，是指系统化的应用如下公式指导软件构造的一种技术路线

[公式]

    App : 所需要构建的目标应用程序
    DSL: 领域特定语言（Domain Specific Language），针对特定业务领域定制的业务逻辑描述语言，也是所谓领域模型的文本表示形式
    Generator : 根据领域模型提供的信息，反复应用生成规则可以推导产生大量的衍生代码。实现方式包括独立的代码生成工具，以及基于元编程（Metaprogramming）的编译期模板展开
    Biz : 根据已知模型推导生成的逻辑与目标应用程序逻辑之间的差异被识别出来，并收集在一起，构成独立的差量描述
    aop_extends: 差量描述与模型生成部分通过类似面向切面编程（Aspect Oriented Programming）的技术结合在一起，这其中涉及到对模型生成部分的增加、修改、替换、删除等一系列操作 

DSL是对关键性领域信息的一种高密度的表达，它直接指导Generator生成代码，这一点类似于图灵计算通过输入数据驱动机器执行内置指令。而如果把Generator看作是文本符号的替换生成，则它的执行和复合规则完全就是lambda演算的翻版。差量合并在某种意义上是一种很新奇的操作，因为它要求我们具有一种细致入微、无所不达的变化收集能力，能够把散布系统各处的同阶小量分离出来并合并在一起，这样差量才具有独立存在的意义和价值。同时，系统中必须明确建立逆元和逆运算的概念，在这样的概念体系下差量作为“存在”与“不存在”的混合体才可能得到表达。

现有的软件基础架构如果不经过彻底的改造，是无法有效的实施可逆计算的。正如图灵机模型孕育了C语言，Lambda演算促生了Lisp语言一样，为了有效支持可逆计算，笔者提出了一种新的程序语言X语言，它内置了差量定义、生成、合并、拆分等关键特性，可以快速建立领域模型，并在领域模型的基础上实现可逆计算。

为了实施可逆计算，我们必须要建立差量的概念。变化产生差量，差量有正有负，而且应该满足下面三条要求：

    差量独立存在差量相互作用差量具有结构

在第三节中笔者将会以Docker为实例说明这三条要求的重要性。

可逆计算的核心是“可逆”，这一概念与物理学中熵的概念息息相关，它的重要性其实远远超出了程序构造本身，在可逆计算的方法论来源一文中，笔者会对它有更详细的阐述。

正如复数的出现扩充了代数方程的求解空间，可逆计算为现有的软件构造技术体系补充了“可逆的差量合并”这一关键性技术手段，从而极大扩充了软件复用的可行范围，使得系统级的粗粒度软件复用成为可能。同时在新的视角下，很多原先难以解决的模型抽象问题可以找到更加简单的解决方案，从而大幅降低了软件构造的内在复杂性。在第二节中笔者将会对此进行详细阐述。

软件开发虽然号称是知识密集性的工作，但到目前为止，众多一线程序员的日常中仍然包含着大量代码拷贝/粘贴/修改的机械化手工操作内容，而在可逆计算理论中，代码结构的修改被抽象为可自动执行的差量合并规则，因此通过可逆计算，我们可以为软件自身的自动化生产创造基础条件。笔者在可逆计算理论的基础上，提出了一个新的软件工业化生产模式NOP（Nop is nOt Programming），以非编程的方式批量生产软件。NOP不是编程，但也不是不编程，它强调的是将业务人员可以直观理解的逻辑与纯技术实现层面的逻辑相分离，分别使用合适的语言和工具去设计，然后再把它们无缝的粘接在一起。笔者将在另一篇文章中对NOP进行详细介绍。

可逆计算与可逆计算机有着同样的物理学思想来源，虽然具体的技术内涵并不一致，但它们目标却是统一的。正如云计算试图实现计算的云化一样，可逆计算和可逆计算机试图实现的都是计算的可逆化。
二. 可逆计算对传统理论的继承和发展
（一）组件（Component）

软件的诞生源于数学家研究希尔伯特第十问题时的副产品，早期软件的主要用途也是数学物理计算，那时软件中的概念无疑是抽象的、数学化的。随着软件的普及，越来越多应用软件的研发催生了面向对象和组件化的方法论，它试图弱化抽象思维，转而贴近人类的常识，从人们的日常经验中汲取知识，把业务领域中人们可以直观感知的概念映射为软件中的对象，仿照物质世界的生产制造过程从无到有、从小到大，逐步拼接组装实现最终软件产品的构造。

像框架、组件、设计模式、架构视图等软件开发领域中耳熟能详的概念，均直接来自于建筑业的生产经验。组件理论继承了面向对象思想的精华，借助可复用的预制构件这一概念，创造了庞大的第三方组件市场，获得了空前的技术和商业成功，即使到今天仍然是最主流的软件开发指导思想。但是，组件理论内部存在着一个本质性的缺陷，阻碍了它把自己的成功继续推进到一个新的高度。

我们知道，所谓复用就是对已有的制成品的重复使用。为了实现组件复用，我们需要找到两个软件中的公共部分，把它分离出来并按照组件规范整理成标准形式。但是，A和B的公共部分的粒度是比A和B都要小的，大量软件的公共部分是比它们中任何一个的粒度都要小得多的。这一限制直接导致越大粒度的软件功能模块越难以被直接复用，组件复用存在理论上的极限。可以通过组件组装复用60%-70%的工作量，但是很少有人能超过80%，更不用说实现复用度90%以上的系统级整体复用了。

为了克服组件理论的局限，我们需要重新认识软件的抽象本质。软件是在抽象的逻辑世界中存在的一种信息产品，信息并不是物质。抽象世界的构造和生产规律与物质世界是有着本质不同的。物质产品的生产总是有成本的，而复制软件的边际成本却可以是0。将桌子从房间中移走在物质世界中必须要经过门或窗，但在抽象的信息空间中却只需要将桌子的坐标从x改为-x而已。抽象元素之间的运算关系并不受众多物理约束的限制，因此信息空间中最有效的生产方式不是组装，而是掌握和制定运算规则。

如果从数学的角度重新去解读面向对象和组件技术，我们会发现可逆计算可以被看作是组件理论的一个自然扩展。

    面向对象 : 不等式 A > B 组件 : 加法 A = B + C 可逆计算 : 差量 Y = X + △Y 

面向对象中的一个核心概念是继承：派生类从基类继承，自动具有基类的一切功能。例如老虎是动物的一种派生类，在数学上，我们可以说老虎(A)这个概念所包含的内容比动物(B)这个概念更多，老虎>动物（即A>B）。据此我们可以知道，动物这个概念所满足的命题，老虎自然满足， 例如动物会奔跑，老虎必然也会奔跑（ P(B) -> P(A) ）。程序中所有用到动物这一概念的地方都可以被替换为老虎（Liscov代换原则）。这样通过继承就将自动推理关系引入到软件领域中来，在数学上这对应于不等式，也就是一种偏序关系。

面向对象的理论困境在于不等式的表达能力有限。对于不等式A > B，我们知道A比B多，但是具体多什么，我们并没有办法明确的表达出来。而对于 A > B， D > E这样的情况，即使多出来的部分一模一样，我们也无法实现这部分内容的重用。组件技术明确指出"组合优于继承"，这相当于引入了加法

[公式]

这样就可以抽象出组件C进行重用。

沿着上述方向推演下去，我们很容易确定下一步的发展是引入“减法”，这样才可以把 A = B + C看作是一个真正的方程，通过方程左右移项求解出

[公式]

通过减法引入的“负组件”是一个全新的概念，它为软件复用打开了一扇新的大门。

假设我们已经构建好了系统 X = D + E + F， 现在需要构建 Y = D + E + G。如果遵循组件的解决方案，则需要将X拆解为多个组件，然后更换组件F为G后重新组装。而如果遵循可逆计算的技术路线，通过引入逆元 -F， 我们立刻得到

[公式]

在不拆解X的情况下，通过直接追加一个差量△Y，即可将系统X转化为系统Y。

组件的复用条件是“相同方可复用”，但在存在逆元的情况下，具有最大颗粒度的完整系统X在完全不改的情况下直接就可以被复用，软件复用的范围被拓展为“相关即可复用”，软件复用的粒度不再有任何限制。组件之间的关系也发生了深刻的变化，不再是单调的构成关系，而成为更加丰富多变的转化关系。

Y = X + △Y 这一物理图像对于复杂软件产品的研发具有非常现实的意义。X可以是我们所研发的软件产品的基础版本或者说主版本，在不同的客户处部署实施时，大量的定制化需求被隔离到独立的差量△Y中，这些定制的差量描述单独存放，通过编译技术与主版本代码再合并到一起。主版本的架构设计和代码实现只需要考虑业务领域内稳定的核心需求，不会受到特定客户处偶然性需求的冲击，从而有效的避免架构腐化。主版本研发和多个项目的实施可以并行进行，不同的实施版本对应不同的△Y，互不影响，同时主版本的代码与所有定制代码相互独立，能够随时进行整体升级。
（二）模型驱动架构（Model Driven Architecture)

模型驱动架构（MDA）是由对象管理组织（Object Management Group，OMG）在2001年提出的软件架构设计和开发方法，它被看作是软件开发模式从以代码为中心向以模型为中心转变的里程碑，目前大部分所谓软件开发平台的理论基础都与MDA有关。

MDA试图提升软件开发的抽象层次，直接使用建模语言（例如Executable UML）作为编程语言，然后通过使用类似编译器的技术将高层模型翻译为底层的可执行代码。在MDA中，明确区分应用架构和系统架构，并分别用平台无关模型PIM（Platform Independent Model）和平台相关模型PSM（Platform Specific Model）来描述它们。PIM反映了应用系统的功能模型，它独立于具体的实现技术和运行框架，而PSM则关注于使用特定技术（例如J2EE或者dotNet）实现PIM所描述的功能，为PIM提供运行环境。

使用MDA的理想场景是，开发人员使用可视化工具设计PIM，然后选择目标运行平台，由工具自动执行针对特定平台和实现语言的映射规则，将PIM转换为对应的PSM，并最终生成可执行的应用程序代码。基于MDA的程序构造可以表述为如下公式

[公式]

MDA的愿景是像C语言取代汇编那样最终彻底消灭传统编程语言。但经历了这么多年发展之后，它仍未能够在广泛的应用领域中展现出相对于传统编程压倒性的竞争优势。

事实上，目前基于MDA的开发工具在面对多变的业务领域时，总是难掩其内在的不适应性。根据本文第一节的分析，我们知道建模必须要考虑差量。而在MDA的构造公式中，左侧的App代表了各种未知需求，而右侧的Transformer和PIM的设计器实际上都主要由开发工具厂商提供，未知=已知这样一个方程是无法持久保持平衡的。

目前，工具厂商的主要做法是提供大而全的模型集合，试图事先预测用户所有可能的业务场景。但是，我们知道“天下没有免费的午餐”，模型的价值在于体现了业务领域中的本质性约束，没有任何一个模型是所有场景下都最优的。预测需求会导致出现一种悖论: 模型内置假定过少，则无法根据用户输入的少量信息自动生成大量有用的工作，也无法防止用户出现误操作，模型的价值不明显，而如果反之，模型假定很多，则它就会固化到某个特定业务场景，难以适应新的情况。

打开一个MDA工具的设计器，我们最经常的感受是大部分选项都不需要，也不知道是干什么用的，需要的选项却到处找也找不到。

可逆计算对MDA的扩展体现为两点：

    可逆计算中Generator和DSL都是鼓励用户扩充和调整的，这一点类似于面向语言编程（Language-oriented programming）。 存在一个额外的差量定制机会，可以对整体生成结果进行精确的局部修正。

在笔者提出的NOP生产模式中，必须要包含一个新的关键组件：设计器的设计器。普通的程序员可以利用设计器的设计器快速设计开发自己的领域特定语言（DSL）及其可视化设计器，同时可以通过设计器的设计器对系统中的任意设计器进行定制调整，自由的增加或者删除元素。
（三）面向切面编程（Aspect Oriented Programming)

面向切面（AOP）是与面向对象（OOP）互补的一种编程范式，它可以实现对那些横跨多个对象的所谓横切关注点（cross-cutting concern）的封装。例如，需求规格中可能规定所有的业务操作都要记录日志，所有的数据库修改操作都要开启事务。如果按照面向对象的传统实现方式，需求中的一句话将会导致众多对象类中陡然膨胀出现大量的冗余代码，而通过AOP， 这些公共的“修饰性”的操作就可以被剥离到独立的切面描述中。这就是所谓纵向分解和横向分解的正交性。

AOP本质上是两个能力的组合：

    在程序结构空间中定位到目标切点（Pointcut）对局部程序结构进行修改，将扩展逻辑（Advice)编织(Weave)到指定位置。

定位依赖于存在良好定义的整体结构坐标系（没有坐标怎么定位？），而修改依赖于存在良好定义的局部程序语义结构。目前主流的AOP技术的局限性在于，它们都是在面向对象的语境下表达的，而领域结构与对象实现结构并不总是一致的，或者说用对象体系的坐标去表达领域语义是不充分的。例如，申请人和审批人在领域模型中是需要明确区分的不同的概念，但是在对象层面却可能都对应于同样的Person类，使用AOP的很多时候并不能直接将领域描述转换为切点定义和Advice实现。这种限制反映到应用层面，结果就是除了日志、事务、延迟加载、缓存等少数与特定业务领域无关的“经典”应用之外，我们找不到AOP的用武之地。

可逆计算需要类似AOP的定位和结构修正能力，但是它是在领域模型空间中定义这些能力的，因而大大扩充了AOP的应用范围。特别是，可逆计算中领域模型自我演化产生的结构差量△能够以类似AOP切面的形式得到表达。

我们知道，组件可以标识出程序中反复出现的“相同性”，而可逆计算可以捕获程序结构的“相似性”。相同很罕见，需要敏锐的甄别，但是在任何系统中，有一种相似性都是唾手可得的，即动力学演化过程中系统与自身历史快照之间的相似性。这种相似性在此前的技术体系中并没有专门的技术表达形式。

通过纵向和横向分解，我们所建立的概念之网存在于一个设计平面当中，当设计平面沿着时间轴演化时，很自然的会产生一个“三维”映射关系：后一时刻的设计平面可以看作是从前一时刻的平面增加一个差量映射（定制）而得到，而差量是定义在平面的每一个点上的。这一图像类似于范畴论（Category Theory）中的函子（Functor）概念，可逆计算中的差量合并扮演了函子映射的角色。因此，可逆计算相当于扩展了原有的设计空间，为演化这一概念找到了具体的一种技术表现形式。
（四）软件产品线（Software Product Line）

软件产品线理论源于一个洞察，即在一个业务领域中，很少有软件系统是完全独特的，大量的软件产品之间存在着形式和功能的相似性，可以归结为一个产品家族，把一个产品家族中的所有产品（已存在的和尚未存在的）作为一个整体来研究、开发、演进，通过科学的方法提取它们的共性，结合有效的可变性管理，就有可能实现规模化、系统化的软件复用，进而实现软件产品的工业化生产。

软件产品线工程采用两阶段生命周期模型，区分领域工程和应用工程。所谓领域工程，是指分析业务领域内软件产品的共性，建立领域模型及公共的软件产品线架构，形成可复用的核心资产的过程，即面向复用的开发（development for reuse）。而应用工程，其实质是使用复用来开发（ development with reuse），也就是利用已经存在的体系架构、需求、测试、文档等核心资产来制造具体应用产品的生产活动。

卡耐基梅隆大学软件工程研究所（CMU-SEI）的研究人员在2008年的报告中宣称软件产品线可以带来如下好处：

    提升10倍以上生产率 提升10倍以上产品质量 缩减60%以上成本 缩减87%以上人力需求 缩减98%以上产品上市时间 进入新市场的时间以月计，而不是年

软件产品线描绘的理想非常美好：复用度90%以上的产品级复用、随需而变的敏捷定制、无视技术变迁影响的领域架构、优异可观的经济效益等等。它所存在的唯一问题就是如何才能做到？尽管软件产品线工程试图通过综合利用所有管理的和技术的手段，在组织级别策略性的复用一切技术资产（包括文档、代码、规范、工具等等），但在目前主流的技术体制下，发展成功的软件产品线仍然面临着重重困难。

可逆计算的理念与软件产品线理论高度契合，它的技术方案为软件产品线的核心技术困难---可变性管理带来了新的解决思路。在软件产品线工程中，传统的可变性管理主要是适配、替换和扩展这三种方式：

这三种方式都可以看作是向核心架构补充功能。但是可复用性的障碍不仅仅是来自于无法追加新的功能，很多时候也在于无法屏蔽原先已经存在的功能。传统的适配技术等要求接口一致匹配，是一种刚性的对接要求，一旦失配必将导致不断向上传导应力，最终只能通过整体更换组件来解决问题。可逆计算通过差量合并为可变性管理补充了“消除”这一关键性机制，可以按需在领域模型空间中构建出柔性适配接口，从而有效的控制变化点影响范围。

可逆计算中的差量虽然也可以被解释为对基础模型的一种扩展，但是它与插件扩展技术之间还是存在着明显的区别。在平台-插件这样的结构中，平台是最核心的主体，插件依附于平台而存在，更像是一种补丁机制，在概念层面上是相对次要的部分。而在可逆计算中，通过一些形式上的变换，我们可以得到一个对称性更高的公式：

[公式]

如果把G看作是一种相对不变的背景知识，则形式上我们可以把它隐藏起来，定义一个更加高级的“括号”运算符，它类似于数学中的“内积”。在这种形式下，B和D是对偶的，B是对D的补充，而D也是对B的补充。同时，我们注意到G(D)是模型驱动架构的体现，模型驱动之所以有价值就在于模型D中发生的微小变化，可以被G放大为系统各处大量衍生的变化，因此G(D)是一种非线性变换，而B是系统中去除D所对应的非线性因素之后剩余的部分。当所有复杂的非线性影响因素都被剥离出去之后，最后剩下的部分B就有可能是简单的，甚至能够形成一种新的可独立理解的领域模型结构(可以类比声波与空气的关系，声波是空气的扰动，但是不用研究空气本体，我们就可以直接用正弦波模型来描述声波)。

A = (B,D)的形式可以直接推广到存在更多领域模型的情况

[公式]

因为B、D、E等概念都是某种DSL所描述的领域模型，因此它们可以被解释为A投影到特定领域模型子空间所产生的分量，也就是说，应用A可以被表示为一个“特征向量”（Feature Vector）， 例如

[公式]

与软件产品线中常用的面向特征编程（Feature Oriented Programming）相比，可逆计算的特征分解方案强调领域特定描述，特征边界更加明确，特征合成时产生的概念冲突更容易处理。

特征向量本身构成更高维度的领域模型，它可以被进一步分解下去，从而形成一个模型级列，例如定义

[公式]

, 并且假设D'可以继续分解

[公式]

，则可以得到

[公式]

最终我们可以通过领域特征向量U'来描述D’，然后再通过领域特征向量D‘来描述原有的模型A。

可逆计算的这一构造策略类似于深度神经网络，它不再局限于具有极多可调参数的单一模型，而是建立抽象层级不同、复杂性层级不同的一系列模型，通过逐步求精的方式构造出最终的应用。

在可逆计算的视角下，应用工程的工作内容变成了使用特征向量来描述软件需求，而领域工程则负责根据特征向量描述来生成最终的软件。
三. 初露端倪的差量革命
（一）Docker

Docker是2013年由创业公司dotCloud开源的应用容器引擎，它可以将任何应用及其依赖的环境打包成一个轻量级、可移植、自包含的容器（Container），并据此以容器为标准化单元创造了一种新型的软件开发、部署和交付形式。

Docker一出世就秒杀了Google的亲儿子lmctfy （Let Me Contain That For You）容器技术，同时也把Google的另一个亲儿子Go语言迅速捧成了网红，之后Docker的发展 更是一发而不可收拾。2014年开始一场Docker风暴席卷全球，以前所未有的力度推动了操作系统内核的变革，在众多巨头的跟风造势下瞬间引爆容器云市场，真正从根本上改变了企业应用从开发、构建到部署、运行整个生命周期的技术形态。

Docker技术的成功源于它对软件运行时复杂性的本质性降低，而它的技术方案可以看作是可逆计算理论的一种特例。Docker的核心技术模式可以用如下公式进行概括

[公式]

Dockerfile是构建容器镜像的一种领域特定语言，例如

FROM ubuntu:16.04
RUN useradd --user-group --create-home --shell /bin/bash work
RUN apt-get update -y && apt-get install -y python3-dev
COPY . /app
RUN make /app

ENV PYTHONPATH /FrameworkBenchmarks
CMD python /app/app.py

EXPOSE 8088

通过Dockerfile可以快速准确的描述容器所依赖的基础镜像，具体的构建步骤，运行时环境变量和系统配置等信息。

Docker应用程序扮演了可逆计算中Generator的角色，负责解释Dockerfile，执行对应的指令来生成容器镜像。

创造性的使用联合文件系统（Union FS），是Docker的一个特别的创新之处。这种文件系统采用分层的构造方式，每一层构建完毕后就不会再发生改变，在后一层上进行的任何修改都只会记录在自己这一层。例如，修改前一层的文件时会通过Copy-On-Write的方式复制一份到当前层，而删除前一层的文件并不会真的执行删除操作，而是仅在当前层标记该文件已删除。Docker利用联合文件系统来实现将多个容器镜像合成为一个完整的应用，这一技术的本质正是可逆计算中的aop_extends操作。

Docker的英文是码头搬运工人的意思，它所搬运的容器也经常被人拿来和集装箱做对比：标准的容器和集装箱类似，使得我们可以自由的对它们进行传输/组合，而不用考虑容器中的具体内容。但是这种比较是肤浅的，甚至是误导性的。集装箱是静态的、简单的、没有对外接口的，而容器则是动态的、复杂的、和外部存在着大量信息交互的。这种动态的复杂结构想和普通的静态物件一样封装成所谓标准容器，其难度不可同日而语。如果没有引入支持差量的文件系统，是无法构建出一种柔性边界，实现逻辑分离的。

Docker所做的标准封装其实虚拟机也能做到，甚至差量存储机制在虚拟机中也早早的被用于实现增量备份，Docker与虚拟机的本质性不同到底在什么地方？回顾第一节中可逆计算对差量三个基本要求，我们可以清晰的发现Docker的独特之处。

    差量独立存在：Docker最重要的价值就在于通过容器封装，抛弃了作为背景存在（必不可少，但一般情况下不需要了解），占据了99%的体积和复杂度的操作系统层。应用容器成为了可以独立存储、独立操作的第一性的实体。轻装上阵的容器在性能、资源占用、可管理性等方面完全超越了虚胖的虚拟机。差量相互作用：Docker容器之间通过精确受控的方式发生相互作用，可通过操作系统的namespace机制选择性的实现资源隔离或者共享。而虚拟机的差量切片之间是没有任何隔离机制的。差量具有结构：虚拟机虽然支持增量备份，但是人们却没有合适的手段去主动构造一个指定的差量切片出来。归根结底，是因为虚拟机的差量定义在二进制字节空间中，而这个空间非常贫瘠，几乎没有什么用户可以控制的构造模式。而Docker的差量是定义在差量文件系统空间中，这个空间继承了Linux社区最丰富的历史资源。每一条shell指令的执行结果最终反映到文件系统中都是增加/删除/修改了某些文件，所以每一条shell指令都可以被看作是某个差量的定义。差量构成了一个异常丰富的结构空间，差量既是这个空间中的变换算符（shell指令），又是变换算符的运算结果。差量与差量相遇产生新的差量，这种生生不息才是Docker的生命力所在。

（二）React

2013年，也就是Docker发布的同一年，Facebook公司开源了一个革命性的Web前端框架React。React的技术思想非常独特，它以函数式编程思想为基础，结合一个看似异想天开的虚拟DOM（Virtual DOM)概念，引入了一整套新的设计模式，开启了前端开发的新大航海时代。

class HelloMessage extends React.Component {
  constructor(props) {
    super(props);
    this.state = { count: 0 };
    this.action = this.action.bind(this);
  }

  action(){
    this.setState(state => ({
      count: state.count + 1
    }));
  },

  render() {
    return (
      <button onClick={this.action}>
        Hello {this.props.name}:{this.state.count}
      </button>
    );
  }
}

ReactDOM.render(
  <HelloMessage name="Taylor" />,
  mountNode
);

React组件的核心是render函数，它的设计参考了后端常见的模板渲染技术，主要区别在于后端模板输出的是HTML文本，而React组件的Render函数使用类似XML模板的JSX语法，通过编译转换在运行时输出的是虚拟DOM节点对象。例如上面HelloMessage组件的render函数被翻译后的结果类似于

render(){
   return new VNode("button", {onClick: this.action, 
          content: "Hello "+ this.props.name + ":" + this.state.count });
}

可以用以下公式来描述React组件：

[公式]

当状态发生变化以后，只要重新执行render函数就会生成新的虚拟DOM节点，虚拟DOM节点可以被翻译成真实的HTML DOM对象，从而实现界面更新。这种根据状态重新生成完整视图的渲染策略极大简化了前端界面开发。例如对于一个列表界面，传统编程需要编写新增行/更新行/删除行等多个不同的DOM操作函数，而在React中只要更改state后重新执行唯一的render函数即可。

每次重新生成DOM视图的唯一问题是性能很低，特别是当前端交互操作众多、状态变化频繁的时候。React的神来之笔是提出了基于虚拟DOM的diff算法，可以自动的计算两个虚拟DOM树之间的差量，状态变化时只要执行虚拟Dom差量对应的DOM修改操作即可（更新真实DOM时会触发样式计算和布局计算，导致性能很低，而在JavaScript中操作虚拟DOM 的速度是非常快的）。整体策略可以表示为如下公式

[公式]

显然，这一策略也是可逆计算的一种特例。

只要稍微留意一下就会发现，最近几年merge/diff/residual/delta等表达差量运算的概念越来越多的出现在软件设计领域中。比如大数据领域的流计算引擎中，流与表之间的关系可以表示为

[公式]

对表的增删改查操作可以被编码为事件流，而将表示数据变化的事件累积到一起就形成了数据表。

现代科学发端于微积分的发明，而微分的本质就是自动计算无穷小差量，而积分则是微分的逆运算，自动对无穷小量进行汇总合并。19世纪70年代，经济学经历了一场边际革命，将微积分的思想引入经济分析，在边际这一概念之上重建了整个经济学大厦。软件构造理论发展到今天，已经进入一个瓶颈，也到了应该重新认识差量的时候。
四. 结语

笔者的专业背景是理论物理学，可逆计算源于笔者将物理学和数学的思想引入软件领域的一种尝试，它最早由笔者在2007年左右提出。一直以来，软件领域对于自然规律的应用一般情况下都只限于"模拟"范畴，例如流体动力学模拟软件，虽然它内置了人类所认知的最深刻的一些世界规律，但这些规律并没有被用于指导和定义软件世界自身的构造和演化，它们的指向范围是软件世界之外，而不是软件世界自身。在笔者看来，在软件世界中，我们完全可以站在“上帝的视角”，规划和定义一系列的结构构造规律，辅助我们完成软件世界的构建。而为了完成这一点，我们首先需要建立程序世界中的“微积分”。

类似于微积分，可逆计算理论的核心是将“差量”提升为第一性的概念，将全量看作是差量的一种特例（全量=单位元+全量）。传统的程序世界中我们所表达的都只是“有”，而且是“所有”，差量只能通过全量之间的运算间接得到，它的表述和操纵都需要特殊处理，而基于可逆计算理论，我们首先应该定义所有差量概念的表达形式，然后再围绕这些概念去建立整个领域概念体系。为了保证差量所在数学空间的完备性（差量之间的运算结果仍然需要是合法的差量），差量所表达的不能仅仅是“有”，而必须是“有”和“没有”的一种混合体。也就是说差量必须是“可逆的”。可逆性具有非常深刻的物理学内涵，在基本的概念体系中内置这一概念可以解决很多非常棘手的软件构造问题。

为了处理分布式问题，现代软件开发体系已经接受了不可变数据的概念，而为了解决大粒度软件复用问题，我们还需要接受不可变逻辑的概念（复用可以看作是保持原有逻辑不变，然后增加差量描述）。目前，业内已经逐步出现了一些富有创造性的主动应用差量概念的实践，它们都可以在可逆计算的理论框架下得到统一的诠释。笔者提出了一种新的程序语言X语言，它可以极大简化可逆计算的技术实现。目前笔者已经基于X语言设计并实现了一系列软件框架和生产工具，并基于它们提出了一种新的软件生产范式（NOP）。
canonical：NOP --- 下一代软件生产范式35 赞同 · 9 评论文章

编辑于 2022-04-24 22:16

]]
[[
https://zhuanlan.zhihu.com/p/85492497

canonical
canonical
千山万水
从可逆计算看声明式编程
25 天前 · 来自专栏 可逆计算

可逆计算是笔者提出的下一代软件构造理论，它的核心思想可以表示为一个通用的软件构造公式

[公式]

在这一公式中，所谓的领域特定语言（DSL）占有核心位置，而可逆计算在实践中的主要策略就是将业务逻辑分解为多个业务切面，针对每个业务切面设计一种DSL来描述。DSL是声明式编程的一种典型范例，因此可逆计算可以被看作是声明式编程的一种实现途径。透过可逆计算的概念，我们可以获得对声明式编程的一些新的理解。
canonical：可逆计算：下一代软件构造理论131 赞同 · 41 评论文章
一. 虚拟化

DSL是声明式的，因为它所表达的内容不像是可以直接交由某个物理机器执行的，而必须通过某种interpreter/compiler进行翻译。不过如果换一个角度去考虑，这个interpreter一样可以被看作是某种虚拟机，只不过它不一定是冯.诺伊曼体系结构的。这里核心的要点在于，底层的interpreter只要支持少数固定的针对某个特定领域的原语，即可执行DSL所编写的程序，从而实现不同的业务逻辑。在一般的程序结构中，业务逻辑是一次性表达的，而在基于DSL概念的程序中，逻辑是分两阶段表达的。底层是与具体业务无关的，只与领域结构有关的相对通用的逻辑，而上层才是多变的，与特定业务场景绑定的逻辑。

在比较现代的大型软件结构设计中，多多少少都会体现出构造某种内部虚拟机的努力。以Slate富文本编辑器框架为例，它号称是一个“完全可定制的”框架，核心是一个所谓的“Schema-less core"。也就是说，Slate的内核并不直接知道它所编辑的数据的具体结构，这些结构是通过schema告诉内核的。schema定义了允许哪些节点，节点有哪些属性，属性需要满足什么样的格式。

const schema = {
  document: {
    nodes: [
      {
        match: [{ type: 'paragraph' }, { type: 'image' }],
      },
    ],
  },
  blocks: {
    paragraph: {
      nodes: [
        {
          match: { object: 'text' },
        },
      ],
    },
    image: {
      isVoid: true,
      data: {
        src: v => v && isUrl(v),
      },
    },
  },
}
​
<Editor
  schema={schema}
  value={this.state.value}
  ...
/>

自定义的render函数类似于解释器

function renderNode(props, editor, next) {
  const { node, attributes, children } = props
​
  switch (node.type) {
    case 'paragraph':
      return <p {...attributes}>{children}</p>
    case 'quote':
      return <blockquote {...attributes}>{children}</blockquote>
    case 'image': {
      const src = node.data.get('src')
      return <img {...attributes} src={src} />
    }
    default:
      return next()
  }
}

传统的富文本编辑器，在内核中需要明确知道bold/italic这样的概念，而在Slate的内核中，关键的关键就在于不需要知道具体的业务含义就可以操纵对应的技术元素，这就类似于硬件指令不需要知道软件层面的业务信息。通过使用同一个内核，我们可以通过类似配置的方式实现Markdown编辑器，Html编辑器等多种不同用途的设计器。
二. 语法制导

实现虚拟化，最简单的方式是采用一一对应的映射机制，即将一组动作直接附加到DSL的每条语法规则上，处理到DSL的某个语法节点时，就执行对应的动作，这叫作语法制导（Syntax Directed）。

基于XML或者类XML语法的模板技术，例如Ant脚本，FreeMarker模板都可以看作是语法制导翻译的范例。以Vue的模板语法为例，

<template>
    <BaseButton @click="search">
      <BaseIcon name="search"/>
    </BaseButton>
  </template>

template相当于是将抽象语法树（AST）直接以XML格式展现，处理到组件节点时，将会直接根据标签名称定位到对应组件的定义，然后递归进行处理。整个映射过程是上下文无关的，即映射过程并不依赖于节点所处的上下文环境，同样的标签名总是映射到同样的组件。

同样的套路构成了Facebook的GraphQL技术的核心，它通过语法制导将待执行的数据访问请求发送到一个延迟处理队列，通过合并请求实现批量加载优化。 例如，为处理如下gql请求

query {
      allUsers {
        id
        name
        followingUsers {
          id
          name
        }
      }
    }

后台只需要针对数据类型指定对应dataLoader

const typeDefs = gql`
  type Query {
    testString: String
    user(name: String!): User
    allUsers: [User]
  }

  type User {
    id: Int
    name: String
    bestFriend: User
    followingUsers: [User]
  }
`;

const resolvers = {
  Query: {
    allUsers(root, args, context) {
      return ...
    }
  },
  User: {
     // allUsers调用返回的每个User对象，其中只有followingUserIds属性，它需要被转换为完整的User对象
    async followingUsers(user, args, { dataloaders }) {
      return dataloaders.users.loadMany(user.followingUserIds)
    }
  }
};

为了方便实现语法制导这一模式，现代程序语言已经有了默认的解决方案，那就是基于注解（Annotation）的元编程技术。例如，python中的函数注解

def logged(level, name=None, message=None):
    """
    Add logging to a function. level is the logging
    level, name is the logger name, and message is the
    log message. If name and message aren't specified,
    they default to the function's module and name.
    """
    def decorate(func):
        logname = name if name else func.__module__
        log = logging.getLogger(logname)
        logmsg = message if message else func.__name__

        @wraps(func)
        def wrapper(*args, **kwargs):
            log.log(level, logmsg)
            return func(*args, **kwargs)
        return wrapper
    return decorate

 # Example use
 @logged(logging.DEBUG)
 def add(x, y):
    return x + y

将注解看作是函数名，这一观念非常简单直观，TypeScript也采纳了同样的观点。相比之下，Java的APT（Annotation Processing Tool）技术显得迂回冗长，这也导致很少有人使用APT去实现自定义的注解处理器，不过它的作用是在编译期，拿到的是AST抽象语法树，因此可以做一些更加深刻的转化。Rust语言中的过程宏（procedural macros）则展现了一种更加优雅的编译期实现方案。

#[proc_macro_derive(Hello)]
    pub fn hello_macro_derive(input: TokenStream) -> TokenStream {
        // 从token流构建AST语法树
        let ast = syn::parse(input).unwrap();

        // 采用类似模板生成的方式构造返回的语法树
        let name = &ast.ident;
        let gen = quote! {
        impl Hello for #name {
            fn hello_macro() {
                println!("Hello, Macro! My name is {}", stringify!(#name));
            }
        }
        };
        gen.into()
    }

    pub trait Hello {
        fn hello_macro();
    }

    // 使用宏为Pancakes结构体增加Hello这个trait的实现
    #[derive(Hello)]
    struct Pancakes;

三. 多重诠释

传统上一段代码只有一种设定的运行语义，一旦信息从人的头脑中流出经由程序员的手固化为代码，它的形式和内涵就固定了。但是可逆计算指出，逻辑表达应该是双向可逆的，我们可以逆转信息的流向，将以代码形式表达的信息反向提取出来，这使得“一次表达，多重诠释”成为实现声明式编程，分离表达与运行的常规手段。例如，下面一段过滤条件

<and>
  <eq name="status" value="1" />
  <gt name="amount" value="3" />
</and>

展现在前台，对应于一个查询表单，应用到后台，对应于Predicate接口的实现，发送到数据库中，转化为SQL过滤条件的一部分。而这一切，并不需要人工编码，它们只是同一信息的多重诠释而已。

随着编译技术的广泛传播，传统上的命令式编程经过再诠释，现在也具有了声明式的意味。比如，Intel的OpenMP（Open Multi-Processing）技术

int sum = 0;
   int i = 0;

   #pragma omp parallel for shared(sum, i)
   for(i = 0; i < COUNT;i++){
      sum = sum + i;
    }

只要在传统的命令式语句中增加一些标记，即可把串行执行的代码转化为并行程序。

而在深度学习领域，编译转换技术更是被推进到了新的深度。PyTorch和Tensorflow这样的框架均可将形式上的python函数编译转换为GPU上运行的指令。而TVM这样的大杀器，甚至可以直接编译得到FPGA代码。

多重诠释的可能性，使得一段代码的语义永远处于开放状态，一切都是虚拟化的。
四. 差量修订

可逆计算将差量作为第一性的概念，将全量看作是差量的特例。按照可逆计算的设计，DSL必须要定义差量表示，允许增量改进，同时，DSL展开后的处理逻辑也应该支持增量扩展。

以Antlr4为例，它引入了import语法和visitor机制，从而第一次实现了模型的差量修订。

在Antlr4中，import语法类似面向对象编程语言中的继承概念。它是一种智能的include，当前的grammar会继承导入的grammar的所有规则，tokens specifications，names actions等，并可以重写规则来覆盖继承的规则。

在上面的例子中，MyElang通过继承ELang得到若干规则，同时也重写了expr规则并增加了INT规则。终于，我们不再需要每次扩展语法都要拷贝粘贴了。

在Antlr4，不再推荐将处理动作直接嵌入在语法定义文件中，而是使用Listener或者Visitor模式，这样就可以通过面向对象语言内置的继承机制来实现对处理过程的增量修订。

// Simple.g4
grammar Simple; 

expr  : left=expr op=('*'|'/') right=expr #opExpr
      | left=expr op=('+'|'-') right=expr #opExpr
      | '(' expr ')'                      #parenExpr
      | atom=INT                          #atomExpr
      ;

INT : [0-9]+ ;

// Generated Visitor
public class SimpleBaseVisitor<T> extends AbstractParseTreeVisitor<T> implements SimpleVisitor<T> {
    @Override public T visitOpExpr(SimpleParser.OpExprContext ctx) { return visitChildren(ctx); }
    @Override public T visitAtomExpr(SimpleParser.AtomExprContext ctx) { return visitChildren(ctx); }
    @Override public T visitParenExpr(SimpleParser.ParenExprContext ctx) { return visitChildren(ctx); }
}

class MyVisitor<Double> extends SimpleBaseVisitor<Double>{
  ...
}

五. 自动微分

如果说声明式编程的理想是人们只需要描述问题，由机器自动找出解决方案，那么我们从哪里去找一类足够通用，而且又能够自动求解的问题呢？幸而自牛顿以降，科学昌明，我们还是积攒了几个这样的祖传问题的，其中一个就是自动微分。

只要指定几个基础函数的微分表达式，我们就可以自动计算大量复合函数的微分，这一能力是目前所有深度学习框架的必备技能。可逆计算理论指出，自动计算差量这一概念可以被扩展到数学或者算法领域之外，成为一种有效的软件结构构造机制。

以k8s为例，这一容器编排引擎的核心思想是通过声明式的API来指定系统的“理想”状态，然后通过监控测量不断发现当前状态与理想状态的偏差，自动执行相应的动作来“纠正”这些偏差。它的核心逻辑可以总结为如下公式：

[公式]

k8s所采用的这种设计原理可以称为是状态驱动（State Driven），它关注的重点是系统的状态以及状态之间的差异，而不再是传统的基于动作概念的API调用和事件监听。从动作（Action）到状态（State）的这种思维转换其实类似于物理学中从力的观点过渡到以势能函数（Potential）为基础的场（Field）的观点。

从状态A迁移到状态B，无论经过什么路径，最终得到的结果都是一样的，因此势的概念是路径无关的。摆脱了路径依赖极大简化了我们对系统的认知。而所谓的力，随时可以通过对势函数求导，从势函数的梯度得到。

[公式]

同样，在k8s中，对于任意的状态偏差，引擎都可以自动推导得到相应需要执行的动作。

从状态A迁移到状态B有多条可行的路径，在这些路径中按照成本或者收益原则选择其一，这就是所谓的优化。

从动作到状态的转换是整体思维模式的一种变革，它要求我们用新的世界观去思考问题，并不断调整相应的技术实现去适应这种世界观。这一变革趋势正在逐渐加强，也在越来越多的应用领域促生着新的框架和技术。

势的观念要求我们对状态空间有着全面的认知，每一个可达的状态都有着合法的定义。有的时候，对于特定应用而言，这种要求可能过于严苛，例如，我们可能只需要找到从特定状态A到特定状态B的某一条可行的道路即可，没必要去研究所有状态构成的状态空间自身，此时传统的命令式的做法就足够了。
六. 同构转化

太阳底下没有新鲜事。在日常编程中，真正需要人们去创造的新的逻辑是很少的，绝大多数情况下我们所做的只是某种逻辑关系的映射而已。比如说，日志收集这件事情，为了采集日志文件内容进行分析，一般需要使用类似logstash这样的工具解析日志文本到json格式，然后投递到ElasticSearch服务。

但是，如果在打印日志的时候，我们就保留对象格式，那么实际上可以不需要中间logstash的解析过程。如果需要对属性过滤或者进行再加工，也可以直接对接一个通用的对象映射服务（可以通过可视化界面进行映射规则配置），而不需要为日志处理领域单独编写一套实现。

// 保持对象格式输出日志
   LOG.info(日志码，{参数名：参数值});

很多时候，我们之所以需要程序员去编写代码，原因在于跨越边界时出现了信息丢失。例如，以文本行形式打印日志时，我们丢失了对象结构信息，从文本反向恢复出结构的工作很难自动完成，它必须借助程序员的头脑，才能消除解析过程中可能出现的各种歧义情况。

程序员头脑中的信息包括我们所处的这个世界的背景知识，各种习惯约定，以及整体架构设计思想等。因此，很多看似逻辑上等价的事情往往无法通过代码自动完成，而必须通过增加人这个变量来实现配平。

[公式]

现代数学是建立在同构概念基础之上的，在数学上我们说A就是B，潜台词说的是A等价于B。等价归并大幅削减了我们所需要研究的对象，加深了我们对系统本质结构的认识。

    为什么 3/8 = 6/16, 因为这就是分数的定义！（3/8，6/16，9/24...）这一系列表示被定义为一个等价类，它的代表元素就是3/8（参见 彭罗斯《通向实在之路--宇宙法则的完全指南》一书的前言）。

可逆计算强调逻辑结构的可逆转化，从而试图在软件构造领域建立起类似数学的抽象表达能力，而这只有当上下游软件各个部分都满足可逆原则时才能够实现效用的最大化。

例如，当细粒度组件和处理过程均可逆时，可视化设计器可以根据DSL直接生成，而不需要进行特殊编码

[公式]

在现实开发过程中实现可逆性的一个障碍在于，目前软件开发的目的性都是很强的，因此与当前场景无关的信息往往无处安放。为了解决这个问题，必须在系统底层增加允许自定义扩展的元数据空间。

[公式]

对应于A'部分的信息在当前的系统A中不一定会使用，但是为了适应系统B的应用逻辑，我们必须找到一个地方把这些信息存储下来。这是一种整体性的协同处理过程。

你注意到没有，所有能称得上现代的程序语言都经历了戴帽子工程改造，都支持某种形式的自定义注解（Annotation）机制，一些扩展的描述信息会存在帽子里随身携带。换句话说，(data, metadata)配对才是信息的完整表达，这和消息对象总是包含(body, headers)是一个道理。

世界如此复杂，目的为何唯一？在声明式的世界中，我们有必要持有一种更加开放的态度。戴帽子不为了挡风挡雨，也不为了遮阳防晒，我就为了好看不行吗？metadata是声明式的，一般我们说它是描述数据的数据，但实际上它就算当前不描述任何东西可以有自己存在的理由，不是说有一种用叫“无用之用”吗。
编辑于 2022-04-24 22:17

]]
[[
https://zhuanlan.zhihu.com/p/85491177
什么是声明式编程

canonical
千山万水
什么是声明式编程
25 天前 · 来自专栏 可逆计算

一. 声明式 vs. 命令式。

什么是声明式编程？一般来说我们对于声明式的理解都是相对于命令式（imperative）而言的。图灵教会了我们imperative的真谛，并赋予了它数学意义上的精确定义：一台有状态的机器，根据明确的指令（instruction）一步步的执行。而所谓的声明式，它可以看作是命令式的反面。曾有人言：一切非imperative，皆是declarative。从这个意义上说，越是偏离图灵机的图像越远的，就越是声明式的。

所以，函数式编程（Functional Programming）是声明式的，因为它不使用可变状态，也不需要指定任何的执行顺序关系（可以假定所有的函数都是同时执行的，因为存在引用透明性，所谓的参数和变量都只是一堆符号的别名而已）。逻辑式编程（Logical Programming）也是声明式的，因为我们只需要通过facts和rules描述我们所需要解决的问题，具体的求解路径由编译器和程序运行时自动决定。

如果说命令式对应于由具体的物理机器可执行的步骤，那么声明式就可以看作是对应于更高级别的抽象的表达。由此引申出一种令人浮想联翩的理解：命令式是关于“how to do”的，而声明式是关于“what to do”的。在这种理解下，SQL语言作为一种领域特定语言（DSL）是声明式的。SQL语言描述了我们希望得到的逻辑上的数据加工结果，由执行引擎将SQL语言翻译为物理执行计划。

参考Kowalski曾提出的公式：algorithm = logic + control，逻辑（解决问题时所需要用到的知识）可以独立于具体执行时的控制流（具体使用知识的解题策略）得到表达。在DSL中，重要的是表达所有需要表达的信息，表达时的先后顺序往往是不重要的，并且与具体执行时的处理顺序也没有什么必然的关系。比如SQL语句表连接的先后顺序，以及过滤条件的先后顺序原则上是不影响执行结果的。

select *
   from a,b,c
   where a.x = b.x and c.x = a.x

在逻辑上等价于

select *
   from c,b,a
   where c.x = a.x and a.x = b.x

注意到select写在from部分的前面并不意味着select部分先执行，实际上这里的顺序仅仅是习惯上的。在C#的LINQ语法中，我们会这样写

from x in array
  where x % 2 == 1
  orderby x descending
  select x * x;

二. 声明式编程：表达与运行分离

如果将命令式编程看作是一种“忠实的”表达（表达了就要执行，而且所表达的正是要执行的内容），那么声明式编程就是相当不老实的表达。
表达了可以不执行，甚至没法执行

比如说

list = range(0, Infinity); // 得到一个从0到无穷大的所有整数构成的数组
   list.take(5)            // 取数组的前5条记录

声明式编程中延迟计算是一个常见的特性，它极大增加了逻辑组织结构的灵活性。比如在WebMVC架构中

// action中
   entity = dao.getEntity(id)

   // view中
   entity.mainTable
   entity.subItems

基于ORM的延迟加载特性可以同时兼顾表达的便捷性和按需访问的高性能。在action层可以直接表达获取相关数据，但并不真正把所有数据都读取到内存中。当实际使用时，才通过延迟加载机制进行数据读取。
不仅表达当下，还表达未来

现代编程语言中标配的Promise对象，它表示了未来可以获得的一个值，当我们还未真正得到这个值的时候，就可以把它作为返回值返回，并在程序中作为参数传来传去。

而在传统的命令式编程概念中，函数的返回就表示执行完毕，如果是异步执行，则只能通过回调函数获取通知，在概念层面上我们并无法直接定义和使用“未来的值”。

async function asyncValue(){
    return new Promise((resolve, reject) => {
        setTimeout(() => resolve('a'), 1000)
     });
  }

  var result = asyncValue();
  doSomething(result);

  async function doSomething(input){
     console.log('begin');
     var result = await input;
     console.log('1 second later: result='+result);
  }

不仅表达自己有的，还表达自己没有的

未来的值虽然现在未来，但毕竟未来可期。但如果根本不知道未来是否会来，那能否给它分配一个表达形式呢？

在groovy语言中，提供了类似Ruby的methodMissing机制

class Foo {

    def methodMissing(String name, def args) {
        println "Missing method name is $name"
    }

    static def $static_methodMissing(String name, Object args) {
        println "Missing static method name is $name"
    }
    static def $static_propertyMissing(String name) {
        println "Missing static property name is $name"
    }

    def propertyMissing(String name) { println "Missing property name is $name" }
}

foo = new Foo();
fo.x;
foo.f();

三. 声明式 & 命令式

传统上主流编程语言都是偏向命令式的，因为我们的硬件运行环境都是图灵机的升级版本，软件的功能就是指导硬件执行预设的动作。甚至有一种说法，程序开发工作的本质就是命令式的，毕竟为老板的小目标（what）找到具体的技术实现方案（how）才是我们的本职工作。但是，如果仔细观察一下现代编程的日常，就会发现，绝大多数的编程工作是建立在声明式API的基础之上的。

比如说，要显示界面，我们通过字符串操作拼接出HTML问本，为了调用服务，我们拼接出URL和JSON文本，为了访问数据库，我们拼接出SQL请求。很少有人清楚，如何使用命令式的指令一步步的构造出完整的应用程序。即使是最简单的前台拖拽动作，我们所会的多半也只是调用一个Draggable组件，监听（声明）一下拖拽结束时的触发动作。在这个意义上说，我们所掌握的编程技能只是从一种声明式视图映射到另一种声明式视图之间的转换策略而已。

整个软件开发生态环境正在不断向着声明式和命令式水乳交融的方向发展。以前，为了突出声明式的部分，我们会选择模板语言，即在描述性内容中嵌入少量的命令式控制逻辑。而在今天，出现了JSX这种直接将描述性内容嵌入到命令式上下文中的技术。更进一步，类似SwiftUI这种基于通用程序语言直接实现声明式表达的技术正快步向我们走来

List(landmarks) { landmark in
       HStack {
          Image(landmark.thumbnail)
          Text(landmark.name)
          Spacer()

          if landmark.isFavorite {
         Image(systemName: "star.fill")
            .foregroundColor(.yellow)
          }
       }
    }

四. 可逆计算视角下的声明式编程

我们如何才能进一步推进声明式编程？如果套用What & How的比喻，方向就在于如何通过系统化的方案来定义What, 并自动推导得到How。可逆计算提供了实现DSL的一整套完整技术路线，同时也为实现声明式编程带来一些新的启发。

这里空白太小，我写不下了，且听下回分解。
canonical：从可逆计算看声明式编程19 赞同 · 8 评论文章

编辑于 2022-04-24 22:17

]]
]]]
]]]]
[[
https://baike.baidu.com/item/%E5%A3%B0%E6%98%8E%E5%BC%8F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/22700944

目录
声明式编程语言

    科普中国 | 本词条由“科普中国”科学百科词条编写与应用工作项目审核
    审阅专家王慧维

在计算机科学中，声明式编程是一种编程范式，即构建计算机程序的结构和元素的一种风格，它表达了计算的逻辑而没有描述其控制流程。

许多应用这种风格的语言试图通过描述程序在问题领域必须完成的事情来最小化或消除副作用，而不是描述如何将它作为一系列编程语言原语来实现（如何离开直至语言的实现）。这与命令式编程相反，命令式编程以明确的步骤实现算法。

声明性编程通常将程序视为形式逻辑的理论，并将计算视为逻辑空间中的推论。声明式编程可能会极大地简化编写并行程序。

常用的声明性语言包括数据库查询语言（例如SQL，XQuery），正则表达式，逻辑编程，函数式编程和配置管理系统。

    中文名
    声明式编程语言
    外文名
    Declarative programming language

快速
导航

    编程

定义
声明式编程通常被定义为任何不是必须的编程风格。还有其他一些常见的定义，试图给这个术语一个定义，而不是简单地将它与命令式编程对比。例如：
a.一个描述计算应该执行的高级程序。
b.任何缺乏副作用的编程语言（或者更具体地说，都是引用透明的）
c.与数学逻辑对应的语言。
这些定义基本上重叠。声明式编程与命令式和程序式编程形成对比。声明式编程是一种非必要的编程风格，其中程序在不明确列出必须执行的命令或步骤的情况下描述其预期结果。功能和逻辑编程语言的特点是声明式编程风格。在逻辑编程语言中，程序由逻辑语句组成，程序通过搜索语句的证明来执行。
在纯粹的函数式语言中，比如Haskell，所有的函数都没有副作用，而状态变化只是表现为转换状态的函数，状态被明确表示为程序中的第一类对象。尽管纯粹的功能语言不是必需的，但它们通常提供一种功能描述作为一系列步骤的功能。其他函数式语言，如Lisp，OCaml和Erlang支持程序和函数式编程的混合。
一些逻辑编程语言（如Prolog）和数据库查询语言（如SQL）虽然原则上是声明性的，但也支持程序式编程风格。
编程
声明性编程是一个总括性术语，包括许多更为人熟知的编程范例[1] 。
约束编程
约束编程以指定目标解决方案属性的约束形式表示变量之间的关系。通过给每个变量赋予一个值来解决这组约束，以便解决方案与约束的最大数目一致。约束规划经常补充其他范式：功能性，逻辑性甚至是命令式编程。
特定于域的语言
众所周知的声明性域特定语言（DSL）的示例包括yacc解析器生成器输入语言，QML，Make构建规范语言，Puppet的配置管理语言，正则表达式和SQL的子集（例如，SELECT查询）。 DSL具有非常有用的优点，但不一定需要Turing-complete，这使得语言更容易纯粹是声明性的。
许多标记语言(如HTML，MXML，XAML，XSLT或其他用户界面标记语言)通常都是声明式的。例如，HTML仅描述网页上应显示的内容 - 它既不指定呈现页面的控制流，也不指定页面与用户可能的交互。
截至2013年，一些软件系统将传统的用户界面标记语言（例如HTML）与声明性标记相结合，声明性标记定义了后端服务器系统应该做什么（但不是如何）以支持声明的接口。这种系统通常使用特定于域的XML名称空间，可能包括SQL数据库语法的抽象或使用表示状态传输（REST）和SOAP对Web服务的参数化调用。
混合语言
例如，Makefiles以声明方式指定了依赖关系，但也包括一个必要的行动列表。同样，yacc声明式地指定了一个上下文无关语法，但是包含来自宿主语言的代码片断，这通常是必要的（比如C）。
逻辑编程
逻辑编程语言，如Prolog状态和查询关系。回答这些查询的具体细节取决于实现及其定理证明，但通常采取某种形式的统一。像函数式编程一样，许多逻辑编程语言都允许有副作用，因此不是严格声明式的。
建模
物理系统的模型或数学表示可以在声明性的计算机代码中实现。该代码包含许多描述（“声明”）行为关系的等式，而不是强制性的任务。当一个模型用这种形式表达时，计算机能够执行代数操作来最好地制定解决方案算法。数学因果关系通常强加于物理系统的边界，而系统本身的行为描述则是声明性的或非因果性的。声明式建模语言和环境包括Analytica，Modelica和Simile。
参考资料

    [1]  NEMO:一种声明式网络编程与业务定制语言．万方 [引用日期2018-06-30]

词条目录

        百科名片
        定义
        编程
        约束编程
        混合语言
        逻辑编程
        建模
        TA说
]]
[[
https://baike.baidu.com/item/%E5%A3%B0%E6%98%8E%E5%BC%8F%E7%BC%96%E7%A8%8B/9939512

目录
声明式编程

    科普中国 | 本词条由“科普中国”科学百科词条编写与应用工作项目审核
    审阅专家吴晨涛

声明式编程（英语：Declarative programming）是一种编程范式，与命令式编程相对立。它描述目标的性质，让计算机明白目标，而非流程。声明式编程不用告诉计算机问题领域，从而避免随之而来的副作用。而命令式编程则需要用算法来明确的指出每一步该怎么做。

声明式编程通常被看做是形式逻辑的理论，把计算看做推导。声明式编程因大幅简化了并行计算的编写难度，自2009年起备受关注。

声明式语言包包括数据库查询语言（SQL，XQuery），正则表达式，逻辑编程，函数式编程和组态管理系统。

声明式编程透过函数、推论规则或项重写（term-rewriting）规则，来描述变量之间的关系。它的语言运行器（编译器或解释器）采用了一个固定的算法，以从这些关系产生结果。

声明式编程语言通常用作解决人工智能和约束满足问题。

    中文名
    声明式编程
    外文名
    Declarative programming
    类别
    编程形式
    作用
    解决人工智能和约束满足问题

快速
导航

    子编程范式
    参见

定义
声明式编程通常被定义为除命令式以外的编程范式。同时存在一些其他的定义，这些定义不是简单的将声明式编程和命令式编程做对比，例如：

    声明式编程是告诉计算机需要计算“什么”而不是“如何”去计算
    任何没有副作用的编程语言，或者更确切一点，任何引用透明的编程语言
    任何有严格计算逻辑的编程语言

这些定义有一些是重合的。
子编程范式
声明式编程是一个大的概念，其下包含一些有名的子编程范式。
约束式编程
在约束式编程中，变量之间的关系是在约束中说明的，定义了问题的解的范围。这些约束然后被应用程序来求解，以使得每个变量获得一个值，并让最多的约束得到满足。
约束式编程经常被用作函数式编程、逻辑编程甚至命令式编程的补充。
领域专属语言
一些著名的声明式领域专属语言（DSLs）包括yacc语法分析器，编译说明语言Make，Puppet管理配置语言，正则表达式和SQL的一些子集（例如Select queries等）。DSLs有时非常有用，并且不需要是图灵完全的，这往往让其很容易以一种纯声明式的方式来表达。
很多文本标记语言例如HTML、MXML、XAML和XSLT往往是声明式的[1] 。
函数式编程
函数式编程，特别是纯函数式编程，尝试最小化状态带来的副作用，因此被认为是声明式的。大多数函数式编程语言，例如Scheme、Clojure、Haskell、OCaml、Standard ML和Unlambda，允许副作用的存在。
逻辑式编程
逻辑式编程语言如Prolog声明关系并且对关系进行提问。同函数式编程一样，许多逻辑编程语言允许副作用的存在。
参见

    （对立的）命令式编程
    函数式编程和逻辑编程

参考资料

    [1]  李凤凯, 张亚丽, 夏寅贲. NEMO:一种声明式网络编程与业务定制语言[J]. 信息通信技术, 2016(4):65-74.

词条目录

        百科名片
        定义
        子编程范式
        约束式编程
        领域专属语言
        函数式编程
        逻辑式编程
        参见
        TA说
]]
[[
https://baike.baidu.com/item/Puppet

目录
puppet

puppet是一种Linux、Unix、windows平台的集中配置管理系统，使用自有的puppet描述语言，可管理配置文件、用户、cron任务、软件包、系统服务等。puppet把这些系统实体称之为资源，puppet的设计目标是简化对这些资源的管理以及妥善处理资源间的依赖关系。

puppet采用C/S星状的结构，所有的客户端和一个或几个服务器交互。每个客户端周期的（默认半个小时）向服务器发送请求，获得其最新的配置信息，保证和该配置信息同步。每个puppet客户端每半小时(可以设置)连接一次服务器端, 下载最新的配置文件,并且严格按照配置文件来配置客户端. 配置完成以后,puppet客户端可以反馈给服务器端一个消息. 如果出错,也会给服务器端反馈一个消息.

    外文名
    puppet
    性质
    集中配置管理系统
    特点
    使用自有的puppet描述语言
    设计目标
    简化对这些资源的管理

快速
导航

    使用的稳定性
    细节和原理
    Facter变量
    工作方式流程
    修改系统配置
    资源之间关系
    语言资源
    版本

开发原因
系统管理员都喜欢自己写点小工具来让自己的工作完成的更快或者更好, 不管是在大企业管理大量的服务器还是只管理两三台机器. 但是很少人会把他们的工具发布出来. 也就是是说极少有工具能被重用,或者说很多工具就只能在所在的组织内部有用.拷贝给别的组织,他们也用不上. 也就是说,每个系统管理员,在一个新的公司,都会另起炉灶开发一套基于ssh,for循环的"系统"来帮助自己完成系统管理任务.
开发puppet是为了让系统管理员可以相互交流和共享成熟的工具,避免重复的劳动.通过以下两个特性来实现这一目标:
提供一个简洁的但是强大的框架来完成系统管理任务
系统管理任务可以描述成puppet语言,因此可以相互分享代码,就像分享其他语言的代码一样,比如python, c等
因此,作为系统管理员的你可以更快的完成工作,因为你可以用puppet来处理所有的管理细节. 甚至你还可以下载其他管理员的puppet代码来让你的工作完成的更快.
使用的稳定性
puppet与其他手工操作工具有一个最大的区别就是 puppet的配置具有稳定性,因此你可以多次执行puppet, 一旦你更新了你的配置文件,puppet就会根据配置文件来更改你的机器配置,通常每30分钟检查一次. puppet会让你的系统状态同配置文件所要求的状态保持一致. 比如你配置文件里面要求ssh服务必须开启. 假如不小心ssh服务被关闭了,那么下一次执行puppet的时候,puppet会发现这个异常,然后会开启 ssh 服务. 以使系统状态和配置文件保持一致.puppet就象一个魔术师,会让你的混乱的系统收敛到puppet配置文件所想要的状态.
可以使用puppet管理服务器的整个生命周期,从初始化到退役.不同于传统的例如sun的Jumpstart或者redhat的Kickstart, puppet可以长年让服务器保持最新状态.只要一开始就正确的配置他们,然后再也不用去管他们.通常puppet用户只需要给机器安装好puppet并让他们运行,然后剩余的工作都由puppet来完成.
细节和原理
puppet的目的是让你只集中于你要管理的目标,而忽略实现的细节,例如命令名,参数或者文件格式. puppet把系统里面的用户,软件包,服务 看作是"资源", puppet的作用就是管理这些资源以及资源之间的相互联系.
底层支撑工具 Providers,puppet有很多的资源类型,例如文件,用户,软件包,服务, 不同的操作系统上对资源的管理命令是不一样的,例如debian下面用apt-get安装软件,redhat下面用yum安装软件. 因此puppet 对同一资源的管理可以有多个实现,配置资源的时候,可以明确的指定用什么provider. 例如在redhat上配置一个package资源的时候,可以指定provider是yum.
Facter变量
在puppet客户端分析代码的时候,会把从facter传送过来的对应的值赋值给变量. 你可以单独手工执行facter这个命令,这个命令会打印出它所收集到的关于主机的信息,例如ip地址等等. facter把收集到值发送给puppet服务器端,服务器端就可以根据不同的条件来对不同的节点机器生成不同的puppet配置文件. 最重要的一个就是服务器的主机名.
工作方式流程
puppet既可以在单机上使用,也可以以c/s结构使用.在大规模使用puppet的情况下,通常使用c/s结构.在这种结构中puppet客户端只是指运行puppet的客户端,puppet服务器端是只运行puppetmaster的服务器.
puppet客户端首先会连接到puppet服务器端,并且通过facter工具把客户端的基本配置信息发送给服务器端. 服务器端通过分析客户端的主机名,通过node 定义,找到该主机的配置代码,然后编译配置代码,把编译好的配置代码发回客户端,客户端执行代码完成配置.并且把代码执行情况反馈给puppet服务器端.
修改系统配置
puppet 通过管理资源的方式来管理系统, 例如管理某个软件是否要安装,是安装最新的还是安装了就行. 管理某个服务是否开启, 管理某个文件的属性,内容等等. 所有的资源都有对应的几个属性可以设置. 通过设置属性的方式来管理资源. 有一种特殊的属性可以用在所有的资源上面,这种属性叫做 metaparams ( 元参数或者元属性).
资源之间关系
支持资源之间的关系配置是puppet的关键特性之一. 一个资源的变更可以对另一个资源产生一个动作.例如 /etc/apache.conf这个资源有改动,可以让/etc/init.d/apache 这个资源 reload一下.假如一个资源依赖另一个资源,那么puppet会优先配置被依赖的资源,因此如果你的配置文件没有准备好,对应的服务是不会先启动的.
语言资源
puppet的全部就是管理资源,因此puppet语言的焦点就是处理这些资源,下面是一个基本的管理单个资源的例子.
file {"/etc/hosts": owner = root, group = root, mode = 644}
上面的例子给出了定义一个资源所需要的所有组件,类型,名字和属性. 定义了一个 file 资源, 资源的title(标题)是 "/etc/hosts", 资源的属性里面设置了该文件属于哪个用户和组,以及文件的权限.
也可以在一个大括号里面定义多个资源,通过分号来区分.
避免重复配置
puppet的编译器会避免在不同的代码段里面管理同一个资源, 如果在不同的代码段对同一个资源进行配置,执行puppet的时候你会得到一个语法错误.puppet探测这种冲突的情况是通过判断资源类型和资源的title(标题); 如果两个资源有相同的资源类型和title; 那么就认为这两个资源是表示同一个资源.
类
你可以把多个相关的资源定义在一起,组成一个类.可以在其他的代码段include这个类.puppet还支持有限制的类的继承,作用就是在子类里面的属性可以覆盖父类里面的属性.
字符串
几乎所有的东西和符号在puppet里面都被看作是字符串,包括数字和布尔值. 但是如果你用引号把true和false引起来,他们会被当做字符串,例如你想赋值给某个资性"yes"的 字符串.
变量
puppet除facter变量外，也可以自定义变量，但不允许你在同一个类里面对一个变量进行两次赋值.
$myvar = value123
条件语句
Puppet支持常见的条件语句，使得你能根据不同的条件导入不同的资源定义。如if、case、另外puppet从版本0.24.6开始支持比较运算符。
数组
puppet 非常有限的支持数组这种类型,你可以创建数组,并且给他们赋值,但是你不能删除它们.数组用的最多的情况就是上面ssh例子里面,资源依赖哪种情况. 或者是一次管理多个相同类型的资源.例如:user { [bin, adm]: ensure => present }
函数
puppet提供一些有用的函数,例如template利用erb模板来生成文件内容,这样就可以根据不同主机的情况,生成不同的配置文件.例如配置squid的内存缓存大小,可以利用facter返回的内存值做一个简单的数学计算,然后写入到squid的配置文件,就是通过template来完成的. 另外一个函数include 可以读入另外的puppet配置文件或者类.这样可以把puppet的文件分割的更有规律.
节点
最后一个关于puppet语言的语法是节点定义"node", 节点定义很象类定义,也支持继承特性. 当一个节点(puppet客户端)连接到puppet服务器端,puppet解析器会查找这个节点的node代码片断,然后利用这个代码片断来生成该客户端的配置代码. puppet里面主机名来标明一个主机,因此主机名在puppet里面相当重要. 如果puppet找不到匹配该主机名的node定义,就会用默认的节点定义来配置该主机. 在node里面使用主机名,需要用单引号把主机名括起来.
node 'server1' { include nginx }
在上面的代码中,如果server1这个主机连接到puppet服务器,puppet服务器就会按照nginx的代码来配置这台服务器.
自定义资源
puppet里面有一个非常有用的语法结构,叫做define, 通过define可以把多个资源包装成一个资源,或者把一个资源包装成一个模型,便于使用.例如,在debian里面管理一个apache虚拟机非常简单,把一个虚拟主机的配置文件放到/etc/sites-available/里面,然后做一个符号链接到/etc/sites-enabled目录. 你可以为你每个虚拟主机复制同样的配置代码.
版本
puppet 有企业版和社区版，版本是2.6。
社区版是免费的，有些常用的功能。
企业版是收费的，支持vmware虚拟机的部署和审计功能。但如果10个节点以下是免费的。
2013年1月13日。

词条目录

        百科名片
        开发原因
        使用的稳定性
        细节和原理
        Facter变量
        工作方式流程
        修改系统配置
        资源之间关系
        语言资源
        类
        字符串
        变量
        条件语句
        数组
        函数
        节点
        自定义资源
        版本
        TA说
]]
[[
]]
[[


Digital Guide
IONOS

    24.02.20Web development

Declarative programming: When “what” is more important than “how”

Whether programming an app, IoT software or a computer game – developers have to make a fundamental decision before they write their first line of code: What programming language do they want to use? A variety of languages is available, but all of them can be assigned to two fundamental programming paradigms: declarative programming and imperative programming.
Contents

    What is declarative programming?
    Imperative vs declarative programming
    Declarative programming example
    Advantages and disadvantages of declarative programming languages

What is declarative programming?

There is no one specific definition of the paradigm, but all definitions agree on one thing: A characteristic feature of declarative programming languages is that they always describe the desired end result rather than outlining all the intermediate work steps. In declarative programming, the solution path to reach the goal is determined automatically. This works well, provided the specifications of the final state are clearly defined and an appropriate implementation procedure exists. If both of these conditions are met, declarative programming is very efficient.

Since declarative programming does not specifically describe the “how” but works at a very high level of abstraction, the programming paradigm also leaves room for optimization. If a better implementation procedure is developed, the integrated algorithm can identify and use it. This makes the paradigm futureproof. The procedure for how the result is to be achieved does not have to be set in stone when writing the code.

The best-known declarative programming languages are:

    Prolog
    Lisp
    Haskell
    Miranda
    Erlang
    SQL (in the broadest sense)

The different declarative programming languages can, in turn, be divided into two paradigms: functional programming languages and logic programming languages.

However, in practice, the boundaries are frequently blurred and elements of both imperative programming – with its sub-types procedural, modular, and structured programming – and declarative programming are used to solve problems.
Overview of the systematization of imperative and declarative programmingProgramming languages can be assigned to two fundamental programming paradigms, which in turn have their own programming styles.
Imperative vs declarative programming

The imperative programming paradigm (command-based paradigm) is the older of the two basic paradigms. Unlike in declarative programming, in this case, the developer specifies in the source code precisely what the computer should do, step by step, to achieve the result. The focus is on the “how” of the solution path. For example, this approach can be found in Java, Pascal, and C. By contrast, in declarative programming the “what” of the solution is described directly.

As an example, let’s apply the idea to furniture assembly: While imperative programming provides instructions for assembly, declarative programming provides a picture of the finished piece of furniture as a template.

Instead of leaving the “how” of implementation open with functions, in imperative programming there are variables, which are changed at runtime. This makes the code longer but also more understandable than the truncated and very abstract form of the declarative style.
Declarative programming example

One of the strengths of declarative programming is its ability to describe problems more briefly and succinctly than imperative languages.

If we want to output a list of first names, in PHP this can be described with just one line of code using declarative programming – as the example shows – while the imperative method requires five lines.

Imperative programming

$participantlist = [1 => 'Peter', 2 => 'Henry', 3 => 'Sarah'];
$firstnames= [];
foreach ($participantlist as $id => $name) {
    $firstnames[] = $name;
}

Declarative programming

$firstnames = array_values($participantlist);

Advantages and disadvantages of declarative programming languages

These days, the declarative programming style is used in a variety of cases, even if not in its purest form. However, the method is not suitable for all uses.

Declarative code is characterized by a high level of abstraction. This enables developers to represent complex programs in a compressed form. But the more sophisticated the application, the greater the danger that the code becomes so convoluted that it can only be read by the developer who originally wrote it. For companies that want to be able to maintain and develop applications without having to rely on a single person’s knowledge, this presents a challenge. External developers have to carefully read and work out the declarative code until they understand the structure and have solved any problems.

However, the level of abstraction in declarative programming also offers advantages. Because implementation is clearly delineated from the system using an algorithm, maintenance can be performed independently of application development. Interruptions of day-to-day operations are reduced to a minimum. At the same time, optimization is easier because the algorithm used allows new methods to be integrated. One disadvantage of algorithm use is that this kind of formulaic solution is often insufficiently equipped to deal with specific characteristics of individual applications.

Not so much a disadvantage as a challenge is the conceptual model of declarative programming. Thinking in terms of solution states contradicts natural human thought processes. People tend to think in terms of processes moving towards a goal rather than starting from a goal and working backward. This requires developers to rethink and accustom themselves to the concept, which can initially slow down problem-solving. However, once the new mindset has been learned, the declarative approach can capitalize on its strengths.

Another advantage of development starting from the description of the problem is that teams can outline solution models rapidly. Ultimately, specific programming of the implementation can take place later. The declarative style is thus well suited for prototyping in agile software development.
Advantages 	Disadvantages
Short, efficient code 	Sometimes hard to understand for external people
Can be implemented using methods not yet known at the time of programming 	Based on an unfamiliar conceptual model for people (solution state)
Easy optimization as implementation is controlled by an algorithm 	Hard to take characteristics of individual applications into account during programming
Maintenance possible independent of application development 	 

In practice, mixed forms of the paradigms are often used these days, with declarative programming languages being supplemented with imperative methods. However, this increases susceptibility to errors and can impair the legibility of the code.

    24.02.20Web development

]]
[[
https://www.benfrederickson.com/python-as-a-declarative-programming-language/


Ben Frederickson
Python as a Declarative Programming Language

If you look at the programming languages benchmarks game, Python is one of the slowest commonly used programming languages out there. Typical programs written in pure Python average around 40 times slower than the equivalent program written in C or C++.

Despite the performance penalty, Python is still probably the most popular language choice out there for doing Data Analysis and Machine Learning. Most of the recent Deep Learning frameworks target Python for development: TensorFlow, Theano, and Keras all use Python. Torch originally was written for Lua, which is substantially faster than Python when using LuaJIT - but Torch failed to gain traction until switching to Python with the release of PyTorch.

The reason for this is that the performance penalty in writing programs in Python isn’t as large as the programming language benchmarks game would suggest: Most of the best Python Data libraries have their core routines written as native extensions.

This all means that to get the most out of these libraries, you need to treat Python as a Declarative Language - and push as much control flow as possible down to a native layer, and just let the Python program describe what needs done.
Declarative Programming Languages

Declarative Programming Languages focus on on describing what should be computed - and avoid mentioning how that computation should be performed. In practice this means avoiding expressions of control flow: loops and conditional statements are removed and replaced with higher level constructs that describe the logic of what needs to be computed.

The usual example of a declarative programming language is SQL. It lets you define what data you want computed - and translates that efficiently onto the database schema. This lets you avoid having to specify details of how to execute the query, and instead lets the query optimizer figure out the best index and query plan on a case by case basis.

Python isn’t a pure Declarative Language - but the same flexibility that contributes to its sluggish speed can be be leveraged to create Domain Specific API’s that use the same principles. I thought it would be kind of interesting to look at a couple specific examples of how this plays out.
NumPy

The design of NumPy has a couple neat declarative programming features, that lead to code that is not only cleaner and easier to understand - but also substantially faster.

A simple example of this might be to apply TF-IDF weighting to a sparse matrix. I originally needed to do this in order to add some basic nearest neighbour recommendation code as a baseline for my implicit recommendation library, and I thought it would provide a good example of what I’m talking about here.

In an imperative style, TF-IDF weighting on a sparse matrix can be written like:

def tfidf_imperative(m):
    # count up unique occurrences of each column of the sparse matrix
    X = coo_matrix(m)
    df = bincount(X.col)

    # calculate inverse-document-frequency = log(N/df) 
    N = float(X.shape[0])    
    idf = zeros(X.shape[1])
    for i in range(X.shape[1]):
        idf[i] = log(N / (1.0 + df[i]))

    # adjust data by TF-IDF weighting
    X.data = X.data.copy()
    for i in range(X.nnz):
        X.data[i] = sqrt(X.data[i]) * idf[X.col[i]]
   
    return X

There are 2 different for loops in that code - and each of which can be replaced by different NumPy language constructs.

The first for loop calculates the IDF itself. Numpy lets you do almost all operations on arrays of values as well as on single values and its much faster to use the vectorized form: idf = log(N / (1.0 + bincount(X.col))).

This tells NumPy to loop over the array returned from the bincount(X.col) function, and create a new array with the IDF value transformed appropriately. In effect we’re telling NumPy what result we want and letting it figure out how to calculate it best itself.

The final TF-IDF weighting can be done in a similar fashion using NumPy’s array indexing feature. This feature lets you use one array as an index into another array. Going idf[X.col] looks up each column value from X in IDF and returns an array with the IDF weight for that column.

Putting it all together leads to code like:

def tfidf_declarative(m):
    X = coo_matrix(m)

    # calculate IDF
    N = float(X.shape[0])
    idf = log(N / (1 + bincount(X.col)))

    # apply TF-IDF adjustment
    X.data = sqrt(X.data) * idf[X.col]
    return X

Not only is the declarative version shorter and more readable, its also substantially faster. By removing the for loops, the iteration can happen in vectorized C calls and makes this code run 75 times faster than the imperative version on my laptop. By avoiding writing any loops, we’ve declared the operations that need to happen and let the NumPy translate that to control flow.
TensorFlow

One frequently asked question is why Deep Learning frameworks like TensorFlow are written for Python instead of a faster language like C++.

The answer is that for the most part these frameworks are written in a language like C++, but provide a Python API to make it convenient to call. The Python code only describes the computations that need to be performed, all the real work happens in the library in either C++ or CUDA calls on the GPU.

Take a look at this simple function that uses TensorFlow to do Linear Regression:

def linear_regression(train_X, train_Y, learn_rate=0.005):
    # define placeholders for input data
    X, Y = tf.placeholder("float"), tf.placeholder("float")

    # define the variables we're learning
    slope, intercept = tf.Variable(0.0), tf.Variable(0.0)

    # learn the slope/intercept on a ordinary least squares loss function
    loss_function = (Y - (X * slope + intercept)) ** 2

    # find the parameters slope/intercept using a basic GD optimizer
    train = tf.train.GradientDescentOptimizer(learn_rate).minimize(loss_function)

    with tf.Session() as sess:
        tf.global_variables_initializer().run()

        # Train the model
        for x in range(100):
            sess.run(train, feed_dict={X: train_X, Y: train_Y})

        return sess.run(slope), sess.run(intercept)

In terms of line count, most of the function is in defining the variables to optimize, the linear model that we’re trying to learn and the loss function and optimization method to learn that function. None of these calls do any work though - all they do is declare a computation graph of what should be done.

Basically everything here happens in the sess.run call on the training function. This call takes the computation graph defined in the train variable binds the placeholder variables X and Y to the training data and runs the graph to learn the regression coefficients.
Python as Super Glue

Python is sort of like glue - it works well for binding different libraries together, but if you try to build a large fast program out of it you end up with a sticky mess that’s difficult to quickly move through.

The reason it has been so successful with Data Processing and Machine Learning tasks is that many of the libraries have adopted API’s where you declare the operations you want to perform, and the library executes those declarations in an efficient manner in a lower level language. This leads to the best of both worlds, code that’s easy to write in Python that runs as fast as code written in C++.

Using an imperative style means that you spend too much time wading through the glue, but declaring what operations you want leads to code that’s efficient and clean.

The side effect of this is that in order to be a great Python programmer, you have to learn to program in a lower level language too. All of the most popular Python data libraries have native extensions: TensorFlow, scikit-learn, NumPy, Pandas, SciPy, spaCY etc all have significant portions of their code written in a native language. If you are comfortable just using these libraries its enough to be just a good Python programmer; however, if you want to be the type of programmer that can produce libraries like these you really should be learning something like C++ or Cython too.

Published on 28 February 2017
]]
]]]
]]]]
